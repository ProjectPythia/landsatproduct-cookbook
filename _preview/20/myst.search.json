{"version":"1","records":[{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nSee the \n\nCookbook Contributor‚Äôs Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!\n\nThis Project Pythia Cookbook covers ... (replace ... with the main subject of your cookbook ... e.g., working with radar data in Python)","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Motivation"},"content":"(Add a few sentences stating why this cookbook will be useful. What skills will you, ‚Äúthe chef‚Äù, gain once you have reached the end of the cookbook?)","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Authors"},"content":"First Author, \n\nSecond Author, etc. Acknowledge primary content authors here","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Structure"},"content":"(State one or more sections that will comprise the notebook. E.g., This cookbook is broken up into two main sections - ‚ÄúFoundations‚Äù and ‚ÄúExample Workflows.‚Äù Then, describe each section below.)","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. ‚ÄúFoundations‚Äù )","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":10},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. ‚ÄúFoundations‚Äù )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"The foundational content includes ... \")","type":"content","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":11},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. ‚ÄúExample workflows‚Äù )","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":12},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. ‚ÄúExample workflows‚Äù )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"Example workflows include ... \")","type":"content","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":13},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n‚Äúlaunch Binder‚Äù. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you‚Äôll be able to execute\nand even change the example programs. You‚Äôll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace ‚Äúcookbook-example‚Äù with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"Calibrate a physical model"},"type":"lvl1","url":"/notebooks/calibration-note","position":0},{"hierarchy":{"lvl1":"Calibrate a physical model"},"content":"","type":"content","url":"/notebooks/calibration-note","position":1},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"ü§î Why Calibrate?"},"type":"lvl3","url":"/notebooks/calibration-note#id-why-calibrate","position":2},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"ü§î Why Calibrate?"},"content":"\n\nCalibration of a physical model is the process of tuning its parameters to ensure its outputs accurately match real-world measurements. It‚Äôs about bridging the gap between theoretical calculations and physical reality.\n\nKey Goal: The primary goal is to improve predictive accuracy, transforming a model from a theoretical construct into a reliable tool for analysis and design.\n\n","type":"content","url":"/notebooks/calibration-note#id-why-calibrate","position":3},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"üìù What Do You Need?"},"type":"lvl3","url":"/notebooks/calibration-note#id-what-do-you-need","position":4},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"üìù What Do You Need?"},"content":"\n\nTo calibrate a model, you need four key components:\n\n1. A Physical ModelA set of mathematical equations or simulation software.\n\n2. Tunable ParametersThe specific \"knobs\" in your model that you can adjust.\n\n3. Experimental DataHigh-quality measurements from the real-world system.\n\n4. An Objective FunctionA metric that quantifies the error (e.g., RMSE).\n\n","type":"content","url":"/notebooks/calibration-note#id-what-do-you-need","position":5},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚öôÔ∏è How to Calibrate?"},"type":"lvl3","url":"/notebooks/calibration-note#id-how-to-calibrate","position":6},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚öôÔ∏è How to Calibrate?"},"content":"\n\nThere are two main approaches to calibration: by hand (trial and error) or by using a smart computer search (optimization algorithms). Optimization is highly recommended for its efficiency and accuracy.\n\nClick to see details on different optimization methods\n\nGradient-Based Methods: Use the error gradient for efficient searching (e.g., Levenberg-Marquardt).\n\nGradient-Free Methods: Do not require gradients, essential for ‚Äúblack-box‚Äù simulations (e.g., Nelder-Mead).\n\nBayesian Calibration: Treats parameters as probability distributions to quantify uncertainty.\n\nCross-Calibration: Calibrates one model against a trusted reference model to ensure consistency.\n\n","type":"content","url":"/notebooks/calibration-note#id-how-to-calibrate","position":7},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"type":"lvl3","url":"/notebooks/calibration-note#id-how-do-you-know-its-calibrated","position":8},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"content":"\n\nA successful calibration can be verified by analyzing the errors and by validating the model against new data. A common way to visualize the result is by plotting the model‚Äôs output against the experimental data.\n\n","type":"content","url":"/notebooks/calibration-note#id-how-do-you-know-its-calibrated","position":9},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl4":"Interactive Example: Adjusting Model Parameters","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"type":"lvl4","url":"/notebooks/calibration-note#interactive-example-adjusting-model-parameters","position":10},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl4":"Interactive Example: Adjusting Model Parameters","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"content":"To make this concept interactive, you can run the code cell below. It will create the same plot but with sliders that let you manually adjust the model‚Äôs parameters (slope and intercept). Try to move the sliders to make the red line fit the blue dots. This gives you a hands-on feel for the ‚ÄúBy Hand‚Äù calibration process.\n\n# First, let's install ipywidgets for the interactive sliders\n!pip install -q ipywidgets\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, fixed\n\n# 1. Create the sample \"Experimental Data\"\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 20)\ntrue_slope = 2.5\ntrue_intercept = 1.5\ny_data = true_slope * x_data + true_intercept + np.random.normal(0, 2, size=x_data.shape)\n\n# 2. Define a function to plot the data and our adjustable model\ndef plot_model(x, y, slope, intercept):\n    \"\"\"Plots the experimental data against the model line defined by slope and intercept.\"\"\"\n    y_model = slope * x + intercept\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(x, y, 'o', label='Experimental Data', markersize=8, color='royalblue')\n    plt.plot(x, y_model, '-', label='Adjustable Model', linewidth=3, color='red')\n    \n    # Calculate and display the RMSE as our objective function score\n    rmse = np.sqrt(np.mean((y - y_model)**2))\n    plt.title(f'Comparison of Model vs. Data (RMSE: {rmse:.2f})', fontsize=16)\n    \n    plt.xlabel('Independent Variable', fontsize=12)\n    plt.ylabel('Dependent Variable', fontsize=12)\n    plt.ylim(min(y_data)-2, max(y_data)+2)\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.6)\n    plt.show()\n\n# 3. Create the interactive plot!\n# The 'interact' function automatically creates sliders for the numerical arguments.\ninteract(plot_model, x=fixed(x_data), y=fixed(y_data), slope=(0.0, 5.0, 0.1), intercept=(-5.0, 5.0, 0.1));\n\n","type":"content","url":"/notebooks/calibration-note#interactive-example-adjusting-model-parameters","position":11},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl2","url":"/notebooks/calibration-note#example-landsat-calibration-using-modis-sst","position":12},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"Create matchups between Landsat and MODIS SST data near Cosgrove, West Antarctica\nto produce a calibration for Landsat SSTs\n\nimport earthaccess\n%pip install seaborn\n%pip install pykrige\n%pip install xarray==2024.05.0\n\n# Import libraries and modules\n%config InlineBackend.figure_format = 'svg'\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport xarray as xr\nimport geopandas as gpd\nfrom datetime import date, timedelta, datetime\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom matplotlib import colors\nfrom matplotlib.pylab import rcParams\nfrom matplotlib.patches import Polygon as Pgon\nimport cartopy.crs as ccrs\nimport cartopy\n\nimport os\nfrom cycler import cycler\nimport pyproj\nfrom pyproj import Proj, transform\nfrom sklearn.neighbors import BallTree\nimport pytz\nimport pygmt\nimport gc\nimport copy\nimport random\nimport statsmodels.formula.api as sm\nimport scipy.stats as stats\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom shapely.geometry import Point, Polygon\nfrom pathlib import Path\nimport math\nfrom scipy.odr import Model, RealData, ODR\nfrom tqdm.notebook import trange, tqdm\nimport seaborn as sns\n\nimport earthaccess\n\n# For LST file masking\nimport pystac_client\nimport intake\nfrom rasterio.session import AWSSession\nimport boto3\n\nimport SSTutils as stu\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#For color cycling in plots that is color blind friendly...make new ones at \"I want hue\" tools.medialab.sciences-po.fr/iwanthue\ncolor_cycler = cycler(color=[\"#6777cf\",\"#adba49\",\"#c65ca0\",\"#5fa042\",\"#683287\",\"#72ce7b\",\"#c44a48\",\"#45c7a9\",\"#933c1d\",\"#d0803f\",\"#ac9239\",\"#317c39\"])\ncolorline_cycler = (cycler(color=[\"#75a141\",\"#6c61b9\",\"#bc4d45\",\"#c1913d\",\"#b85298\",\"#4aa8e8\"]) +\n                 cycler(linestyle=['-','--',':','-.','-','--']))\nrcParams['axes.prop_cycle'] = cycler('color', color_cycler)\n\n","type":"content","url":"/notebooks/calibration-note#example-landsat-calibration-using-modis-sst","position":13},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Build Landsat - MODIS SST matchups","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration-note#build-landsat-modis-sst-matchups","position":14},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Build Landsat - MODIS SST matchups","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Set paths and important variables and Calibration region bounding box\n\nbasepath = Path('/home/jovyan/landsatproduct-cookbook')\nspacing = [990,-990] # 990m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\nparam = 'sea_surface_temperature'\nsize_threshold = 30\n\nlocation = 0             # 0 and 1 are the Cosgrove and Dotson Polynya calibration areas, respectively\nsurf_temp = 'SST'        # 'SST' and 'LST' are for the Landsat SST and LST algorithms respectively\n\n# Set location bounds\nif location==1:\n    pathdir = 'DotsonPolynya'\n    latboundsC = [ -73.9 , -73.5 ] # Dotson polynya\n    lonboundsC = [ -113 , -111.5 ]\n    dfloc = 'Dotson'\nelif location==0:\n    pathdir = 'Cosgrove'\n    latboundsC = [ -73.5 , -73.42 ] # near Cosgrove\n    lonboundsC = [ -103.0 , -102.0 ]\n    dfloc = 'Cosgrove'\nelif location==2:\n    pathdir = 'Burke'\n    latboundsC = [ -73.81 , -73.42 ] # south of Burke\n    lonboundsC = [ -104.2 , -103.8 ]\n    dfloc = 'Burke'\nif location==3:\n    pathdir = 'DotsonIntercomp'\n    latboundsC = [ -74.2 , -74.11 ] # Dotson plume for intercomparison\n    lonboundsC = [ -113.5 , -113.17 ]\n    dfloc = 'DotsonIntercomp'\n\n# Coefficients for calibration\n# SST\nsstcalib_m = 0.76 \nsstcalib_b = 0.55 \n\n# LST\nlstcalib_m = 0.80\nlstcalib_b = 1.00\n\nmodmin = -1.9\nLSTmin = np.around(modmin/lstcalib_m - lstcalib_b,2) \nSSTmin = np.around(modmin/sstcalib_m - sstcalib_b,2) # should be about -2.0\n\n# Uncertainties used in ODR propagation of error\nmodis_uncertainty = 0.44  # long wave sst ocean color atbd\nsst_uncertainty = 0.3 # USGS Landsat stray light notice\nlst_uncertainty = 1.0 # gerace 2020\npix_uncertainty = np.sqrt((1000*1000)/(100*100)) # MODIS 1km x 1km and Landsat 100m x 100m\n\n\n# For calibrated SST runs\nif surf_temp=='SST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/Validation/{pathdir}/'\n    else:\n        sstpath = basepath / f'Data/SST/MODcalib/{pathdir}/'\n    tif = 'tif'\n    thresh = SSTmin\n    calib_m = sstcalib_m\n    calib_b = sstcalib_b\n    \n# If running for LST comparisons\nelif surf_temp=='LST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/LST/Calibration/DotsonPolynya/'\n    else:\n        sstpath = basepath / f'Data/SST/LST/Calibration/{pathdir}/'\n    tif = 'TIF'\n    thresh = LSTmin\n    calib_m = lstcalib_m\n    calib_b = lstcalib_b\n\n# Authenticate for accessing NASA data (MODIS)\nauth = earthaccess.login(strategy=\"interactive\")\n\n# If we are not authenticated\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\n# Convert bounding box to south polar stereo for checking if landsat has any data in bounding box\n# Speeds up process a lot\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the file\n\nbbox,checkbox = stu.lsat_reproj(source_crs,target_crs,(lonboundsC[0],latboundsC[0],lonboundsC[1],latboundsC[1]))\n\n# Create polygon for later cropping\npolygon = Polygon([(bbox[0][0],bbox[0][1]),(bbox[3][0],bbox[3][1]),(bbox[2][0],bbox[2][1]),(bbox[1][0],bbox[1][1])])\n\n# Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\nminx, miny, maxx, maxy = polygon.bounds\npolarx = [minx, maxx]\npolary = [miny, maxy]\n\n# Get Landsat file paths in directory\nlsatfiles = os.listdir(sstpath)\nlsatfiles = [x for x in lsatfiles if x[-3:] == tif]\nlsatfiles.sort()\nprint (len(lsatfiles))\nos.chdir(sstpath)\n\nSSTfails = [\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n]\nLSTfails = [\n 'LC08_L1GT_007112_20211215_20211223_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20220201_20220211_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20221202_20221212_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20230204_20230209_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220105_20220114_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220121_20220128_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221105_20221115_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230108_20230124_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230313_20230321_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF'\n]\n\n","type":"content","url":"/notebooks/calibration-note#build-landsat-modis-sst-matchups","position":15},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Search for desired Landsat scenes","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration-note#search-for-desired-landsat-scenes","position":16},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Search for desired Landsat scenes","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Authenticate for boto S3 access, etc.\nos.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\naws_session = AWSSession(boto3.Session(), requester_pays=True)\n\n# Setup and authenticate \nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient\n\n# Define the landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1 - includes L8 and L9\n\ni=0 # We will use the first image as an example\nls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\nls_scene\n\n%%time\n# ~1 min 32 sec per image\n# If number of MODIS images per satellite is much more than 25, its because there is a ULY,LRY issue\nos.chdir('/home/jovyan/landsatproduct-cookbook/Data/SST/MODcalib/Cosgrove/')\n\nlsat_mod = []\nfor i in tqdm(range(len(lsatfiles)), desc=\"Processing\"):\n    # Check for known repeatedly bad files that will kill the code\n    if surf_temp == 'SST':    \n        if lsatfiles[i] in SSTfails:\n            continue\n    elif surf_temp == 'LST':\n        if lsatfiles[i] in LSTfails:\n            continue\n        \n    # Concatenate all landsat files into xarray with a time dimension\n    ls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\n    ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n    \n    if surf_temp == 'SST':\n        times = pd.to_datetime(lsatfiles[i][17:25]+lsatfiles[i][41:47], format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-8])\n    elif surf_temp == 'LST':\n        # Need to mask LST because not done previously\n        mask = stu.get_lst_mask(lsatfiles[i])\n        ls_scene = ls_scene * mask\n        \n        times = pd.to_datetime(lsatfiles[i][17:25]+'120000', format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-4])\n        ls_scene = ls_scene - 273.15\n\n    # Subset scene and check that it has the correct dimensions because y order changes sometimes\n    ls_scene = stu.subset_img(ls_scene,polarx,polary) # subset so easier to work with\n    ls_scene = stu.crop_xarray_dataarray_with_polygon(ls_scene, polygon) # crop data to exact bounding box\n\n    lsID = lsatfiles[i]\n    \n    # Take mean temp, will skip the modis stage if no Landsat data in the calibration region\n    try:\n        lsat = np.nanmean(ls_scene)\n    except Exception as e:\n        lsat = np.nan\n\n    if ~np.isfinite(lsat):\n        continue\n\n    # Find coincident MODIS SST scene\n    mod_scene, mod_file,time_dif = stu.find_MODIS(lonboundsC,latboundsC,ls_scene)\n\n    try:\n        # Acquire and align MODIS data to Landsat\n        MODsst_xr = stu.get_sst(ls_scene,mod_scene.sea_surface_temperature,spacing,param)\n        # Remove SSTs that are unrealistically cool\n        MODsst_xr = MODsst_xr.where(MODsst_xr >= -1.9, np.nan)\n        # Crop Landsat image to meet the slightly smaller MODIS image\n        ls_scene = stu.subset_img(ls_scene,[MODsst_xr.x.min(),MODsst_xr.x.max()],[MODsst_xr.y.min(),MODsst_xr.y.max()])\n        # Only use MODIS data where cropped Landsat data is also available\n        MODsst_xr_sub = MODsst_xr.where(ls_scene.notnull(),np.nan)\n        # Take mean temp\n        modis = np.nanmean(MODsst_xr_sub)\n        MOD_num = MODsst_xr_sub.notnull().values.sum()\n    except Exception as e:\n        modis = np.nan\n        MOD_num = 0\n\n    # Take mean using Landsat data only where cropped MODIS data is also available (need to do both)\n    try:\n        ls_scene_sub = ls_scene.where(MODsst_xr_sub.notnull(),np.nan)\n        lsat = np.nanmean(ls_scene_sub)\n        ls_num = ls_scene_sub.notnull().values.sum()\n    except Exception as e:\n        lsat = np.nan\n        ls_num = 0 # FIX: Initialize ls_num in case of exception\n\n    # Append file names with SST means from the Cosgrove box\n    lsat_mod.append([times,mod_file,modis,MOD_num,lsID,lsat,ls_num,time_dif])\n    \n    try:\n        del ls_scene, mod_scene, MODsst_xr, MODsst_xr_sub\n    except:\n        pass\n\n    gc.collect()\n\n# Put data into DataFrame and save    \nheaders = ['DateTime','MODIS_filename','MODIS_SST','MODIS_pix','L8_filename',f'L8_{surf_temp}','L8_pix','time_dif']\nlsat_mod_df = pd.DataFrame(lsat_mod,columns=headers)\nout_df = basepath / f'Data/MODISvLandsat_{surf_temp}_{dfloc}_20250500.csv'\nlsat_mod_df.to_csv(out_df, index=False)\n\nprint (out_df)\n\n","type":"content","url":"/notebooks/calibration-note#search-for-desired-landsat-scenes","position":17},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Calculate calibration bias and trend","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration-note#calculate-calibration-bias-and-trend","position":18},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Calculate calibration bias and trend","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Read in paired MODIS/Landsat data created above\nsurf_temp = 'SST'\n\nif surf_temp=='LST':\n    thresh = -3.5 # -3.4 is ok too\n    pix_thresh = 1300\nelif surf_temp=='SST':\n    thresh = -3.1\n    pix_thresh = 1300\nmod_sst_thresh = -1.9\n\n# For Cosgrove region\nif surf_temp=='LST':\n    out_df_C = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Cosgrove.csv'\nelse:   \n    out_df_C = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Cosgrove_lin_scale.csv' \nlsat_mod_df_C = pd.read_csv(out_df_C)\nlsat_mod_df_C['Region'] = 'Cosgrove'\n\n# For Dotson polynya region\nif surf_temp=='LST':\n    out_df_D = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Dotson.csv'\nelse:\n    out_df_D = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Dotson_lin_scale.csv'  \nlsat_mod_df_D = pd.read_csv(out_df_D)\nlsat_mod_df_D['Region'] = 'Dotson'\n\n# For Burke region\nif surf_temp=='LST':\n    out_df_B = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Burke.csv'\nelse:\n    out_df_B = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Burke_lin_scale.csv'\nlsat_mod_df_B = pd.read_csv(out_df_B)\nlsat_mod_df_B['Region'] = 'Burke'\n\n# Concatenate data from all regions\nlsat_mod_df_n = pd.concat([lsat_mod_df_B,lsat_mod_df_C,lsat_mod_df_D])\nprint(f'Original # matchups at Cosgrove: {lsat_mod_df_C.shape[0]}, at Dotson: {lsat_mod_df_D.shape[0]}, at Burke: {lsat_mod_df_B.shape[0]}')\n\n# sum_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([2])]\n# sum_c = lsat_mod_df_C[lsat_mod_df_C.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# sum_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([2])]\n# sum_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([2])]\n# sum_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([2])]\n\n# # ***check all the february images to see if we need to add a threshold of 2.0C or cut images or if the issue is clouds???\n# # shld\n# look = lsat_mod_df_n.sort_values('L8_filename')\n# look.head(20)\n\n# Orthoganal Regression \nif surf_temp=='LST':\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = lst_uncertainty\nelse:\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = sst_uncertainty\n\n# Original data\nx_original = np.array(data0[f'L8_{surf_temp}'])\ny_original = np.array(data0['MODIS_SST'])\n\n# Assume these are your uncertainty estimates per observation\nsy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\nsx = np.full_like(x_original, landsat_uncertainty)\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model\nlinear = Model(linear_model)\n\n# Create a RealData object using your DataFrame\ndata = RealData(x_original, y_original,sx=sx, sy=sy)\n\n# Set up ODR with the model and data\nodr = ODR(data, linear, beta0=[1., 0.])\n\n# Run the regression\nout = odr.run()\n\n# Use the output\nbeta = out.beta\nbeta_err = out.sd_beta\n\n# Print the summary\nout.pprint()\n\n# Predicting values using the ODR model\ny_pred = linear_model(beta, x_original)\n\n# Get R2\n# Calculate Total Sum of Squares (SST)\ny_mean = np.mean(y_original)\nSST = np.sum((y_original - y_mean)**2)\n\n# Calculate Residual Sum of Squares (SSR)\nSSR = np.sum((y_original - y_pred)**2)\n\n# Compute RMSE\nrmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n\n# Calculate R^2\nR2 = 1 - (SSR / SST)\nprint(\"R^2:\", np.around(R2,2))\nprint(f\"RMSE: {np.around(rmse,2)}\")\n\nif surf_temp=='LST':\n    # Plot regression\n    beta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    beta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    print(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\n    xfill = np.array([-4.5,1.5])\n    \n    fig, ax = plt.subplots(figsize=(8, 3.5))\n    ax.tick_params(labelsize=14)\n    \n    # LST data and regression\n    plt.scatter(x_original, y_original, s=12,color='mediumslateblue')\n    plt.plot(x_original, y_pred, color='mediumslateblue', label='LST ODR')\n    plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n    \n    # Comparison regressions\n    xi = np.arange(-7.0,5.0,1.0)\n    plt.plot(xi,xi * sstcalib_m + sstcalib_b,color='k',linewidth=2,label='SST ODR')\n    plt.plot(xi,xi,color='lightcoral',linewidth=2, label='MODIS 1:1')\n        \n    plt.legend(loc='lower right',fontsize=14)\n    plt.text(-2.7,-0.15,rf'$\\mathbf{{y={np.around(beta[0],2)}x+{np.around(beta[1],2)}\\quad r^2={np.around(R2,2)}}}$',color='mediumslateblue', fontweight='bold',fontsize=14)\n    plt.xlim([-3.5,-1.2])\n    plt.ylim([-3.05,0.8])\n    # else: \n    #     plt.plot(x_original, y_pred, color='k', label='NLSST Orthogonal Distance Regression')\n    #     plt.legend(loc='lower right',fontsize=12)\n    #     plt.text(-2.6,-0.2,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\n    #     plt.xlim([-3.2,-0.15])\n    #     plt.ylim([-2.4,0.9]) \n    plt.xlabel('Landsat ST [¬∞C]',fontsize=16)\n    plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n    plt.tight_layout()\n\n# Orthoganal Regression for SST only\ndataframes = [\n    ('Combined', lsat_mod_df_n),\n    ('Burke', lsat_mod_df_B),\n    ('Cosgrove', lsat_mod_df_C),\n    ('Dotson', lsat_mod_df_D),\n]\n\nif surf_temp=='LST':\n    landsat_uncertainty = lst_uncertainty\nelse:\n    landsat_uncertainty = sst_uncertainty\n\n# Dictionary to store the results from each DataFrame\nodr_results = {}\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model object\nlinear = Model(linear_model)\n\n# Loop over each DataFrame\nfor df_name, data0 in dataframes:\n    print(f\"\\n=== Processing {df_name} ===\")\n    \n    # Original data\n    x_original = np.array(data0[f'L8_{surf_temp}'])\n    y_original = np.array(data0['MODIS_SST'])\n\n    # Assume these are your uncertainty estimates per observation\n    sy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\n    sx = np.full_like(x_original, landsat_uncertainty)\n    \n    # Create a RealData object using your DataFrame\n    data = RealData(x_original, y_original,sx=sx, sy=sy)\n    \n    # Set up ODR with the model and data, providing an initial guess\n    odr = ODR(data, linear, beta0=[1., 0.])\n    \n    # Run the regression\n    out = odr.run()\n    \n    # Retrieve best-fit parameters and their std. dev.\n    beta = out.beta\n    beta_err = out.sd_beta\n    \n    # Print the summary\n    out.pprint()\n    \n    # Predicting values using the ODR model\n    y_pred = linear_model(beta, x_original)\n    \n    # Get R2\n    # Calculate Total Sum of Squares (SST)\n    y_mean = np.mean(y_original)\n    SST = np.sum((y_original - y_mean)**2)\n    \n    # Calculate Residual Sum of Squares (SSR)\n    SSR = np.sum((y_original - y_pred)**2)\n    \n    # Calculate R^2\n    R2 = 1 - (SSR / SST)\n\n    # Compute RMSE\n    rmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n    \n    # Print R^2\n    print(f\"{df_name} R^2:\", np.around(R2, 2))\n    print(f\"RMSE: {np.around(rmse,2)}\")\n    \n    # Store results in a dictionary for later use (plotting, etc.)\n    odr_results[df_name] = {\n        'beta': beta,\n        'beta_err': beta_err,\n        'R2': R2,\n        'x_original': x_original,\n        'y_original': y_original,\n        'y_pred': y_pred\n    }\n\nif surf_temp=='SST':\n    # Plot with all points and by region (Burke=r, Cosgrove=b, Dotson=g) - show with lsat_mod_df_n calculations for the line\n    beta_mdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n    beta_mup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n    beta_bdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n    beta_bup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n    a1 = np.around(odr_results['Combined']['beta'][0],2)\n    a1e = np.around(odr_results['Combined']['beta_err'][0]*1.96,2)\n    a2 = np.around(odr_results['Combined']['beta'][1],2)\n    a2e = np.around(odr_results['Combined']['beta_err'][1]*1.96,2)\n    nn = odr_results['Combined']['y_pred'].shape[0]\n    ar = np.around(odr_results['Combined']['R2'],2)\n    b1 = np.around(odr_results['Burke']['beta'][0],2)\n    b2 = np.around(odr_results['Burke']['beta'][1],2)\n    br = np.around(odr_results['Burke']['R2'],2)\n    c1 = np.around(odr_results['Cosgrove']['beta'][0],2)\n    c2 = np.around(odr_results['Cosgrove']['beta'][1],2)\n    cr = np.around(odr_results['Cosgrove']['R2'],2)\n    d1 = np.around(odr_results['Dotson']['beta'][0],2)\n    d2 = np.around(odr_results['Dotson']['beta'][1],2)\n    dr = np.around(odr_results['Dotson']['R2'],2)\n    print(f'At 95% confidence interval: {a1}+/-{a1e}, {a2}+/-{a2e}, n={nn}')\n    xfill = np.array([-4.3,0.9])\n    \n    \n    fig, ax = plt.subplots(figsize=(8, 3))\n    ax.tick_params(labelsize=14)\n    \n    plt.scatter(np.array(lsat_mod_df_B[f'L8_{surf_temp}']), np.array(lsat_mod_df_B['MODIS_SST']), s=12,color='#00bf7d', label='Burke')\n    plt.scatter(np.array(lsat_mod_df_C[f'L8_{surf_temp}']), np.array(lsat_mod_df_C['MODIS_SST']), s=12,color=sns.color_palette(\"colorblind\")[3], label='Cosgrove')\n    plt.scatter(np.array(lsat_mod_df_D[f'L8_{surf_temp}']), np.array(lsat_mod_df_D['MODIS_SST']), s=12,color='#0073e6', label='Dotson')\n    \n    plt.plot(odr_results['Combined']['x_original'], odr_results['Combined']['y_pred'], color='k')\n    plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n    plt.plot(odr_results['Burke']['x_original'], odr_results['Burke']['y_pred'], ls='-',linewidth=1,color='#00bf7d')\n    plt.plot(odr_results['Cosgrove']['x_original'], odr_results['Cosgrove']['y_pred'], ls='-',linewidth=1,color=sns.color_palette(\"colorblind\")[3])\n    plt.plot(odr_results['Dotson']['x_original'], odr_results['Dotson']['y_pred'], ls='-',linewidth=1,color='#0073e6')\n    \n    if surf_temp=='LST':\n        plt.text(-2.25,-0.2,f'y={a1}x+{a2}   $r^2$={ar}',color='#00bf7d',fontsize=14)\n        plt.text(-2.25,-0.2,f'y={c1}x+{c2}   $r^2$={cr}',color=sns.color_palette(\"colorblind\")[3],fontsize=12)\n        plt.text(-2.25,-0.2,f'y={d1}x+{d2}   $r^2$={dr}',color='#0073e6',fontsize=12)\n        plt.xlim([-2.5,-1.4])\n        plt.ylim([-2.05,0.0])\n    else: \n        plt.text(-2.9,0.3,f'y={a1}x+{a2}   $r^2$={ar}',color='k',fontsize=14)\n        plt.text(-2.9,0.0,f'y={b1}x+{b2}   $r^2$={br}',color='#00bf7d',fontsize=12)\n        plt.text(-2.9,-0.3,f'y={c1}x+{c2}   $r^2$={cr}',color=sns.color_palette(\"colorblind\")[3],fontsize=12)\n        plt.text(-2.9,-0.6,f'y={d1}x+{d2}   $r^2$={dr}',color='#0073e6',fontsize=12)\n        plt.xlim([-3.05,-0.15])\n        plt.ylim([-2.3,0.9])\n    plt.xlabel('Landsat SST [¬∞C]',fontsize=16)\n    plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n    plt.legend(loc='lower right',fontsize=10)\n    plt.tight_layout()\n\nodr_results['Combined']['beta_err']\n\nif surf_temp=='SST':\n    # Ordinary least squares regression between Landsat and MODIS SST matchups\n    resultC = sm.ols(formula=\"MODIS_SST ~ L8_SST\", data=data0).fit()\n    print (resultC.summary())\n\n","type":"content","url":"/notebooks/calibration-note#calculate-calibration-bias-and-trend","position":19},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Interactive Analysis Dashboard using Plotly","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration-note#interactive-analysis-dashboard-using-plotly","position":20},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Interactive Analysis Dashboard using Plotly","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Imports for Interactive Dashboard\nimport ipywidgets as widgets\nfrom ipywidgets import interact, Layout\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Interactive Dashboard Function\n\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\ndef interactive_calibration_dashboard(region, chart_type, pix_thresh, modis_sst_thresh, lsat_sst_thresh):\n    # 1. Filter each dataframe individually based on widget values\n    df_C_filt = lsat_mod_df_C[(lsat_mod_df_C['MODIS_pix'] >= pix_thresh) &\n                              (lsat_mod_df_C['MODIS_SST'] >= modis_sst_thresh) &\n                              (lsat_mod_df_C[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    \n    df_D_filt = lsat_mod_df_D[(lsat_mod_df_D['MODIS_pix'] >= pix_thresh) &\n                              (lsat_mod_df_D['MODIS_SST'] >= modis_sst_thresh) &\n                              (lsat_mod_df_D[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n\n    df_B_filt = lsat_mod_df_B[(lsat_mod_df_B['MODIS_pix'] >= pix_thresh) &\n                              (lsat_mod_df_B['MODIS_SST'] >= modis_sst_thresh) &\n                              (lsat_mod_df_B[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n\n    # 2. Select data based on dropdown menu\n    if region == 'All Regions':\n        df_filtered = pd.concat([df_B_filt, df_C_filt, df_D_filt])\n    elif region == 'Cosgrove':\n        df_filtered = df_C_filt\n    elif region == 'Dotson':\n        df_filtered = df_D_filt\n    elif region == 'Burke':\n        df_filtered = df_B_filt\n    \n    if len(df_filtered) < 2:\n        # Create an empty plot with a message\n        fig = go.Figure()\n        fig.update_layout(title_text=\"Not enough data with the current filter settings.\", \n                          xaxis={'visible': False}, yaxis={'visible': False})\n        fig.show()\n        return\n    \n    # 3. Perform Orthogonal Distance Regression (ODR)\n    x_data = df_filtered[f'L8_{surf_temp}'].values\n    y_data = df_filtered['MODIS_SST'].values\n    \n    sx = np.full_like(x_data, sst_uncertainty)\n    sy = np.full_like(y_data, modis_uncertainty * pix_uncertainty)\n\n    model = Model(linear_model)\n    data = RealData(x_data, y_data, sx=sx, sy=sy)\n    odr = ODR(data, model, beta0=[1., 0.])\n    output = odr.run()\n    \n    slope, intercept = output.beta\n    y_pred = linear_model(output.beta, x_data)\n    \n    # 4. Calculate statistics including bias and trend\n    bias = np.mean(y_data - x_data)\n    trend = slope\n    ss_total = np.sum((y_data - np.mean(y_data))**2)\n    ss_resid = np.sum((y_data - y_pred)**2)\n    r2 = 1 - (ss_resid / ss_total) if ss_total > 0 else 0\n    rmse = np.sqrt(np.mean((y_data - y_pred)**2))\n    stats_text = (f\"<b>Trend (Slope):</b> {trend:.2f} | <b>Bias (MODIS - Landsat):</b> {bias:.2f}¬∞C<br>\"\n                  f\"<b>R¬≤:</b> {r2:.2f} | <b>RMSE:</b> {rmse:.2f} | <b>N:</b> {len(df_filtered)}\")\n\n    # 5. Create Plotly figure based on chart_type\n    if chart_type == 'Scatter':\n        fig = px.scatter(df_filtered, x=f'L8_{surf_temp}', y='MODIS_SST', \n                         color='Region', hover_data=['L8_filename', 'DateTime'])\n    elif chart_type == 'Heatmap':\n        fig = go.Figure(go.Histogram2d(\n            x=df_filtered[f'L8_{surf_temp}'],\n            y=df_filtered['MODIS_SST'],\n            colorscale='Viridis'\n        ))\n    \n    # Add regression line to both plot types\n    sorted_indices = np.argsort(x_data)\n    fig.add_trace(go.Scatter(x=x_data[sorted_indices], y=y_pred[sorted_indices], \n                           mode='lines', name='ODR Fit', line=dict(color='black', width=2)))\n\n    fig.update_layout(\n        title_text=stats_text,\n        xaxis_title=\"Landsat SST [¬∞C]\",\n        yaxis_title=\"MODIS SST [¬∞C]\",\n        xaxis_range=[-3.05, -0.15],\n        yaxis_range=[-2.3, 0.9],\n        legend_title=\"Region\"\n    )\n    \n    fig.show()\n\n# Define Widgets\nstyle = {'description_width': 'initial'}\nw_region = widgets.Dropdown(options=['All Regions', 'Cosgrove', 'Dotson', 'Burke'], value='All Regions', description='Select Region:', style=style)\nw_chart_type = widgets.ToggleButtons(options=['Scatter', 'Heatmap'], description='Chart Type:', button_style='info')\nw_pix_thresh = widgets.IntSlider(value=1300, min=0, max=5000, step=100, description='Min MODIS Pixels:', style=style, layout=Layout(width='500px'))\nw_modis_sst = widgets.FloatSlider(value=-1.9, min=-2.5, max=0, step=0.1, description='Min MODIS SST (¬∞C):', style=style, layout=Layout(width='500px'))\nw_lsat_sst = widgets.FloatSlider(value=-3.1, min=-4.0, max=0, step=0.1, description='Min Landsat SST (¬∞C):', style=style, layout=Layout(width='500px'))\n\n# Launch the Dashboard\ninteract(interactive_calibration_dashboard, \n         region=w_region, \n         chart_type=w_chart_type,\n         pix_thresh=w_pix_thresh, \n         modis_sst_thresh=w_modis_sst, \n         lsat_sst_thresh=w_lsat_sst);","type":"content","url":"/notebooks/calibration-note#interactive-analysis-dashboard-using-plotly","position":21},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/notebook-template","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let‚Äôs start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in \n\nthis MyST guide, or you edit this cell to see a demonstration. Be sure to include alt text for any embedded images to make your content more accessible.\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/notebook-template","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/notebook-template#overview","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they‚Äôll be leaving with\n\n","type":"content","url":"/notebooks/notebook-template#overview","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/notebook-template#prerequisites","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they‚Äôll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/notebook-template#prerequisites","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/notebook-template#imports","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport sys\n\n","type":"content","url":"/notebooks/notebook-template#imports","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-first-content-section","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\n# as well as any and all of your code cells\nprint(\"Hello world!\")\n\n","type":"content","url":"/notebooks/notebook-template#your-first-content-section","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-content-subsection","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\na = [1, 2, 3, 4, 5]\n[i + 2 for i in a]\n\n","type":"content","url":"/notebooks/notebook-template#a-content-subsection","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#another-content-subsection","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/notebook-template#another-content-subsection","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-second-content-section","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n","type":"content","url":"/notebooks/notebook-template#your-second-content-section","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-subsection-to-the-second-section","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-subsection-to-the-second-section","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/notebook-template#a-quick-demonstration","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-quick-demonstration","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/notebook-template#of-further-and-further","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#of-further-and-further","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/notebook-template#header-levels","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don‚Äôt hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/notebook-template#header-levels","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/notebook-template#last-section","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book‚Äôs \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/notebook-template#last-section","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/notebook-template#summary","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/notebook-template#summary","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What‚Äôs next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/notebook-template#whats-next","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What‚Äôs next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/notebook-template#whats-next","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/notebook-template#resources-and-references","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you‚Äôre done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you‚Äôd like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you‚Äôre legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/notebook-template#resources-and-references","position":31},{"hierarchy":{"lvl1":"Validating your data product"},"type":"lvl1","url":"/notebooks/validation","position":0},{"hierarchy":{"lvl1":"Validating your data product"},"content":"%pip install xarray==2024.05.0\n\n# Imports\n%pip install pykrige\n#%pip install xarray\n# %pip install xarray==2024.05.0\n\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom skimage import exposure\nfrom skimage.io import imsave, imread\nfrom osgeo import ogr\nimport pystac_client\nfrom pyproj import Transformer\nfrom datetime import date, timedelta, datetime\nfrom dateutil.relativedelta import relativedelta\nimport geopandas as gpd\nimport pandas as pd\nimport geoviews as gv\nimport hvplot.pandas\nimport intake\nimport xarray as xr\nimport numpy as np\nfrom numpy.random import default_rng\nimport intake\nfrom pyproj import Proj, transform\nfrom osgeo import gdal\nfrom sklearn.neighbors import BallTree\nimport earthaccess\nimport gzip\n\n# for progress bar\nfrom ipywidgets import IntProgress\nfrom IPython.display import display\nfrom ipywidgets import interact, Dropdown\nimport time\nfrom tqdm.notebook import trange, tqdm\n\nimport boto3\nimport rasterio as rio\nfrom rasterio.features import rasterize\nfrom rasterio.session import AWSSession\nimport dask\nimport os\nimport rioxarray\nfrom rasterio.enums import Resampling\nfrom rasterio.warp import reproject\nfrom rasterio.warp import Resampling as resample\nimport cartopy.crs as ccrs\nimport cartopy\nfrom pykrige.ok import OrdinaryKriging\nfrom sklearn.linear_model import LinearRegression, RANSACRegressor\nfrom scipy.odr import Model, RealData, ODR\nimport scipy.odr as odr\nimport scipy\nimport statsmodels.formula.api as smf\nfrom shapely.geometry.polygon import Polygon, Point\nimport pygmt\nimport gc\nimport pytz\nimport pyproj\nimport math\nfrom pathlib import Path\nfrom matplotlib.patches import Polygon as Pgon\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\n\nimport SSTutils as sut\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","type":"content","url":"/notebooks/validation","position":1},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Why do we need to validate?"},"type":"lvl3","url":"/notebooks/validation#why-do-we-need-to-validate","position":2},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Why do we need to validate?"},"content":"Now we have our calibrated SST data product! ü•≥ We‚Äôre almost ready to use this data product for our scientific analysis, but there is still one more important step. As a quick reminder, our data product was derived from top-of-atmosphere radiance measurements. We then converted these radiances into actual SST values (in units of temperature) by calibrating with another satellite (MODIS). But can we trust that these derived SST values are accurately reflecting real ocean surface temperatures? Validation allows us to quantitfy the uncertainty of our product.\n\n","type":"content","url":"/notebooks/validation#why-do-we-need-to-validate","position":3},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data to validate with"},"type":"lvl3","url":"/notebooks/validation#finding-data-to-validate-with","position":4},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data to validate with"},"content":"When validating satellite products, we typically want to use in situ measurements: i.e., direct measurements taken in the field. For the ocean, these measurements come from buoys, ship-based thermometers and autonomous floats. An important thing to keep in mind is that while satellites measure the skin temperature (top ~10‚Äì20 microns), in situ platforms measure bulk SST (a few cm to 1 m depth).\n\nShould be high quality!\n\nFinding a good validation dataset can be tricky. Here‚Äôs are some lists of commonly-used validation datasets to help get you started:\n\nTO DO: These links need to be checked\n\nüåä Ocean\n\nDataset\n\nAccess\n\nVariables\n\nArgo\n\nargo.ucsd.edu  ‚Äî DOI: \n\nArgo (2025)  \n\nNOAA archive ‚Äî DOI: \n\n10.25921/q97e‚Äëd719\n\nSea surface temperature, salinity\n\nGHRSST iQuam\n\nGHRSST iQuam website  \n\nGHRSST documentation (Zenodo)\n\nSea surface temperature\n\nGTSPP\n\nNCEI GTSPP access\n\nTemperature, salinity profiles\n\nSPURS\n\nSPURS homepage (NASA)\n\nSea surface salinity\n\nSeaBASS\n\nseabass‚Äã.gsfc‚Äã.nasa‚Äã.gov\n\nOcean color, chlorophyll-a\n\nNOMAD\n\nNOMAD at NOAA STAR\n\nOcean color, chlorophyll-a\n\nBOUSSOLE\n\nBOUSSOLE Project\n\nOcean color, optics, chlorophyll\n\nGDP (Drifters)\n\nGlobal Drifter Program\n\nOcean surface currents\n\nHF Radar\n\nHFRNet Portal\n\nOcean surface currents\n\nADCP\n\nNOAA ADCP Program\n\nWater column currents\n\n‚õÖÔ∏è Atmosphere\n\nDataset\n\nAccess\n\nVariables\n\nAERONET\n\naeronet‚Äã.gsfc‚Äã.nasa‚Äã.gov  \n\nre3data entry\n\nAerosol optical depth (AOD), aerosol type\n\nIGRA\n\nIGRA at NOAA\n\nAtmospheric temperature, pressure\n\nGRUAN\n\nGRUAN\n\nTemperature, humidity, pressure\n\nMETAR/ASOS\n\nIowa State Mesonet\n\nSurface temperature, pressure\n\nGPM-GV\n\nNASA GPM Ground Validation\n\nPrecipitation\n\nGPCC\n\nGPCC at DWD\n\nPrecipitation\n\nSKYNET\n\nChiba University SKYNET\n\nAerosols, AOD\n\nMPLNET\n\nMPLNET at NASA\n\nAerosols, clouds\n\nTCCON\n\nTCCON Data Portal\n\nCO‚ÇÇ, CH‚ÇÑ, other trace gases\n\nPandora\n\nPandora Project\n\nNO‚ÇÇ, O‚ÇÉ, trace gases\n\nMAX-DOAS\n\nMAX-DOAS Network\n\nNO‚ÇÇ, SO‚ÇÇ, HCHO\n\nüå≥ Land\n\nDataset\n\nAccess\n\nVariables\n\nSURFRAD\n\nNOAA SURFRAD\n\nLand surface temperature, radiation\n\nBSRN\n\nBSRN\n\nSolar radiation, surface energy fluxes\n\nFLUXNET\n\nfluxnet.org\n\nLST, vegetation indices, fluxes\n\nSCAN\n\nUSDA SCAN\n\nSoil moisture\n\nISMN\n\nInternational Soil Moisture Network\n\nSoil moisture\n\nPhenocam\n\nPhenocam Network\n\nVegetation phenology (NDVI proxy)\n\nNEON\n\nNEON Data Portal\n\nVegetation indices, climate variables\n\nBELMANIP\n\nCopernicus Land Service\n\nLeaf area index (LAI)\n\nVALERI\n\nVALERI Project\n\nLAI, fAPAR\n\nDIRECT\n\nVALERI/DIRECT Info\n\nLAI\n\n‚ùÑÔ∏è Cryosphere\n\nDataset\n\nAccess\n\nVariables\n\nSnowEx\n\nNASA SnowEx\n\nSnow depth, snow cover, SWE\n\nCALVAL (NSIDC)\n\nNSIDC Cal/Val\n\nSnow, cryosphere\n\nGSNOW\n\nNOAA GSNOW\n\nSnow cover\n\nNSIDC\n\nNSIDC\n\nSea ice, snow cover\n\nIABP (Ice Buoys)\n\nInternational Arctic Buoy Program\n\nSea ice concentration, drift\n\nIceBridge\n\nNASA IceBridge\n\nIce sheet elevation, thickness\n\nATM\n\nAirborne Topographic Mapper (ATM)\n\nIce elevation profiles\n\nNOHRSC\n\nNOAA NOHRSC\n\nSnow depth and snow water equivalent\n\nCCSN (Canada)\n\nCanadian Cryospheric Snow Network\n\nSnow depth, SWE\n\n","type":"content","url":"/notebooks/validation#finding-data-to-validate-with","position":5},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Example: GHRSST iQUAM data","lvl3":"Finding data to validate with"},"type":"lvl4","url":"/notebooks/validation#example-ghrsst-iquam-data","position":6},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Example: GHRSST iQUAM data","lvl3":"Finding data to validate with"},"content":"For our new SST product, we‚Äôll use the GHRSST iQUAM dataset for validation. GHRSST is the Group for High Resolution Sea Surface Temperature ‚Äì an international collaboration supporting high-quality SST products for research and operational use ‚Äì and iQuam is a system developed by NOAA to collect, quality-control (QC), and distribute in situ SST observations in near real-time and delayed mode. This dataset aggregates SST measurements from a variety of in situ platforms, such as drifting buoys, moored buoys, shipboard sensors, and Argo floats.\n\nhttps://‚Äãwww‚Äã.star‚Äã.nesdis‚Äã.noaa‚Äã.gov‚Äã/socd‚Äã/sst‚Äã/iquam‚Äã/‚Äã?tab‚Äã=‚Äã0‚Äã&‚Äãdateinput‚Äã_year‚Äã=‚Äã2023‚Äã&‚Äãdateinput‚Äã_month‚Äã=‚Äã02‚Äã&‚Äãdayofmoninput‚Äã_day‚Äã=‚Äã26‚Äã&‚Äãdateinput‚Äã_hour‚Äã=‚Äã00‚Äã&‚Äãdayofmon‚Äã=‚Äãmonthly‚Äã&‚Äãqcrefsst‚Äã=‚Äã‚Äã_qcrey‚Äã&‚Äãqcrefsst‚Äã=‚Äã‚Äã_qccmc‚Äã&‚Äãoutlier‚Äã=‚Äãqced‚Äã#qmap\n\n","type":"content","url":"/notebooks/validation#example-ghrsst-iquam-data","position":7},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data matchups"},"type":"lvl3","url":"/notebooks/validation#finding-data-matchups","position":8},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data matchups"},"content":"\n\nHere are some important considerations we need to make when finding matchups between the satellite product and in situ datasets:\n\nüîπ 1. Spatial Collocation\n\nFootprint Differences: Satellite pixels often represent an area (e.g., 1 km¬≤ or more), while in situ data may be point measurements.\n\nSolution: Use in situ data averaged over the satellite footprint or compare satellite data averaged over multiple pixels surrounding the in situ point.\n\nGeolocation Accuracy: Both satellite and in situ positions should be accurately known, especially in dynamic environments (e.g., drifting buoys).\n\nEnvironmental Variability: Spatial gradients (e.g., near coastlines or fronts) can lead to mismatches even with close locations.\n\nüîπ 2. Temporal Matching\n\nTemporal Resolution: Satellites provide snapshots (sometimes daily, sometimes instantaneous), while in situ data may be continuous or periodic.\n\nSolution: Match satellite observation time as closely as possible to in situ sampling time (e.g., within ¬±1 hour).\n\nDiurnal Effects: Some variables (e.g., SST, radiative fluxes) vary significantly throughout the day.\n\nSolution: Use diurnal correction or only match at known overpass times (e.g., MODIS ~1:30 pm local time).\n\nüîπ 3. Variable Definitions and Depths\n\nDepth Differences: For example, satellite SST represents skin temperature (top ~10‚Äì20 Œºm), whereas in situ sensors often measure at ~1 m.\n\nSolution: Apply a skin-to-bulk correction or compare to ‚Äúfoundation temperature‚Äù from models.\n\nVariable Representation: Ensure the in situ measurement is of the same quantity the satellite estimates (e.g., top-of-canopy reflectance vs. leaf-level LAI).\n\nüîπ 4. Quality Control\n\nFlagging: Use only high-quality satellite and in situ data (e.g., use quality flags to exclude cloud-contaminated pixels or questionable sensor readings).\n\nConsistency in Units and Calibration: Verify that data are in the same units and reference systems (e.g., radiance vs. reflectance, SI units).\n\nError Estimates: Consider measurement uncertainty and noise in both datasets.\n\nüîπ 5. Statistical Considerations\n\nMatchup Volume: A large number of matchup pairs increases robustness.\n\nBias and RMSE Analysis: Use metrics like bias, RMSE, and correlation to assess agreement.\n\nOutlier Handling: Identify and analyze outliers to understand limitations or failure modes.\n\nüîπ 6. Sensor Calibration\n\nEnsure both satellite and in situ instruments are properly calibrated and traceable to standards.\n\nüîπ 7. Geophysical Context\n\nGeographical Diversity: Validation should include diverse regions (e.g., open ocean, coastal, tropical, polar) to capture algorithm performance globally. In our example, we are only validating our product near Antarctica, so we should only use this product in that region.\n\nIn order to maximize the number of data matchups while still making a fair comparison, we need to determine an appropriate window in space and time. In our example, we set our spatial window to 1 km and our temporal window to half of a day:dist = 1.0\ntime_add = 0.5\n\n# Landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\n\n# Paths\nbasepath = Path('/home/jovyan/landsatproduct-cookbook')\nlsatpath = basepath / 'Data'\natmpath = lsatpath / 'AtmCorrection'\nmodout_path = lsatpath / 'MOD07_L2'\nSSTpath = lsatpath / 'SST/Validation/iQuamIntercomp/'\niQpath = lsatpath / 'iQuam'\n\nWV = 'Water_Vapor'\n\n# For geopandas and tile plots\nsatellite = 'Landsat8'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1\ncolnm = ['landsat:wrs_path','landsat:wrs_row']\ngjson_outfile = lsatpath / f'{satellite}_iQuam.geojson'\n\n# Buffer around iquam point used to create a bounding box for Landsat sample\ndist = 1.0 # km\n\n# Temporal search range (days) before/after iquam measurement for finding Landsat image\ntime_add = 0.5\n\nlthresh = -1.9\n\ninterp = 1\n\nimport s3fs\n\njetstream_url = 'https://js2.jetstream-cloud.org:8001/'\n\ns3 = s3fs.S3FileSystem(anon=True, client_kwargs=dict(endpoint_url=jetstream_url))\n\n# Generate a list of all files in CESM folder\ns3path = 's3://pythia/landsat8/iQuam/202009-STAR-L2i_GHRSST-SST-iQuam-V2.10-v01.0-fv04.0.nc'\n\ns3file = s3.open(s3path)\n\n# # Open with xarray\nds = xr.open_dataset(s3file)\n\n# Year and months desired (multiple years)\nstart_yr = 2013\nend_yr = 2023\n\n# Note these will get months from the later part of the year to early next\nstart_mo = '09'\nend_mo = '03'\n\n# Headers for the saved outputs\nheaders = ['DateTime','L8_filename','L8_SST','L8_std','center','N','S','E','W','NE','SE','NW','SW','L8_SST_max','L8_SST_min','Argo_id','Argo_SST','A_lat','A_lon']\n\n# Desired projection transformation\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the Landsat file\n\nNow we‚Äôre ready to find our matchups!\n\nWe‚Äôre repeating the retrieval step for the locations where we have data matchups.\n\n%%time\n\n# Multiple years\n\n# Set up projections\ntransformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)\n\n# Get iQuam file paths in directory between desired dates and find and produce matching Landsat SSTs \nfor year in range(start_yr, end_yr):  \n    yrmo = []\n    start_yrmo = f\"{year}{start_mo}\"  # Start from September of the current year\n    end_yrmo = f\"{year+1}{end_mo}\"  # End in March of the next year\n\n    m0 = start_yrmo\n    \n    # Make a list of months between start and end\n    while int(m0) <= int(end_yrmo):\n        calc_dt = datetime.strptime(f'{m0[:4]}-{m0[4:]}', '%Y-%m')\n        yrmo.append(calc_dt.strftime(\"%Y%m\"))\n        m0 = (calc_dt + relativedelta(months=1)).strftime(\"%Y%m\")\n    \n    # Get file names and select only those matching dates from yrmo    \n    iQfiles = os.listdir(iQpath)\n    iQfiles = [x for x in iQfiles if x[:6] in yrmo]\n    iQfiles.sort(reverse=True)\n    print (f'{year}: {len(iQfiles)}')\n    \n    os.chdir(iQpath)\n\n    # For each iquam file, pair West Antarctic Argo buoy data with Landsat data and create calibrated SSTs\n    valid = []\n    \n    for iquam_file in iQfiles:\n        # Open Argos data from iQuam file\n        df = xr.open_dataset(s3file)\n        iquam = df.to_dataframe()\n        \n        # Subset to Antarctica\n        ant = iquam[(iquam.lat<-65)&(iquam.lon>-142)&(iquam.lon<-72)&(iquam.platform_type==5.0)&(iquam.quality_level==5.0)]  # Entire West Antarctica (later)\n        # ant = iquam[(iquam.lat<-69)&(iquam.lon>-125)&(iquam.lon<-98)&(iquam.platform_type==5.0)&(iquam.quality_level==5.0)] # Amundsen Sea\n        \n        # To remove a landsat day that is coming up with a 403 error\n        if ant['year'].iloc[0] == 2020 and ant['month'].iloc[0] == 12:\n            ant = ant[ant.day != 9.0] # for 202012 because otherwise will fail\n        \n        print('')\n        print(f'{iquam_file[:6]}: {ant.shape[0]} measurements')\n    \n        for idx in tqdm(range(ant.shape[0]), desc=\"Processing\"):\n    \n            # Create search area\n            ilat = ant['lat'].iloc[idx]\n            ilon = ant['lon'].iloc[idx]\n    \n            lat_add = sut.km_to_decimal_degrees(dist, ilat, direction='latitude')\n            lon_add = sut.km_to_decimal_degrees(dist, ilat, direction='longitude')\n            bboxV = (ilon-lon_add,ilat-lat_add,ilon+lon_add,ilat+lat_add)\n    \n            # Create Landsat temporal search range in correct format\n            ihr = int(ant.hour.iloc[idx])\n            iyr = int(ant.year.iloc[idx])\n            imo = int(ant.month.iloc[idx])\n    \n            calc_dt = datetime.strptime(f'{iyr}-{imo}-{int(ant.day.iloc[idx])} {ihr}', '%Y-%m-%d %H')\n            start_dt = (calc_dt + timedelta(days=-time_add)).strftime('%Y-%m-%dT%H:%M:%SZ')\n            end_dt = (calc_dt + timedelta(days=time_add)).strftime('%Y-%m-%dT%H:%M:%SZ')\n    \n            timeRangeV = f'{start_dt}/{end_dt}'\n    \n            # Search for desired Landsat scenes\n            items = sut.search_stac(url,collection,gjson_outfile=gjson_outfile,bbox=bboxV,timeRange=timeRangeV)\n    \n            # Load the geojson file and open stac catalog\n            catalog = intake.open_stac_item_collection(items)\n            gf = gpd.read_file(gjson_outfile)\n    \n            # Exclude Landsat 9\n            catalog_list = [x for x in items if x.id[3]=='8']\n            num_scene = len(catalog_list)\n            # print(f'{num_scene} Landsat 8 items')\n    \n            # If any matching landsat scenes are found create calibrated SSTs for them\n            if num_scene>0:\n    \n                # Reproject to determine bounding box in espg 3031\n                sbox,checkbox = sut.lsat_reproj(source_crs,target_crs,(bboxV[0],bboxV[1],bboxV[2],bboxV[3]))\n    \n                # Create polygon for later cropping\n                polygon = Polygon([(sbox[0][0],sbox[0][1]),(sbox[3][0],sbox[3][1]),(sbox[2][0],sbox[2][1]),(sbox[1][0],sbox[1][1])])\n                \n                # Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\n                minx, miny, maxx, maxy = polygon.bounds\n                polarx = [minx, maxx]\n                polary = [miny, maxy]\n    \n                # Create calibrated SSTs for each matching landsat scene\n                for sceneid in catalog_list:\n                    print(sceneid.id)\n    \n                    scene = catalog[sceneid.id]\n                    timestr = scene.metadata['datetime'].strftime('%H%M%S')\n    \n                    outFile = f'{SSTpath}/{sceneid.id}_{timestr}_Cel.tif'\n    \n                    if os.path.isfile(outFile):\n                        print (f'{sceneid.id} - atm corr exists')\n                        ls_scene = xr.open_dataset(outFile,chunks=dict(x=512, y=512),engine='rasterio')\n                        ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n    \n                        # Subset all scenes and check for right dimensions because y order changes sometimes\n                        ls_sub = sut.subset_img(ls_scene['band_data'].sel(band=1),polarx,polary) # subset so easier to work with\n    \n                    else:\n                        # try:\n                        # Open all desired bands for one scene\n                        ls_scene = sut.landsat_to_xarray(sceneid,catalog)\n                        ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n        \n                        # Create classification mask\n                        ls_scene = sut.create_masks(ls_scene, cloud_mask=True, ice_mask=True, ocean_mask=True)\n\n                        # Check for any open ocean pixels - go to next image if none - ??? s\n                        mask = np.ones(ls_scene.shape[1:])\n                        mask[ls_scene.mask!=3] = np.nan\n                        ls_thermal = ls_scene.sel(band='lwir11').compute()\n\n                        # Check in bounding box or for entire Landsat image depending on whether doing calibration runs or not\n                        ls_box = sut.subset_img(ls_thermal*mask,polarx,polary)\n\n                        if ((ls_box).notnull()).sum().values==0:\n                            print (f'{sceneid.id} has no SSTs')\n                            try:\n                                del ls_scene, scene, mask, ls_thermal, ls_box\n                            except:\n                                pass\n                            gc.collect()\n                            continue\n\n                        # Use band ratios for RF cloud pixel classification\n                        ####\n\n                        # Atmospheric correction using MODIS\n                        # Acquire and align MODIS water vapor (MOD/MYD07) to Landsat\n                        mod07,modfilenm = sut.open_MODIS(ls_scene,scene,modout_path)\n                        print(\"1\")\n\n                        # Create water vapor files aligned and subsampled to Landsat\n                        spacing = [300,-300] # 300m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\n                        WV_xr = sut.get_wv(ls_scene,mod07,spacing,WV,scene,interp=interp)\n                        print(\"2\")\n                        # Create SST by masking and using water vapor to apply atmospheric correction\n                        SST = sut.apply_retrieval(ls_thermal,scene,mask,WV_xr,atmcor,simT_transformer,simTOA_transformer,simWV_transformer)\n\n                        # Record MODIS water vapor image used in atmospheric correction, will find this info save under band_data in\n                        # data variables in COG (click on white paper info button in xarray readout)\n                        SST.attrs['MODIS_WV'] = modfilenm\n\n                        # Save to a cloud-optimized Geotiff\n                        SST.rio.to_raster(raster_path=outFile, driver=\"COG\")\n                        print (f'Mean SST: {np.nanmean(SST)}')\n\n                        # Subset all scenes and check for right dimensions because y order changes sometimes\n                        ls_sub = sut.subset_img(SST,polarx,polary) # subset so easier to work with \n\n                        try:\n                            del mask, ls_thermal, mod07, WV_xr, SST\n                        except:\n                            pass\n    \n                        # except Exception as e:\n                        #     print (sceneid.id, e)\n                        #     lsat = np.nan\n                        #     lstd = np.nan\n    \n                    # Crop data to exact bounding box\n                    ls_sub = sut.crop_xarray_dataarray_with_polygon(ls_sub, polygon) \n    \n                    # Calibrate using MODIS\n                    ls_sub = ls_sub * calib_m + calib_b\n    \n                    # Remove all pixels that are too cold\n                    ls_sub = ls_sub.where(ls_sub>=lthresh,np.nan)\n    \n                    lsat = np.around(np.nanmean(ls_sub),2)\n                    lstd = np.around(np.nanstd(ls_sub),2)\n    \n                    # Convert Argo lat/lon to Landsat's EPSG:3031\n                    argo_px, argo_py = transformer.transform(ilon, ilat)\n    \n                    # 1) Find the nearest center pixel\n                    center_val = ls_sub.sel(x=argo_px, y=argo_py, method=\"nearest\")\n                    \n                    # Extract the x/y coordinate values as plain floats\n                    center_x = center_val.x.item()\n                    center_y = center_val.y.item()\n                    \n                    # 2) Get integer indices from the coordinate indexes\n                    #    This uses ls_sub.get_index('dim_name') -> pandas.Index -> get_indexer(...)\n                    center_x_idx = ls_sub.get_index(\"x\").get_indexer([center_x])[0]\n                    center_y_idx = ls_sub.get_index(\"y\").get_indexer([center_y])[0]\n                    \n                    # 3) Gather offsets for the 3x3 neighborhood\n                    offsets = [\n                        ( 0,  0, \"center\"),\n                        ( 0,  1, \"N\"),\n                        ( 0, -1, \"S\"),\n                        ( 1,  0, \"E\"),\n                        (-1,  0, \"W\"),\n                        ( 1,  1, \"NE\"),\n                        ( 1, -1, \"SE\"),\n                        (-1,  1, \"NW\"),\n                        (-1, -1, \"SW\"),\n                    ]\n                    \n                    neighbors = {}\n                    for dx, dy, name in offsets:\n                        nx = center_x_idx + dx\n                        ny = center_y_idx + dy\n                        # Ensure we're within the array bounds\n                        if (0 <= nx < ls_sub.sizes['x']) and (0 <= ny < ls_sub.sizes['y']):\n                            # xarray dimension order is typically (y, x), so use isel(y=ny, x=nx):\n                            neighbors[name] = ls_sub.isel(y=ny, x=nx).values.item()\n                        else:\n                            neighbors[name] = np.nan\n                    \n                    # 4) Record coincident data from Landsat and Argo float\n                    argo_temp = np.around((ant.sst.iloc[idx] - 273.15),2)  # convert to Celsius\n                    times = pd.to_datetime(calc_dt, format='%Y%m%d%H')  # standardize time\n                    \n                    valid.append([\n                        times,\n                        sceneid.id,\n                        lsat,\n                        lstd,\n                        neighbors['center'],\n                        neighbors['N'],\n                        neighbors['S'],\n                        neighbors['E'],\n                        neighbors['W'],\n                        neighbors['NE'],\n                        neighbors['SE'],\n                        neighbors['NW'],\n                        neighbors['SW'],\n                        ls_sub.max().values.item(),\n                        ls_sub.min().values.item(),\n                        ant.iloc[idx].name,  # Argo ID or whichever label you prefer\n                        argo_temp,\n                        ilat,\n                        ilon\n                    ])\n                    print (f'Argo temp: {argo_temp}, Landsat 8 mean: {lsat}+/-{lstd}')\n    \n                    try:\n                        del ls_scene, scene, ls_thermal, ls_box, mod07, WV_xr, SST, ls_sub, neighbors\n                    except:\n                        pass\n    \n                    gc.collect()\n\n    # Put data into DataFrame and save    \n    lsat_mod_df = pd.DataFrame(valid,columns=headers)\n    out_df = lsatpath / f'Landsat_validation_{start_yrmo}_{end_yrmo}_{dist}.csv'\n    lsat_mod_df.to_csv(out_df)\n\n","type":"content","url":"/notebooks/validation#finding-data-matchups","position":9},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Landsat-iQUAM validation assessment","lvl3":"Finding data matchups"},"type":"lvl4","url":"/notebooks/validation#landsat-iquam-validation-assessment","position":10},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Landsat-iQUAM validation assessment","lvl3":"Finding data matchups"},"content":"\n\n# Read in processed matchups\n\n# 20250107 is threshold=-1.9, 20250114 is thresh=-1.94, 20250205 is thresh=-1.9\nout_df = lsatpath / 'Landsat_validation_202009_202103_1.0.csv'\nvalids = pd.read_csv(out_df)\n\nvalids = valids.set_index('DateTime')\nvalids = valids.sort_index()\nvalids['Argo_id'] = valids['Argo_id'].astype(int)\n\n# Remove the non-numeric column for calculating daily means\nnumeric_valids = valids.select_dtypes(include=[np.number])\nvalidmn = numeric_valids.groupby(numeric_valids['Argo_id']).mean()\nvalids = valids.reset_index()\n\n# Group by the date component of the datetime and calculate the difference\nvalids['temp_dif'] = valids.groupby(valids['Argo_id'])[f'L8_SST'].diff()\nvalidmn['temp_dif'] = valids.groupby(valids['Argo_id'])['temp_dif'].first()\nvalids = valids.set_index('DateTime')\n\nvalidmn['std'] = valids.groupby([valids['Argo_id']])[f'L8_SST'].std()\nvalidmn['xaxis'] = pd.to_datetime(validmn.index).dayofyear\nvalidmn['xaxis'][validmn['xaxis']<(365/2)] = validmn['xaxis'] + 365\n\nvalids['xaxis'] = pd.to_datetime(valids.index).dayofyear\nvalids['xaxis'][valids['xaxis']<(365/2)] = valids['xaxis'] + 365\n\nvalidmn = validmn.dropna(subset=['L8_SST'])\n\nvalids\n\n","type":"content","url":"/notebooks/validation#landsat-iquam-validation-assessment","position":11},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Visualize all validation matchups for manual QC","lvl3":"Finding data matchups"},"type":"lvl4","url":"/notebooks/validation#visualize-all-validation-matchups-for-manual-qc","position":12},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Visualize all validation matchups for manual QC","lvl3":"Finding data matchups"},"content":"\n\n# Setup and authenticate \nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient\n\npwd\n\nos.chdir(lsatpath)\nlsatfiles = os.listdir(lsatpath)\nlsatfiles = [i for i in lsatfiles if i[0]=='L']\n\n# Remove all files from the list with repeats and Landsat mean = nan\nremove = [\n'LC08_L1GT_029109_20160922_20200906_02_T2', \n'LC08_L1GT_022110_20181029_20201016_02_T2', \n'LC08_L1GT_005110_20181209_20201016_02_T2',\n'LC08_L1GT_228108_20200123_20201016_02_T2',\n'LC08_L1GT_001108_20200929_20201006_02_T2',\n'LC08_L1GT_002109_20201022_20201105_02_T2',\n'LC08_L1GT_233108_20201109_20210317_02_T2',\n'LC08_L1GT_233109_20201109_20210317_02_T2',\n'LC08_L1GT_001109_20201202_20210312_02_T2',\n'LC08_L1GT_027112_20220128_20220204_02_T2',\n'LC08_L1GT_002109_20210331_20210408_02_T2'\n]\n\nlsatfiles = [i for i in lsatfiles if i[:-15] not in remove]\nif len(lsatfiles)!=12:\n    print('Wrong number of Landsat scenes!!!')\n\n# Number of columns/rows for subplots\nn_cols = 3\nn_rows = 4\n\n# Create one figure and a 4x7 grid of subplots\n# The figsize is 10 across; adjust height as needed for clarity\nfig, axes = plt.subplots(\n    nrows=n_rows,\n    ncols=n_cols,\n    figsize=(11, 8.5),   \n    subplot_kw={'projection': ccrs.PlateCarree()}\n)\n\n# Optional: if you want them *really* close, you can fine-tune spacing:\nplt.subplots_adjust(wspace=0.05, hspace=0.03)\n# plt.subplots_adjust(bottom=0.15)\n\n# Counter for subplot index, and a handle to store the last \"imshow\" (for colorbar)\ni = 0\nim_obj = None\n\nfor lsatfile in lsatfiles:\n    lsID = lsatfile\n    print(lsID)\n    \n    mrow = valids[valids['L8_filename'].str.contains(lsatfile[:-15])]\n    \n    for idx, row in mrow.iterrows():\n        # Check if L8_SST is NaN\n        if pd.isnull(row['L8_SST']):\n            # If it is NaN, skip this iteration and do not plot\n            continue\n        \n        # --- Prepare data and coordinates ---\n        ilat = row['A_lat']\n        ilon = row['A_lon']\n        \n        lat_add = km_to_decimal_degrees(dist, ilat, direction='latitude')\n        lon_add = km_to_decimal_degrees(dist, ilat, direction='longitude')\n        xmin, ymin, xmax, ymax = (ilon - lon_add, ilat - lat_add, \n                                  ilon + lon_add, ilat + lat_add)\n        \n        # Load the Landsat file\n        ds = xr.open_dataset(lsatfile, chunks=dict(x=512, y=512), engine='rasterio')\n        ls_scene = ds['band_data'].sel(band=1).rio.write_crs(\"epsg:3031\", inplace=True)\n        \n        # Assign time coordinate\n        times = pd.to_datetime(lsatfile[17:25] + lsatfile[41:47], format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times, ID=lsatfile[:-8])\n        \n        # Reproject to EPSG:4326\n        ls_scene = ls_scene.rio.reproject(\"EPSG:4326\")\n\n        # Calibrate using MODIS\n        ls_scene = ls_scene * calib_m + calib_b\n\n        # Remove all pixels that are too cold\n        ls_scene = ls_scene.where(ls_scene>=lthresh,np.nan)\n        \n        # Select the subplot axis\n        ax = axes[i // n_cols, i % n_cols]\n        \n        # Plot on that axis, without a colorbar\n        # Store the \"imshow\" result in im_obj so we can build one colorbar later\n        im_obj = ls_scene.plot.imshow(\n            x='x', y='y',\n            vmin=-2.0, vmax=1.5,\n            ax=ax,\n            transform=ccrs.PlateCarree(),\n            origin='upper',\n            add_colorbar=False  # <- No individual colorbar\n        )\n        \n        # Remove titles completely (xarray may add one by default)\n        ax.set_title('')\n        \n        # Set extent\n        ax.set_extent([ilon - 0.4, ilon + 0.4, ilat - 0.2, ilat + 0.2], crs=ccrs.PlateCarree())\n        \n        # Argo observation\n        ax.scatter([ilon], [ilat], c='r', s=3, transform=ccrs.PlateCarree(), label='Argo location')\n        \n        # Draw bounding box\n        polygon_show = Pgon([(xmin, ymin), (xmin, ymax), \n                             (xmax, ymax), (xmax, ymin)],\n                            closed=True, edgecolor='red', facecolor='none')\n        ax.add_patch(polygon_show)\n        \n        # Text label\n        text_str = (\n            f\"Argo ID: {row['Argo_id']}\\n\"\n            f\"Argo Temp: {np.around(row['Argo_SST'], 2)}\\n\"\n            f\"Landsat SST: {np.around(row['L8_SST'], 2)}\"\n        )\n        ax.text(\n            0.02, 0.95,\n            text_str,\n            transform=ax.transAxes,\n            fontsize=10,\n            va='top',\n            ha='left'\n        )\n\n        gc.collect()\n        \n        # Move to next subplot index\n        i += 1\n        \n\n# --- Add a single colorbar for the entire figure ---\n# We use the last \"imshow\" (im_obj) and attach to all subplot axes\ncbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.03])\n\ncbar = fig.colorbar(\n    im_obj, \n    ax=axes.ravel().tolist(),  # or just ax=axes if axes is 2D\n    cax=cbar_ax,\n    orientation='horizontal',  # 'vertical' or 'horizontal'\n    fraction=0.025,            # how long the colorbar is relative to axes\n    pad=0.05                   # space between colorbar and subplots\n)\ncbar.set_label(\"Temperature [¬∞C]\", fontsize=12)\n\n# plt.tight_layout()\nplt.show() \n\n","type":"content","url":"/notebooks/validation#visualize-all-validation-matchups-for-manual-qc","position":13},{"hierarchy":{"lvl1":"Validating your data product","lvl2":"Use matchups to compare modeled and observed data"},"type":"lvl2","url":"/notebooks/validation#use-matchups-to-compare-modeled-and-observed-data","position":14},{"hierarchy":{"lvl1":"Validating your data product","lvl2":"Use matchups to compare modeled and observed data"},"content":"Here, we are going to use a linear regression\n\n# Remove low quality validation data from the valids data\nrm_ids = [1460597, 1614080, 2143782, 2016236, 1790883]\nrm = validmn[validmn.index.isin(rm_ids)]\nvalidmn = validmn.drop(index=rm_ids, errors='ignore')\nvalids = valids[~valids['Argo_id'].isin(rm_ids)]\n\n# Orthoganal Regression \ndata = validmn\n\n# Original data\nx_original = np.array(data['Argo_SST'])\ny_original = np.array(data['L8_SST'])\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model\nlinear = Model(linear_model)\n\n# Create a RealData object using your DataFrame\ndata = RealData(x_original, y_original)\n\n# Set up ODR with the model and data\nodr = ODR(data, linear, beta0=[1., 0.])\n\n# Run the regression\nout = odr.run()\n\n# Use the output\nbeta = out.beta\nbeta_err = out.sd_beta\n\n# Print the summary\nout.pprint()\n\n# Predicting values using the ODR model\ny_pred = linear_model(beta, x_original)\n\n# Get R2\n# Calculate Total Sum of Squares (SST)\ny_mean = np.mean(y_original)\nSST = np.sum((y_original - y_mean)**2)\n\n# Calculate Residual Sum of Squares (SSR)\nSSR = np.sum((y_original - y_pred)**2)\n\n# Compute RMSE\nrmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n\n# Calculate R^2\nR2 = 1 - (SSR / SST)\nprint(\"R^2:\", np.around(R2,2))\nprint(f\"RMSE: {np.around(rmse,2)}\")\n\nbeta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\nbeta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\nbeta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\nbeta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\nprint(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\nxfill = np.array([-4.3,0.9])\n\n\n# Plot data points and 1:1 line\nfig, ax = plt.subplots(figsize=(5, 4))\nax.tick_params(labelsize=14)\n\nxi = np.arange(-7.0,5.0,1.0)\n\n# lower_err = abs(data['L8_SST'] - data['L8_SST_min'])  # distance to lower bound\n# upper_err = abs(data['L8_SST_max'] - data['L8_SST'])  # distance to upper bound\n\nax.scatter(x_original,y_original,color='k',linewidth=0,s=35,label='High quality')\nax.errorbar(x_original,y_original,yerr=validmn['std'],color='k',fmt='o',ecolor='k',elinewidth=1,capthick=1,marker='o',ms=3,capsize=5,label='_no legend_')\n# ax.errorbar(data['Argo_SST'],data['L8_SST'],yerr=[lower_err,upper_err],color='k',fmt='o',ecolor='k',elinewidth=1,capthick=1,marker='o',ms=3,capsize=5,label='_no legend_')\n# ax.scatter(data['Argo_SST'],data['center'],color='r',linewidth=0,s=25,label='_no label_')\nax.scatter(rm['Argo_SST'],rm['L8_SST'],color='0.7', s=35, label='Removed',zorder=2)\nax.plot(xi,xi,color='k',linewidth=2, label='1:1')\nax.plot(x_original, y_pred, color='k', ls=':', label='Validation ODR')\nax.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.1, facecolor='0.3')\n# a1.plot(xi,xi*lreg.coef_[0]+lreg.intercept_[0],color='r',linewidth=2,label='RANSAC regression')\n# a1.scatter(xC,yLC,color='r',linewidth=0,s=35,label='_no label_')\n# a1.plot(xi,xi*resultC.params.L8_SST+resultC.params.Intercept,color='k',linewidth=2,label='OLS regression')\n# a1.text(-2.1,-2.85,f'y={np.around(resultC.params.L8_SST,2)}x+{np.around(resultC.params.Intercept,2)}   p={p_val}',fontsize=12)\nax.text(-1.1,-1.5,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_ylim([-1.95,1.5])\nax.set_xlim([-1.95,1.5])\nax.set_xlabel('Argo Temperature [¬∞C]',fontsize=16)\nax.set_ylabel('Landsat SST [¬∞C]',fontsize=16)\nax.legend(markerscale=1,fontsize=12,loc='upper left')\n\nplt.tight_layout()\n# plt.savefig('/Users/tsnow03/GoogleDrive/User/Docs/PhD_Project/Manuscripts/AmundsenCC_Manuscript/Figures/LMCalibration.jpg', format='jpg', dpi=1000)\nplt.show()","type":"content","url":"/notebooks/validation#use-matchups-to-compare-modeled-and-observed-data","position":15}]}