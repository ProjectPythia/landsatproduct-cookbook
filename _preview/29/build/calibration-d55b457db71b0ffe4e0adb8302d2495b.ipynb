{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Calibration\n",
    "authors:\n",
    "  - name: Jianwen Du\n",
    "    affiliations:\n",
    "      - id: UoA\n",
    "        institution: University of Arizona\n",
    "        department: Hydrology and Atmospheric Sciences\n",
    "license: Apache 2.0\n",
    "date: 2025-08-08\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Why Calibrate? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration of a physical model is the process of tuning its parameters to ensure its outputs accurately match real-world measurements. It's about bridging the gap between theoretical calculations and physical reality.\n",
    "\n",
    "<div style=\"background-color:#E3F2FD; border-left: 5px solid #2196F3; padding: 15px; font-family:sans-serif;\">\n",
    "<b>Key Goal:</b> The primary goal is to improve predictive accuracy, transforming a model from a theoretical construct into a reliable tool for analysis and design.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù What Do You Need? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calibrate a model, you need four key components:\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; gap: 10px; font-family: sans-serif;\">\n",
    "  <div style=\"flex: 1; min-width: 200px; border: 1px solid #ccc; border-radius: 5px; padding: 10px; background: #fafafa;\"><b>1. A Physical Model</b><br>A set of mathematical equations or simulation software.</div>\n",
    "  <div style=\"flex: 1; min-width: 200px; border: 1px solid #ccc; border-radius: 5px; padding: 10px; background: #fafafa;\"><b>2. Tunable Parameters</b><br>The specific \"knobs\" in your model that you can adjust.</div>\n",
    "  <div style=\"flex: 1; min-width: 200px; border: 1px solid #ccc; border-radius: 5px; padding: 10px; background: #fafafa;\"><b>3. Experimental Data</b><br>High-quality measurements from the real-world system.</div>\n",
    "  <div style=\"flex: 1; min-width: 200px; border: 1px solid #ccc; border-radius: 5px; padding: 10px; background: #fafafa;\"><b>4. An Objective Function</b><br>A metric that quantifies the error (e.g., RMSE).</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è How to Calibrate? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main approaches to calibration: by hand (trial and error) or by using a smart computer search (optimization algorithms). Optimization is highly recommended for its efficiency and accuracy.\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to see details on different optimization methods</b></summary>\n",
    "<div style=\"background-color:#E8F5E9; border-left: 5px solid #4CAF50; margin-top:10px; padding: 15px; font-family:sans-serif;\">\n",
    "\n",
    "- **Gradient-Based Methods:** Use the error gradient for efficient searching (e.g., Levenberg-Marquardt).\n",
    "- **Gradient-Free Methods:** Do not require gradients, essential for \"black-box\" simulations (e.g., Nelder-Mead).\n",
    "- **Bayesian Calibration:** Treats parameters as probability distributions to quantify uncertainty.\n",
    "- **Cross-Calibration:** Calibrates one model against a trusted reference model to ensure consistency.\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ How Do You Know It's Calibrated? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful calibration can be verified by analyzing the errors and by validating the model against new data. A common way to visualize the result is by plotting the model's output against the experimental data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Example: Adjusting Model Parameters\n",
    "\n",
    "To make this concept interactive, you can run the code cell below. It will create the same plot but with sliders that let you manually adjust the model's parameters (`slope` and `intercept`). Try to move the sliders to make the red line fit the blue dots. This gives you a hands-on feel for the \"By Hand\" calibration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's install ipywidgets for the interactive sliders\n",
    "#%pip install -q ipywidgets\n",
    "#%pip install -q scikit-image\n",
    "#%pip install seaborn\n",
    "# %pip install plotly\n",
    "%pip install xarray==2024.05.0\n",
    "import earthaccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "# 1. Create the sample \"Experimental Data\"\n",
    "np.random.seed(0)\n",
    "x_data = np.linspace(0, 10, 20)\n",
    "true_slope = 2.5\n",
    "true_intercept = 1.5\n",
    "y_data = true_slope * x_data + true_intercept + np.random.normal(0, 2, size=x_data.shape)\n",
    "\n",
    "# 2. Define a function to plot the data and our adjustable model\n",
    "def plot_model(x, y, slope, intercept):\n",
    "    \"\"\"Plots the experimental data against the model line defined by slope and intercept.\"\"\"\n",
    "    y_model = slope * x + intercept\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, y, 'o', label='Experimental Data', markersize=8, color='royalblue')\n",
    "    plt.plot(x, y_model, '-', label='Adjustable Model', linewidth=3, color='red')\n",
    "    \n",
    "    # Calculate and display the RMSE as our objective function score\n",
    "    rmse = np.sqrt(np.mean((y - y_model)**2))\n",
    "    plt.title(f'Comparison of Model vs. Data (RMSE: {rmse:.2f})', fontsize=16)\n",
    "    \n",
    "    plt.xlabel('Independent Variable', fontsize=12)\n",
    "    plt.ylabel('Dependent Variable', fontsize=12)\n",
    "    plt.ylim(min(y_data)-2, max(y_data)+2)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# 3. Create the interactive plot!\n",
    "# The 'interact' function automatically creates sliders for the numerical arguments.\n",
    "interact(plot_model, x=fixed(x_data), y=fixed(y_data), slope=(0.0, 5.0, 0.1), intercept=(-5.0, 5.0, 0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Landsat calibration using MODIS SST\n",
    "Create matchups between Landsat and MODIS SST data near Cosgrove, West Antarctica\n",
    "to produce a calibration for Landsat SSTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib widget\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.pylab import rcParams\n",
    "from matplotlib.patches import Polygon as Pgon\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "\n",
    "import os\n",
    "from cycler import cycler\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from sklearn.neighbors import BallTree\n",
    "import pytz\n",
    "import pygmt\n",
    "import gc\n",
    "import copy\n",
    "import random\n",
    "import statsmodels.formula.api as sm\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pathlib import Path\n",
    "import math\n",
    "from scipy.odr import Model, RealData, ODR\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import earthaccess\n",
    "\n",
    "# For LST file masking\n",
    "import pystac_client\n",
    "import intake\n",
    "from rasterio.session import AWSSession\n",
    "import boto3\n",
    "\n",
    "import SSTutils as stu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For color cycling in plots that is color blind friendly...make new ones at \"I want hue\" tools.medialab.sciences-po.fr/iwanthue\n",
    "color_cycler = cycler(color=[\"#6777cf\",\"#adba49\",\"#c65ca0\",\"#5fa042\",\"#683287\",\"#72ce7b\",\"#c44a48\",\"#45c7a9\",\"#933c1d\",\"#d0803f\",\"#ac9239\",\"#317c39\"])\n",
    "colorline_cycler = (cycler(color=[\"#75a141\",\"#6c61b9\",\"#bc4d45\",\"#c1913d\",\"#b85298\",\"#4aa8e8\"]) +\n",
    "                 cycler(linestyle=['-','--',':','-.','-','--']))\n",
    "rcParams['axes.prop_cycle'] = cycler('color', color_cycler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Landsat - MODIS SST matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set paths and important variables and Calibration region bounding box\n",
    "\n",
    "basepath = Path('/home/jovyan/landsatproduct-cookbook')\n",
    "spacing = [990,-990] # 990m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\n",
    "param = 'sea_surface_temperature'\n",
    "size_threshold = 30\n",
    "\n",
    "location = 0             # 0 and 1 are the Cosgrove and Dotson Polynya calibration areas, respectively\n",
    "surf_temp = 'SST'        # 'SST' and 'LST' are for the Landsat SST and LST algorithms respectively\n",
    "\n",
    "# Set location bounds\n",
    "if location==1:\n",
    "    pathdir = 'DotsonPolynya'\n",
    "    latboundsC = [ -73.9 , -73.5 ] # Dotson polynya\n",
    "    lonboundsC = [ -113 , -111.5 ]\n",
    "    dfloc = 'Dotson'\n",
    "elif location==0:\n",
    "    pathdir = 'Cosgrove'\n",
    "    latboundsC = [ -73.5 , -73.42 ] # near Cosgrove\n",
    "    lonboundsC = [ -103.0 , -102.0 ]\n",
    "    dfloc = 'Cosgrove'\n",
    "elif location==2:\n",
    "    pathdir = 'Burke'\n",
    "    latboundsC = [ -73.81 , -73.42 ] # south of Burke\n",
    "    lonboundsC = [ -104.2 , -103.8 ]\n",
    "    dfloc = 'Burke'\n",
    "if location==3:\n",
    "    pathdir = 'DotsonIntercomp'\n",
    "    latboundsC = [ -74.2 , -74.11 ] # Dotson plume for intercomparison\n",
    "    lonboundsC = [ -113.5 , -113.17 ]\n",
    "    dfloc = 'DotsonIntercomp'\n",
    "\n",
    "# Coefficients for calibration\n",
    "# SST\n",
    "sstcalib_m = 0.76 \n",
    "sstcalib_b = 0.55 \n",
    "\n",
    "# LST\n",
    "lstcalib_m = 0.80\n",
    "lstcalib_b = 1.00\n",
    "\n",
    "modmin = -1.9\n",
    "LSTmin = np.around(modmin/lstcalib_m - lstcalib_b,2) \n",
    "SSTmin = np.around(modmin/sstcalib_m - sstcalib_b,2) # should be about -2.0\n",
    "\n",
    "# Uncertainties used in ODR propagation of error\n",
    "modis_uncertainty = 0.44  # long wave sst ocean color atbd\n",
    "sst_uncertainty = 0.3 # USGS Landsat stray light notice\n",
    "lst_uncertainty = 1.0 # gerace 2020\n",
    "pix_uncertainty = np.sqrt((1000*1000)/(100*100)) # MODIS 1km x 1km and Landsat 100m x 100m\n",
    "\n",
    "\n",
    "# For calibrated SST runs\n",
    "if surf_temp=='SST':\n",
    "    if location==3:\n",
    "        sstpath = basepath / f'Data/SST/Validation/{pathdir}/'\n",
    "    else:\n",
    "        sstpath = basepath / f'Data/SST/MODcalib/{pathdir}/'\n",
    "    tif = 'tif'\n",
    "    thresh = SSTmin\n",
    "    calib_m = sstcalib_m\n",
    "    calib_b = sstcalib_b\n",
    "    \n",
    "# If running for LST comparisons\n",
    "elif surf_temp=='LST':\n",
    "    if location==3:\n",
    "        sstpath = basepath / f'Data/SST/LST/Calibration/DotsonPolynya/'\n",
    "    else:\n",
    "        sstpath = basepath / f'Data/SST/LST/Calibration/{pathdir}/'\n",
    "    tif = 'TIF'\n",
    "    thresh = LSTmin\n",
    "    calib_m = lstcalib_m\n",
    "    calib_b = lstcalib_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Authenticate for accessing NASA data (MODIS)\n",
    "auth = earthaccess.login(strategy=\"interactive\")\n",
    "\n",
    "# If we are not authenticated\n",
    "if not auth.authenticated:\n",
    "    # ask for credentials and persist them in a .netrc file\n",
    "    auth.login(strategy=\"interactive\", persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert bounding box to south polar stereo for checking if landsat has any data in bounding box\n",
    "# Speeds up process a lot\n",
    "source_crs = 'epsg:4326' \n",
    "target_crs = 'epsg:3031' # Coordinate system of the file   \n",
    "\n",
    "bbox,checkbox = stu.lsat_reproj(source_crs,target_crs,(lonboundsC[0],latboundsC[0],lonboundsC[1],latboundsC[1]))\n",
    "\n",
    "# Create polygon for later cropping\n",
    "polygon = Polygon([(bbox[0][0],bbox[0][1]),(bbox[3][0],bbox[3][1]),(bbox[2][0],bbox[2][1]),(bbox[1][0],bbox[1][1])])\n",
    "\n",
    "# Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\n",
    "minx, miny, maxx, maxy = polygon.bounds\n",
    "polarx = [minx, maxx]\n",
    "polary = [miny, maxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Landsat file paths in directory\n",
    "lsatfiles = os.listdir(sstpath)\n",
    "lsatfiles = [x for x in lsatfiles if x[-3:] == tif]\n",
    "lsatfiles.sort()\n",
    "print (len(lsatfiles))\n",
    "os.chdir(sstpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSTfails = [\n",
    " 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n",
    " 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n",
    "]\n",
    "LSTfails = [\n",
    " 'LC08_L1GT_007112_20211215_20211223_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_007112_20220201_20220211_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_007112_20221202_20221212_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_007112_20230204_20230209_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20220105_20220114_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20220121_20220128_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20221105_20221115_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20230108_20230124_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_010113_20230313_20230321_02_T2_SW_LST.TIF',\n",
    " 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for desired Landsat scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Authenticate for boto S3 access, etc.\n",
    "os.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\n",
    "aws_session = AWSSession(boto3.Session(), requester_pays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup and authenticate \n",
    "from dask.distributed import Client\n",
    "import logging\n",
    "client = Client(processes=True, n_workers=4, \n",
    "                threads_per_worker=1,\n",
    "                silence_logs=logging.ERROR)\n",
    "client.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the landsat STAC catalog location\n",
    "url = 'https://landsatlook.usgs.gov/stac-server'\n",
    "collection = 'landsat-c2l1' # Landsat Collection 2, Level 1 - includes L8 and L9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "ls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\n",
    "ls_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ~1 min 32 sec per image\n",
    "# If number of MODIS images per satellite is much more than 25, its because there is a ULY,LRY issue\n",
    "os.chdir('/home/jovyan/landsatproduct-cookbook/Data/SST/MODcalib/Cosgrove/')\n",
    "\n",
    "lsat_mod = []\n",
    "#for i in tqdm(range(len(lsatfiles)), desc=\"Processing\"):\n",
    "for i in tqdm(range(1), desc=\"Processing the first image\"):\n",
    "    # Check for known repeatedly bad files that will kill the code\n",
    "    if surf_temp == 'SST':    \n",
    "        if lsatfiles[i] in SSTfails:\n",
    "            continue\n",
    "    elif surf_temp == 'LST':\n",
    "        if lsatfiles[i] in LSTfails:\n",
    "            continue\n",
    "        \n",
    "    # Concatenate all landsat files into xarray with a time dimension\n",
    "    ls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\n",
    "    ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n",
    "    print(\"1\")\n",
    "    if surf_temp == 'SST':\n",
    "        times = pd.to_datetime(lsatfiles[i][17:25]+lsatfiles[i][41:47], format='%Y%m%d%H%M%S')\n",
    "        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-8])\n",
    "    elif surf_temp == 'LST':\n",
    "        # Need to mask LST because not done previously\n",
    "        mask = stu.get_lst_mask(lsatfiles[i])\n",
    "        ls_scene = ls_scene * mask\n",
    "        \n",
    "        times = pd.to_datetime(lsatfiles[i][17:25]+'120000', format='%Y%m%d%H%M%S')\n",
    "        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-4])\n",
    "        ls_scene = ls_scene - 273.15\n",
    "\n",
    "    # Subset scene and check that it has the correct dimensions because y order changes sometimes\n",
    "    ls_scene = stu.subset_img(ls_scene,polarx,polary) # subset so easier to work with\n",
    "    ls_scene = stu.crop_xarray_dataarray_with_polygon(ls_scene, polygon) # crop data to exact bounding box\n",
    "\n",
    "    # if location==3:\n",
    "    # # Calibrate\n",
    "    # ls_scene = ls_scene * calib_m + calib_b\n",
    "    \n",
    "    # # Remove SSTs that are unrealistically cool\n",
    "    # ls_scene = ls_scene.where(ls_scene >= thresh, np.nan)\n",
    "\n",
    "    lsID = lsatfiles[i]\n",
    "    print (lsID)\n",
    "    \n",
    "    # Take mean temp, will skip the modis stage if no Landsat data in the calibration region\n",
    "    try:\n",
    "        lsat = np.nanmean(ls_scene)\n",
    "        ls_num = ls_scene.notnull().values.sum()\n",
    "    except Exception as e:\n",
    "        print (lsID, e)\n",
    "        lsat = np.nan\n",
    "\n",
    "    print(lsat)\n",
    "    if ~np.isfinite(lsat):\n",
    "        continue\n",
    "\n",
    "    # Find coincident MODIS SST scene\n",
    "    mod_scene, mod_file,time_dif = stu.find_MODIS(lonboundsC,latboundsC,ls_scene)\n",
    "    print(mod_file)\n",
    "\n",
    "    try:\n",
    "        # Acquire and align MODIS data to Landsat\n",
    "\n",
    "        # To subset to only high quality MODIS temp measurements which doesn't seem to be useful\n",
    "        # print(mod_scene.quality_level.max().values)\n",
    "        # mod_temps = mod_scene.sea_surface_temperature.where(mod_scene.quality_level>=4)\n",
    "\n",
    "        MODsst_xr = stu.get_sst(ls_scene,mod_scene.sea_surface_temperature,spacing,param) #mod_scene.sea_surface_temperature\n",
    "\n",
    "        # Remove SSTs that are unrealistically cool\n",
    "        MODsst_xr = MODsst_xr.where(MODsst_xr >= -1.9, np.nan)\n",
    "\n",
    "        # Crop Landsat image to meet the slightly smaller MODIS image (smaller image results from upsample methods in get_wv2)\n",
    "        ls_scene = stu.subset_img(ls_scene,[MODsst_xr.x.min(),MODsst_xr.x.max()],[MODsst_xr.y.min(),MODsst_xr.y.max()])\n",
    "\n",
    "        # Only use MODIS data where cropped Landsat data is also available\n",
    "        MODsst_xr_sub = MODsst_xr.where(ls_scene.notnull(),np.nan)\n",
    "\n",
    "        # Take mean temp\n",
    "        modis = np.nanmean(MODsst_xr_sub)\n",
    "        MOD_num = MODsst_xr_sub.notnull().values.sum()\n",
    "    except Exception as e:\n",
    "        print (mod_file, e)\n",
    "        modis = np.nan\n",
    "        MOD_num = 0\n",
    "\n",
    "    # Take mean using Landsat data only where cropped MODIS data is also available (need to do both)\n",
    "    try:\n",
    "        ls_scene_sub = ls_scene.where(MODsst_xr_sub.notnull(),np.nan)\n",
    "        lsat = np.nanmean(ls_scene_sub)\n",
    "        ls_num = ls_scene_sub.notnull().values.sum()\n",
    "    except Exception as e:\n",
    "        print (lsID, e)\n",
    "        lsat = np.nan\n",
    "\n",
    "    # Append file names with SST means from the Cosgrove box\n",
    "    lsat_mod.append([times,mod_file,modis,MOD_num,lsID,lsat,ls_num,time_dif])\n",
    "    print (f'MODIS mean: {modis}, Landsat 8: {lsat}')\n",
    "\n",
    "    try:\n",
    "        del ls_scene, ls_sub, mod_scene, MODsst_xr, MODsst_xr_sub\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Put data into DataFrame and save    \n",
    "# headers = ['DateTime','MODIS_filename','MODIS_SST','MODIS_pix','L8_filename',f'L8_{surf_temp}','L8_pix','time_dif']\n",
    "# lsat_mod_df = pd.DataFrame(lsat_mod,columns=headers)\n",
    "# out_df = basepath / f'Data/MODISvLandsat_{surf_temp}_{dfloc}_20250500.csv'\n",
    "# lsat_mod_df.to_csv(out_df, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate calibration bias and trend\n",
    "Uses a [RANSAC regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html), but provides comparisons to an Ordinary Least Squares regression calculation from statsmodel of the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in paired MODIS/Landsat data created above\n",
    "surf_temp = 'SST'\n",
    "\n",
    "if surf_temp=='LST':\n",
    "    thresh = -3.5 # -3.4 is ok too\n",
    "    pix_thresh = 1300\n",
    "elif surf_temp=='SST':\n",
    "    thresh = -3.1\n",
    "    pix_thresh = 1300\n",
    "mod_sst_thresh = -1.9\n",
    "\n",
    "# For Cosgrove region\n",
    "if surf_temp=='LST':\n",
    "    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Cosgrove.csv'\n",
    "    df1 = pd.read_csv(out_df)\n",
    "    lsat_mod_df_C = df1\n",
    "else:   \n",
    "    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Cosgrove_lin_scale.csv' \n",
    "    df1 = pd.read_csv(out_df)\n",
    "    lsat_mod_df_C = df1\n",
    "\n",
    "print(f'Original # matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}')\n",
    "\n",
    "lsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_SST']>=mod_sst_thresh]\n",
    "lsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_pix']>=pix_thresh]\n",
    "lsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C[f'L8_{surf_temp}']>=thresh]\n",
    "\n",
    "# For Dotson polynya region\n",
    "if surf_temp=='LST':\n",
    "    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Dotson.csv'\n",
    "    df5 = pd.read_csv(out_df)\n",
    "    lsat_mod_df_D = df5\n",
    "else:\n",
    "    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Dotson_lin_scale.csv'  \n",
    "    df5 = pd.read_csv(out_df)\n",
    "    lsat_mod_df_D = df5\n",
    "\n",
    "print(f'Original # matchups at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}')\n",
    "\n",
    "lsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_SST']>=mod_sst_thresh]\n",
    "lsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_pix']>=pix_thresh]\n",
    "lsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D[f'L8_{surf_temp}']>=thresh]\n",
    "\n",
    "# For Burke region\n",
    "if surf_temp=='LST':\n",
    "    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Burke.csv'\n",
    "    df9 = pd.read_csv(out_df)\n",
    "    lsat_mod_df_B = df9\n",
    "else:\n",
    "    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Burke_lin_scale.csv'\n",
    "    df9 = pd.read_csv(out_df)\n",
    "    lsat_mod_df_B = df9\n",
    "\n",
    "print(f'Original # matchups at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')\n",
    "\n",
    "lsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_SST']>=mod_sst_thresh]\n",
    "lsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_pix']>=pix_thresh]\n",
    "lsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B[f'L8_{surf_temp}']>=thresh]\n",
    "\n",
    "# Concatenate data from both regions\n",
    "lsat_mod_df_n = pd.concat([lsat_mod_df_B,lsat_mod_df_C,lsat_mod_df_D]) \n",
    "lsat_mod_df_bc = pd.concat([lsat_mod_df_B,lsat_mod_df_C]) \n",
    "lsat_mod_df_cd = pd.concat([lsat_mod_df_C,lsat_mod_df_D])\n",
    "lsat_mod_df_bd = pd.concat([lsat_mod_df_B,lsat_mod_df_D])\n",
    "print(f'Num. good matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}, at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}, at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sum_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([9,10,11,12,1,3])]\n",
    "# shld_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([2])]\n",
    "# sum_c = lsat_mod_df_C[lsat_mod_df_C.DateTime.dt.month.isin([9,10,11,12,1,3])]\n",
    "# sum_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([9,10,11,12,1,3])]\n",
    "# shld_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([2])]\n",
    "# sum_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n",
    "# shld_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([2])]\n",
    "# sum_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n",
    "# shld_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ***check all the february images to see if we need to add a threshold of 2.0C or cut images or if the issue is clouds???\n",
    "# # shld\n",
    "# look = lsat_mod_df_n.sort_values('L8_filename')\n",
    "# look.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Orthoganal Regression \n",
    "if surf_temp=='LST':\n",
    "    data0 = lsat_mod_df_n\n",
    "    landsat_uncertainty = lst_uncertainty\n",
    "else:\n",
    "    data0 = lsat_mod_df_n\n",
    "    landsat_uncertainty = sst_uncertainty\n",
    "\n",
    "# Original data\n",
    "x_original = np.array(data0[f'L8_{surf_temp}'])\n",
    "y_original = np.array(data0['MODIS_SST'])\n",
    "\n",
    "# Assume these are your uncertainty estimates per observation\n",
    "sy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\n",
    "sx = np.full_like(x_original, landsat_uncertainty)\n",
    "\n",
    "# Define a linear function for the model\n",
    "def linear_model(p, x):\n",
    "    return p[0] * x + p[1]\n",
    "\n",
    "# Create a Model\n",
    "linear = Model(linear_model)\n",
    "\n",
    "# Create a RealData object using your DataFrame\n",
    "data = RealData(x_original, y_original,sx=sx, sy=sy)\n",
    "\n",
    "# Set up ODR with the model and data\n",
    "odr = ODR(data, linear, beta0=[1., 0.])\n",
    "\n",
    "# Run the regression\n",
    "out = odr.run()\n",
    "\n",
    "# Use the output\n",
    "beta = out.beta\n",
    "beta_err = out.sd_beta\n",
    "\n",
    "# Print the summary\n",
    "out.pprint()\n",
    "\n",
    "# Predicting values using the ODR model\n",
    "y_pred = linear_model(beta, x_original)\n",
    "\n",
    "# Get R2\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "y_mean = np.mean(y_original)\n",
    "SST = np.sum((y_original - y_mean)**2)\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "SSR = np.sum((y_original - y_pred)**2)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n",
    "\n",
    "# Calculate R^2\n",
    "R2 = 1 - (SSR / SST)\n",
    "print(\"R^2:\", np.around(R2,2))\n",
    "print(f\"RMSE: {np.around(rmse,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if surf_temp=='LST':\n",
    "    # Plot regression\n",
    "    beta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n",
    "    beta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n",
    "    beta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n",
    "    beta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n",
    "    print(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\n",
    "    xfill = np.array([-4.5,1.5])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "    ax.tick_params(labelsize=14)\n",
    "    \n",
    "    # LST data and regression\n",
    "    plt.scatter(x_original, y_original, s=12,color='mediumslateblue')\n",
    "    plt.plot(x_original, y_pred, color='mediumslateblue', label='LST ODR')\n",
    "    plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n",
    "    \n",
    "    # Comparison regressions\n",
    "    xi = np.arange(-7.0,5.0,1.0)\n",
    "    plt.plot(xi,xi * sstcalib_m + sstcalib_b,color='k',linewidth=2,label='SST ODR')\n",
    "    plt.plot(xi,xi,color='lightcoral',linewidth=2, label='MODIS 1:1')\n",
    "        \n",
    "    plt.legend(loc='lower right',fontsize=14)\n",
    "    plt.text(-2.7,-0.15,rf'$\\mathbf{{y={np.around(beta[0],2)}x+{np.around(beta[1],2)}\\quad r^2={np.around(R2,2)}}}$',color='mediumslateblue', fontweight='bold',fontsize=14)\n",
    "    plt.xlim([-3.5,-1.2])\n",
    "    plt.ylim([-3.05,0.8])\n",
    "    # else: \n",
    "    #     plt.plot(x_original, y_pred, color='k', label='NLSST Orthogonal Distance Regression')\n",
    "    #     plt.legend(loc='lower right',fontsize=12)\n",
    "    #     plt.text(-2.6,-0.2,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\n",
    "    #     plt.xlim([-3.2,-0.15])\n",
    "    #     plt.ylim([-2.4,0.9]) \n",
    "    plt.xlabel('Landsat ST [¬∞C]',fontsize=16)\n",
    "    plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthoganal Regression for SST only\n",
    "dataframes = [\n",
    "    ('Combined', lsat_mod_df_n),\n",
    "    ('Burke', lsat_mod_df_B),\n",
    "    ('Cosgrove', lsat_mod_df_C),\n",
    "    ('Dotson', lsat_mod_df_D),\n",
    "]\n",
    "\n",
    "if surf_temp=='LST':\n",
    "    landsat_uncertainty = lst_uncertainty\n",
    "else:\n",
    "    landsat_uncertainty = sst_uncertainty\n",
    "\n",
    "# Dictionary to store the results from each DataFrame\n",
    "odr_results = {}\n",
    "\n",
    "# Define a linear function for the model\n",
    "def linear_model(p, x):\n",
    "    return p[0] * x + p[1]\n",
    "\n",
    "# Create a Model object\n",
    "linear = Model(linear_model)\n",
    "\n",
    "# Loop over each DataFrame\n",
    "for df_name, data0 in dataframes:\n",
    "    print(f\"\\n=== Processing {df_name} ===\")\n",
    "    \n",
    "    # Original data\n",
    "    x_original = np.array(data0[f'L8_{surf_temp}'])\n",
    "    y_original = np.array(data0['MODIS_SST'])\n",
    "\n",
    "    # Assume these are your uncertainty estimates per observation\n",
    "    sy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\n",
    "    sx = np.full_like(x_original, landsat_uncertainty)\n",
    "    \n",
    "    # Create a RealData object using your DataFrame\n",
    "    data = RealData(x_original, y_original,sx=sx, sy=sy)\n",
    "    \n",
    "    # Set up ODR with the model and data, providing an initial guess\n",
    "    odr = ODR(data, linear, beta0=[1., 0.])\n",
    "    \n",
    "    # Run the regression\n",
    "    out = odr.run()\n",
    "    \n",
    "    # Retrieve best-fit parameters and their std. dev.\n",
    "    beta = out.beta\n",
    "    beta_err = out.sd_beta\n",
    "    \n",
    "    # Print the summary\n",
    "    out.pprint()\n",
    "    \n",
    "    # Predicting values using the ODR model\n",
    "    y_pred = linear_model(beta, x_original)\n",
    "    \n",
    "    # Get R2\n",
    "    # Calculate Total Sum of Squares (SST)\n",
    "    y_mean = np.mean(y_original)\n",
    "    SST = np.sum((y_original - y_mean)**2)\n",
    "    \n",
    "    # Calculate Residual Sum of Squares (SSR)\n",
    "    SSR = np.sum((y_original - y_pred)**2)\n",
    "    \n",
    "    # Calculate R^2\n",
    "    R2 = 1 - (SSR / SST)\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n",
    "    \n",
    "    # Print R^2\n",
    "    print(f\"{df_name} R^2:\", np.around(R2, 2))\n",
    "    print(f\"RMSE: {np.around(rmse,2)}\")\n",
    "    \n",
    "    # Store results in a dictionary for later use (plotting, etc.)\n",
    "    odr_results[df_name] = {\n",
    "        'beta': beta,\n",
    "        'beta_err': beta_err,\n",
    "        'R2': R2,\n",
    "        'x_original': x_original,\n",
    "        'y_original': y_original,\n",
    "        'y_pred': y_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary ipywidgets components\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# The @interact decorator will automatically create widgets for the function arguments\n",
    "@interact(\n",
    "    show_burke=widgets.Checkbox(value=True, description=\"Burke Data\"),\n",
    "    show_cosgrove=widgets.Checkbox(value=True, description=\"Cosgrove Data\"),\n",
    "    show_dotson=widgets.Checkbox(value=True, description=\"Dotson Data\"),\n",
    "    show_combined_fit=widgets.Checkbox(value=True, description=\"Combined Fit\"),\n",
    "    show_confidence_interval=widgets.Checkbox(value=True, description=\"95% CI\")\n",
    ")\n",
    "def interactive_sst_plot(show_burke, show_cosgrove, show_dotson, show_combined_fit, show_confidence_interval):\n",
    "    \n",
    "    # This is your original code, with plotting commands wrapped in if-statements\n",
    "    if surf_temp=='SST':\n",
    "        # Your original data calculation code (unchanged)\n",
    "        beta_mdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n",
    "        beta_mup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n",
    "        beta_bdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n",
    "        beta_bup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n",
    "        a1 = np.around(odr_results['Combined']['beta'][0],2)\n",
    "        a2 = np.around(odr_results['Combined']['beta'][1],2)\n",
    "        ar = np.around(odr_results['Combined']['R2'],2)\n",
    "        b1 = np.around(odr_results['Burke']['beta'][0],2)\n",
    "        b2 = np.around(odr_results['Burke']['beta'][1],2)\n",
    "        br = np.around(odr_results['Burke']['R2'],2)\n",
    "        c1 = np.around(odr_results['Cosgrove']['beta'][0],2)\n",
    "        c2 = np.around(odr_results['Cosgrove']['beta'][1],2)\n",
    "        cr = np.around(odr_results['Cosgrove']['R2'],2)\n",
    "        d1 = np.around(odr_results['Dotson']['beta'][0],2)\n",
    "        d2 = np.around(odr_results['Dotson']['beta'][1],2)\n",
    "        dr = np.around(odr_results['Dotson']['R2'],2)\n",
    "        xfill = np.array([-4.3,0.9])\n",
    "\n",
    "        # --- Plotting Section ---\n",
    "        fig, ax = plt.subplots(figsize=(8, 4)) # Increased height slightly for better text placement\n",
    "        ax.tick_params(labelsize=14)\n",
    "\n",
    "        if show_burke:\n",
    "            plt.scatter(np.array(lsat_mod_df_B[f'L8_{surf_temp}']), np.array(lsat_mod_df_B['MODIS_SST']), s=12,color='#00bf7d', label='Burke')\n",
    "            plt.plot(odr_results['Burke']['x_original'], odr_results['Burke']['y_pred'], ls='-',linewidth=1,color='#00bf7d')\n",
    "            plt.text(-2.9,0.0,f'y={b1}x+{b2}   $r^2$={br}',color='#00bf7d',fontsize=12)\n",
    "\n",
    "        if show_cosgrove:\n",
    "            plt.scatter(np.array(lsat_mod_df_C[f'L8_{surf_temp}']), np.array(lsat_mod_df_C['MODIS_SST']), s=12,color=sns.color_palette(\"colorblind\")[3], label='Cosgrove')\n",
    "            plt.plot(odr_results['Cosgrove']['x_original'], odr_results['Cosgrove']['y_pred'], ls='-',linewidth=1,color=sns.color_palette(\"colorblind\")[3])\n",
    "            plt.text(-2.9,-0.3,f'y={c1}x+{c2}   $r^2$={cr}',color=sns.color_palette(\"colorblind\")[3],fontsize=12)\n",
    "            \n",
    "        if show_dotson:\n",
    "            plt.scatter(np.array(lsat_mod_df_D[f'L8_{surf_temp}']), np.array(lsat_mod_df_D['MODIS_SST']), s=12,color='#0073e6', label='Dotson')\n",
    "            plt.plot(odr_results['Dotson']['x_original'], odr_results['Dotson']['y_pred'], ls='-',linewidth=1,color='#0073e6')\n",
    "            plt.text(-2.9,-0.6,f'y={d1}x+{d2}   $r^2$={dr}',color='#0073e6',fontsize=12)\n",
    "\n",
    "        if show_combined_fit:\n",
    "            plt.plot(odr_results['Combined']['x_original'], odr_results['Combined']['y_pred'], color='k')\n",
    "            plt.text(-2.9,0.3,f'y={a1}x+{a2}   $r^2$={ar}',color='k',fontsize=14)\n",
    "            if show_confidence_interval:\n",
    "                plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n",
    "\n",
    "        # General plot labels and limits (unchanged)\n",
    "        plt.xlim([-3.05,-0.15])\n",
    "        plt.ylim([-2.3,0.9])\n",
    "        plt.xlabel('Landsat SST [¬∞C]',fontsize=16)\n",
    "        plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n",
    "        plt.legend(loc='lower right',fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show() # Make sure to show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odr_results['Combined']['beta_err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if surf_temp=='SST':\n",
    "    # Ordinary least squares regression between Landsat and MODIS SST matchups\n",
    "    resultC = sm.ols(formula=\"MODIS_SST ~ L8_SST\", data=data0).fit()\n",
    "    print (resultC.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Analysis Dashboard using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Interactive Dashboard\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib-based Interactive Dashboard Function\n",
    "\n",
    "def linear_model(p, x):\n",
    "    return p[0] * x + p[1]\n",
    "\n",
    "def interactive_calibration_dashboard_matplotlib(region, chart_type, pix_thresh, modis_sst_thresh, lsat_sst_thresh):\n",
    "    # 1. & 2. Data filtering and selection (Same as your original code)\n",
    "    df_C_filt = lsat_mod_df_C[(lsat_mod_df_C['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_C['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_C[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n",
    "    df_C_filt['Region'] = 'Cosgrove'\n",
    "\n",
    "    df_D_filt = lsat_mod_df_D[(lsat_mod_df_D['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_D['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_D[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n",
    "    df_D_filt['Region'] = 'Dotson'\n",
    "\n",
    "    df_B_filt = lsat_mod_df_B[(lsat_mod_df_B['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_B['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_B[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n",
    "    df_B_filt['Region'] = 'Burke'\n",
    "\n",
    "    if region == 'All Regions':\n",
    "        df_filtered = pd.concat([df_B_filt, df_C_filt, df_D_filt])\n",
    "    elif region == 'Cosgrove':\n",
    "        df_filtered = df_C_filt\n",
    "    elif region == 'Dotson':\n",
    "        df_filtered = df_D_filt\n",
    "    elif region == 'Burke':\n",
    "        df_filtered = df_B_filt\n",
    "    \n",
    "    # Create the figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    if len(df_filtered) < 2:\n",
    "        ax.text(0.5, 0.5, \"Not enough data with the current filter settings.\", ha='center', va='center')\n",
    "        ax.set_axis_off()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    # 3. ODR Calculation (Same as your original code)\n",
    "    x_data = df_filtered[f'L8_{surf_temp}'].values\n",
    "    y_data = df_filtered['MODIS_SST'].values\n",
    "    sx = np.full_like(x_data, sst_uncertainty)\n",
    "    sy = np.full_like(y_data, modis_uncertainty * pix_uncertainty)\n",
    "    model = Model(linear_model)\n",
    "    data = RealData(x_data, y_data, sx=sx, sy=sy)\n",
    "    odr = ODR(data, model, beta0=[1., 0.])\n",
    "    output = odr.run()\n",
    "    slope, intercept = output.beta\n",
    "    y_pred = linear_model(output.beta, x_data)\n",
    "\n",
    "    # 4. Statistics Calculation (Same as your original code, but formatted for Matplotlib title)\n",
    "    bias = np.mean(y_data - x_data)\n",
    "    trend = slope\n",
    "    ss_total = np.sum((y_data - np.mean(y_data))**2)\n",
    "    ss_resid = np.sum((y_data - y_pred)**2)\n",
    "    r2 = 1 - (ss_resid / ss_total) if ss_total > 0 else 0\n",
    "    rmse = np.sqrt(np.mean((y_data - y_pred)**2))\n",
    "    # Note: Matplotlib title doesn't support HTML bold tags, so they are removed.\n",
    "    stats_text = (f\"Trend (Slope): {trend:.2f} | Bias (MODIS - Landsat): {bias:.2f}¬∞C\\n\"\n",
    "                  f\"R¬≤: {r2:.2f} | RMSE: {rmse:.2f} | N: {len(df_filtered)}\")\n",
    "\n",
    "    # 5. Create Matplotlib figure based on chart_type\n",
    "    if chart_type == 'Scatter':\n",
    "        # Seaborn's scatterplot is a great way to handle coloring by category easily\n",
    "        sns.scatterplot(data=df_filtered, x=f'L8_{surf_temp}', y='MODIS_SST', hue='Region', ax=ax, s=50)\n",
    "    elif chart_type == 'Heatmap':\n",
    "        ax.hist2d(df_filtered[f'L8_{surf_temp}'], df_filtered['MODIS_SST'], bins=20, cmap='viridis')\n",
    "        fig.colorbar(ax.collections[0], ax=ax, label='Point Density')\n",
    "\n",
    "    # Add regression line\n",
    "    sorted_indices = np.argsort(x_data)\n",
    "    ax.plot(x_data[sorted_indices], y_pred[sorted_indices], color='black', linewidth=2, label='ODR Fit')\n",
    "\n",
    "    # Set titles, labels, and limits\n",
    "    ax.set_title(stats_text)\n",
    "    ax.set_xlabel(\"Landsat SST [¬∞C]\")\n",
    "    ax.set_ylabel(\"MODIS SST [¬∞C]\")\n",
    "    ax.set_xlim(-3.05, -0.15)\n",
    "    ax.set_ylim(-2.3, 0.9)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Define Widgets\n",
    "style = {'description_width': 'initial'}\n",
    "w_region = widgets.Dropdown(options=['All Regions', 'Cosgrove', 'Dotson', 'Burke'], value='All Regions', description='Select Region:', style=style)\n",
    "w_chart_type = widgets.ToggleButtons(options=['Scatter', 'Heatmap'], description='Chart Type:', button_style='info')\n",
    "w_pix_thresh = widgets.IntSlider(value=1300, min=0, max=5000, step=100, description='Min MODIS Pixels:', style=style, layout=Layout(width='500px'))\n",
    "w_modis_sst = widgets.FloatSlider(value=-1.9, min=-2.5, max=0, step=0.1, description='Min MODIS SST (¬∞C):', style=style, layout=Layout(width='500px'))\n",
    "w_lsat_sst = widgets.FloatSlider(value=-3.1, min=-4.0, max=0, step=0.1, description='Min Landsat SST (¬∞C):', style=style, layout=Layout(width='500px'))\n",
    "\n",
    "\n",
    "# Launch the new Matplotlib-based Dashboard\n",
    "interact(interactive_calibration_dashboard_matplotlib, \n",
    "         region=w_region, \n",
    "         chart_type=w_chart_type,\n",
    "         pix_thresh=w_pix_thresh, \n",
    "         modis_sst_thresh=w_modis_sst, \n",
    "         lsat_sst_thresh=w_lsat_sst);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
