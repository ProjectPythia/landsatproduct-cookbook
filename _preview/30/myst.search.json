{"version":"1","records":[{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nSee the \n\nCookbook Contributorâ€™s Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!\n\nThis Project Pythia Cookbook covers ... (replace ... with the main subject of your cookbook ... e.g., working with radar data in Python)","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Motivation"},"content":"(Add a few sentences stating why this cookbook will be useful. What skills will you, â€œthe chefâ€, gain once you have reached the end of the cookbook?)","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Authors"},"content":"First Author, \n\nSecond Author, etc. Acknowledge primary content authors here","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Structure"},"content":"(State one or more sections that will comprise the notebook. E.g., This cookbook is broken up into two main sections - â€œFoundationsâ€ and â€œExample Workflows.â€ Then, describe each section below.)","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. â€œFoundationsâ€ )","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":10},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. â€œFoundationsâ€ )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"The foundational content includes ... \")","type":"content","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":11},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. â€œExample workflowsâ€ )","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":12},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. â€œExample workflowsâ€ )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"Example workflows include ... \")","type":"content","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":13},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\nâ€œlaunch Binderâ€. After a moment you should be presented with a\nnotebook that you can interact with. I.e. youâ€™ll be able to execute\nand even change the example programs. Youâ€™ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace â€œcookbook-exampleâ€ with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"Calibration"},"type":"lvl1","url":"/notebooks/calibration","position":0},{"hierarchy":{"lvl1":"Calibration"},"content":"","type":"content","url":"/notebooks/calibration","position":1},{"hierarchy":{"lvl1":"Calibration","lvl3":"ðŸ¤” Why Calibrate?"},"type":"lvl3","url":"/notebooks/calibration#id-why-calibrate","position":2},{"hierarchy":{"lvl1":"Calibration","lvl3":"ðŸ¤” Why Calibrate?"},"content":"\n\nCalibration of a physical model is the process of tuning its parameters to ensure its outputs accurately match real-world measurements. Itâ€™s about bridging the gap between theoretical calculations and physical reality.\n\nKey Goal: The primary goal is to improve predictive accuracy, transforming a model from a theoretical construct into a reliable tool for analysis and design.\n\n","type":"content","url":"/notebooks/calibration#id-why-calibrate","position":3},{"hierarchy":{"lvl1":"Calibration","lvl3":"ðŸ“ What Do You Need?"},"type":"lvl3","url":"/notebooks/calibration#id-what-do-you-need","position":4},{"hierarchy":{"lvl1":"Calibration","lvl3":"ðŸ“ What Do You Need?"},"content":"\n\nTo calibrate a model, you need four key components:\n\n1. A Physical ModelA set of mathematical equations or simulation software.\n\n2. Tunable ParametersThe specific \"knobs\" in your model that you can adjust.\n\n3. Experimental DataHigh-quality measurements from the real-world system.\n\n4. An Objective FunctionA metric that quantifies the error (e.g., RMSE).\n\n","type":"content","url":"/notebooks/calibration#id-what-do-you-need","position":5},{"hierarchy":{"lvl1":"Calibration","lvl3":"âš™ï¸ How to Calibrate?"},"type":"lvl3","url":"/notebooks/calibration#id-how-to-calibrate","position":6},{"hierarchy":{"lvl1":"Calibration","lvl3":"âš™ï¸ How to Calibrate?"},"content":"\n\nThere are two main approaches to calibration: by hand (trial and error) or by using a smart computer search (optimization algorithms). Optimization is highly recommended for its efficiency and accuracy.\n\nClick to see details on different optimization methods\n\nGradient-Based Methods: Use the error gradient for efficient searching (e.g., Levenberg-Marquardt).\n\nGradient-Free Methods: Do not require gradients, essential for â€œblack-boxâ€ simulations (e.g., Nelder-Mead).\n\nBayesian Calibration: Treats parameters as probability distributions to quantify uncertainty.\n\nCross-Calibration: Calibrates one model against a trusted reference model to ensure consistency.\n\n","type":"content","url":"/notebooks/calibration#id-how-to-calibrate","position":7},{"hierarchy":{"lvl1":"Calibration","lvl3":"âœ… How Do You Know Itâ€™s Calibrated?"},"type":"lvl3","url":"/notebooks/calibration#id-how-do-you-know-its-calibrated","position":8},{"hierarchy":{"lvl1":"Calibration","lvl3":"âœ… How Do You Know Itâ€™s Calibrated?"},"content":"\n\nA successful calibration can be verified by analyzing the errors and by validating the model against new data. A common way to visualize the result is by plotting the modelâ€™s output against the experimental data.\n\n","type":"content","url":"/notebooks/calibration#id-how-do-you-know-its-calibrated","position":9},{"hierarchy":{"lvl1":"Calibration","lvl4":"Interactive Example: Adjusting Model Parameters","lvl3":"âœ… How Do You Know Itâ€™s Calibrated?"},"type":"lvl4","url":"/notebooks/calibration#interactive-example-adjusting-model-parameters","position":10},{"hierarchy":{"lvl1":"Calibration","lvl4":"Interactive Example: Adjusting Model Parameters","lvl3":"âœ… How Do You Know Itâ€™s Calibrated?"},"content":"To make this concept interactive, you can run the code cell below. It will create the same plot but with sliders that let you manually adjust the modelâ€™s parameters (slope and intercept). Try to move the sliders to make the red line fit the blue dots. This gives you a hands-on feel for the â€œBy Handâ€ calibration process.\n\n# First, let's install ipywidgets for the interactive sliders\n#%pip install -q ipywidgets\n#%pip install -q scikit-image\n#%pip install seaborn\n# %pip install plotly\n%pip install xarray==2024.05.0\nimport earthaccess\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, fixed\n\n# 1. Create the sample \"Experimental Data\"\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 20)\ntrue_slope = 2.5\ntrue_intercept = 1.5\ny_data = true_slope * x_data + true_intercept + np.random.normal(0, 2, size=x_data.shape)\n\n# 2. Define a function to plot the data and our adjustable model\ndef plot_model(x, y, slope, intercept):\n    \"\"\"Plots the experimental data against the model line defined by slope and intercept.\"\"\"\n    y_model = slope * x + intercept\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(x, y, 'o', label='Experimental Data', markersize=8, color='royalblue')\n    plt.plot(x, y_model, '-', label='Adjustable Model', linewidth=3, color='red')\n    \n    # Calculate and display the RMSE as our objective function score\n    rmse = np.sqrt(np.mean((y - y_model)**2))\n    plt.title(f'Comparison of Model vs. Data (RMSE: {rmse:.2f})', fontsize=16)\n    \n    plt.xlabel('Independent Variable', fontsize=12)\n    plt.ylabel('Dependent Variable', fontsize=12)\n    plt.ylim(min(y_data)-2, max(y_data)+2)\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.6)\n    plt.show()\n\n# 3. Create the interactive plot!\n# The 'interact' function automatically creates sliders for the numerical arguments.\ninteract(plot_model, x=fixed(x_data), y=fixed(y_data), slope=(0.0, 5.0, 0.1), intercept=(-5.0, 5.0, 0.1));\n\n","type":"content","url":"/notebooks/calibration#interactive-example-adjusting-model-parameters","position":11},{"hierarchy":{"lvl1":"Calibration","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl2","url":"/notebooks/calibration#example-landsat-calibration-using-modis-sst","position":12},{"hierarchy":{"lvl1":"Calibration","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"Create matchups between Landsat and MODIS SST data near Cosgrove, West Antarctica\nto produce a calibration for Landsat SSTs\n\n# Import libraries and modules\n%config InlineBackend.figure_format = 'svg'\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport xarray as xr\nimport geopandas as gpd\nfrom datetime import date, timedelta, datetime\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom matplotlib import colors\nfrom matplotlib.pylab import rcParams\nfrom matplotlib.patches import Polygon as Pgon\nimport cartopy.crs as ccrs\nimport cartopy\n\nimport os\nfrom cycler import cycler\nimport pyproj\nfrom pyproj import Proj, transform\nfrom sklearn.neighbors import BallTree\nimport pytz\nimport pygmt\nimport gc\nimport copy\nimport random\nimport statsmodels.formula.api as sm\nimport scipy.stats as stats\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom shapely.geometry import Point, Polygon\nfrom pathlib import Path\nimport math\nfrom scipy.odr import Model, RealData, ODR\nfrom tqdm.notebook import trange, tqdm\nimport seaborn as sns\n\nimport earthaccess\n\n# For LST file masking\nimport pystac_client\nimport intake\nfrom rasterio.session import AWSSession\nimport boto3\n\nimport SSTutils as stu\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#For color cycling in plots that is color blind friendly...make new ones at \"I want hue\" tools.medialab.sciences-po.fr/iwanthue\ncolor_cycler = cycler(color=[\"#6777cf\",\"#adba49\",\"#c65ca0\",\"#5fa042\",\"#683287\",\"#72ce7b\",\"#c44a48\",\"#45c7a9\",\"#933c1d\",\"#d0803f\",\"#ac9239\",\"#317c39\"])\ncolorline_cycler = (cycler(color=[\"#75a141\",\"#6c61b9\",\"#bc4d45\",\"#c1913d\",\"#b85298\",\"#4aa8e8\"]) +\n                 cycler(linestyle=['-','--',':','-.','-','--']))\nrcParams['axes.prop_cycle'] = cycler('color', color_cycler)\n\n","type":"content","url":"/notebooks/calibration#example-landsat-calibration-using-modis-sst","position":13},{"hierarchy":{"lvl1":"Calibration","lvl3":"Build Landsat - MODIS SST matchups","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#build-landsat-modis-sst-matchups","position":14},{"hierarchy":{"lvl1":"Calibration","lvl3":"Build Landsat - MODIS SST matchups","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Set paths and important variables and Calibration region bounding box\n\nbasepath = Path('/home/jovyan/landsatproduct-cookbook')\nspacing = [990,-990] # 990m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\nparam = 'sea_surface_temperature'\nsize_threshold = 30\n\nlocation = 0             # 0 and 1 are the Cosgrove and Dotson Polynya calibration areas, respectively\nsurf_temp = 'SST'        # 'SST' and 'LST' are for the Landsat SST and LST algorithms respectively\n\n# Set location bounds\nif location==1:\n    pathdir = 'DotsonPolynya'\n    latboundsC = [ -73.9 , -73.5 ] # Dotson polynya\n    lonboundsC = [ -113 , -111.5 ]\n    dfloc = 'Dotson'\nelif location==0:\n    pathdir = 'Cosgrove'\n    latboundsC = [ -73.5 , -73.42 ] # near Cosgrove\n    lonboundsC = [ -103.0 , -102.0 ]\n    dfloc = 'Cosgrove'\nelif location==2:\n    pathdir = 'Burke'\n    latboundsC = [ -73.81 , -73.42 ] # south of Burke\n    lonboundsC = [ -104.2 , -103.8 ]\n    dfloc = 'Burke'\nif location==3:\n    pathdir = 'DotsonIntercomp'\n    latboundsC = [ -74.2 , -74.11 ] # Dotson plume for intercomparison\n    lonboundsC = [ -113.5 , -113.17 ]\n    dfloc = 'DotsonIntercomp'\n\n# Coefficients for calibration\n# SST\nsstcalib_m = 0.76 \nsstcalib_b = 0.55 \n\n# LST\nlstcalib_m = 0.80\nlstcalib_b = 1.00\n\nmodmin = -1.9\nLSTmin = np.around(modmin/lstcalib_m - lstcalib_b,2) \nSSTmin = np.around(modmin/sstcalib_m - sstcalib_b,2) # should be about -2.0\n\n# Uncertainties used in ODR propagation of error\nmodis_uncertainty = 0.44  # long wave sst ocean color atbd\nsst_uncertainty = 0.3 # USGS Landsat stray light notice\nlst_uncertainty = 1.0 # gerace 2020\npix_uncertainty = np.sqrt((1000*1000)/(100*100)) # MODIS 1km x 1km and Landsat 100m x 100m\n\n\n# For calibrated SST runs\nif surf_temp=='SST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/Validation/{pathdir}/'\n    else:\n        sstpath = basepath / f'Data/SST/MODcalib/{pathdir}/'\n    tif = 'tif'\n    thresh = SSTmin\n    calib_m = sstcalib_m\n    calib_b = sstcalib_b\n    \n# If running for LST comparisons\nelif surf_temp=='LST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/LST/Calibration/DotsonPolynya/'\n    else:\n        sstpath = basepath / f'Data/SST/LST/Calibration/{pathdir}/'\n    tif = 'TIF'\n    thresh = LSTmin\n    calib_m = lstcalib_m\n    calib_b = lstcalib_b\n\n# Authenticate for accessing NASA data (MODIS)\nauth = earthaccess.login(strategy=\"interactive\")\n\n# If we are not authenticated\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\n# Convert bounding box to south polar stereo for checking if landsat has any data in bounding box\n# Speeds up process a lot\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the file   \n\nbbox,checkbox = stu.lsat_reproj(source_crs,target_crs,(lonboundsC[0],latboundsC[0],lonboundsC[1],latboundsC[1]))\n\n# Create polygon for later cropping\npolygon = Polygon([(bbox[0][0],bbox[0][1]),(bbox[3][0],bbox[3][1]),(bbox[2][0],bbox[2][1]),(bbox[1][0],bbox[1][1])])\n\n# Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\nminx, miny, maxx, maxy = polygon.bounds\npolarx = [minx, maxx]\npolary = [miny, maxy]\n\n# Get Landsat file paths in directory\nlsatfiles = os.listdir(sstpath)\nlsatfiles = [x for x in lsatfiles if x[-3:] == tif]\nlsatfiles.sort()\nprint (len(lsatfiles))\nos.chdir(sstpath)\n\nSSTfails = [\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n]\nLSTfails = [\n 'LC08_L1GT_007112_20211215_20211223_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20220201_20220211_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20221202_20221212_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20230204_20230209_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220105_20220114_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220121_20220128_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221105_20221115_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230108_20230124_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230313_20230321_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF'\n]\n\n","type":"content","url":"/notebooks/calibration#build-landsat-modis-sst-matchups","position":15},{"hierarchy":{"lvl1":"Calibration","lvl3":"Search for desired Landsat scenes","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#search-for-desired-landsat-scenes","position":16},{"hierarchy":{"lvl1":"Calibration","lvl3":"Search for desired Landsat scenes","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Authenticate for boto S3 access, etc.\nos.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\naws_session = AWSSession(boto3.Session(), requester_pays=True)\n\n# Setup and authenticate \nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient\n\n# Define the landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1 - includes L8 and L9\n\ni=0\nls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\nls_scene\n\n%%time\n# ~1 min 32 sec per image\n# If number of MODIS images per satellite is much more than 25, its because there is a ULY,LRY issue\nos.chdir('/home/jovyan/landsatproduct-cookbook/Data/SST/MODcalib/Cosgrove/')\n\nlsat_mod = []\n#for i in tqdm(range(len(lsatfiles)), desc=\"Processing\"):\nfor i in tqdm(range(1), desc=\"Processing the first image\"):\n    # Check for known repeatedly bad files that will kill the code\n    if surf_temp == 'SST':    \n        if lsatfiles[i] in SSTfails:\n            continue\n    elif surf_temp == 'LST':\n        if lsatfiles[i] in LSTfails:\n            continue\n        \n    # Concatenate all landsat files into xarray with a time dimension\n    ls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\n    ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n    print(\"1\")\n    if surf_temp == 'SST':\n        times = pd.to_datetime(lsatfiles[i][17:25]+lsatfiles[i][41:47], format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-8])\n    elif surf_temp == 'LST':\n        # Need to mask LST because not done previously\n        mask = stu.get_lst_mask(lsatfiles[i])\n        ls_scene = ls_scene * mask\n        \n        times = pd.to_datetime(lsatfiles[i][17:25]+'120000', format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-4])\n        ls_scene = ls_scene - 273.15\n\n    # Subset scene and check that it has the correct dimensions because y order changes sometimes\n    ls_scene = stu.subset_img(ls_scene,polarx,polary) # subset so easier to work with\n    ls_scene = stu.crop_xarray_dataarray_with_polygon(ls_scene, polygon) # crop data to exact bounding box\n\n    # if location==3:\n    # # Calibrate\n    # ls_scene = ls_scene * calib_m + calib_b\n    \n    # # Remove SSTs that are unrealistically cool\n    # ls_scene = ls_scene.where(ls_scene >= thresh, np.nan)\n\n    lsID = lsatfiles[i]\n    print (lsID)\n    \n    # Take mean temp, will skip the modis stage if no Landsat data in the calibration region\n    try:\n        lsat = np.nanmean(ls_scene)\n        ls_num = ls_scene.notnull().values.sum()\n    except Exception as e:\n        print (lsID, e)\n        lsat = np.nan\n\n    print(lsat)\n    if ~np.isfinite(lsat):\n        continue\n\n    # Find coincident MODIS SST scene\n    mod_scene, mod_file,time_dif = stu.find_MODIS(lonboundsC,latboundsC,ls_scene)\n    print(mod_file)\n\n    try:\n        # Acquire and align MODIS data to Landsat\n\n        # To subset to only high quality MODIS temp measurements which doesn't seem to be useful\n        # print(mod_scene.quality_level.max().values)\n        # mod_temps = mod_scene.sea_surface_temperature.where(mod_scene.quality_level>=4)\n\n        MODsst_xr = stu.get_sst(ls_scene,mod_scene.sea_surface_temperature,spacing,param) #mod_scene.sea_surface_temperature\n\n        # Remove SSTs that are unrealistically cool\n        MODsst_xr = MODsst_xr.where(MODsst_xr >= -1.9, np.nan)\n\n        # Crop Landsat image to meet the slightly smaller MODIS image (smaller image results from upsample methods in get_wv2)\n        ls_scene = stu.subset_img(ls_scene,[MODsst_xr.x.min(),MODsst_xr.x.max()],[MODsst_xr.y.min(),MODsst_xr.y.max()])\n\n        # Only use MODIS data where cropped Landsat data is also available\n        MODsst_xr_sub = MODsst_xr.where(ls_scene.notnull(),np.nan)\n\n        # Take mean temp\n        modis = np.nanmean(MODsst_xr_sub)\n        MOD_num = MODsst_xr_sub.notnull().values.sum()\n    except Exception as e:\n        print (mod_file, e)\n        modis = np.nan\n        MOD_num = 0\n\n    # Take mean using Landsat data only where cropped MODIS data is also available (need to do both)\n    try:\n        ls_scene_sub = ls_scene.where(MODsst_xr_sub.notnull(),np.nan)\n        lsat = np.nanmean(ls_scene_sub)\n        ls_num = ls_scene_sub.notnull().values.sum()\n    except Exception as e:\n        print (lsID, e)\n        lsat = np.nan\n\n    # Append file names with SST means from the Cosgrove box\n    lsat_mod.append([times,mod_file,modis,MOD_num,lsID,lsat,ls_num,time_dif])\n    print (f'MODIS mean: {modis}, Landsat 8: {lsat}')\n\n    try:\n        del ls_scene, ls_sub, mod_scene, MODsst_xr, MODsst_xr_sub\n    except:\n        pass\n\n    gc.collect()\n\n# # Put data into DataFrame and save    \n# headers = ['DateTime','MODIS_filename','MODIS_SST','MODIS_pix','L8_filename',f'L8_{surf_temp}','L8_pix','time_dif']\n# lsat_mod_df = pd.DataFrame(lsat_mod,columns=headers)\n# out_df = basepath / f'Data/MODISvLandsat_{surf_temp}_{dfloc}_20250500.csv'\n# lsat_mod_df.to_csv(out_df, index=False)\n\n","type":"content","url":"/notebooks/calibration#search-for-desired-landsat-scenes","position":17},{"hierarchy":{"lvl1":"Calibration","lvl3":"Calculate calibration bias and trend","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#calculate-calibration-bias-and-trend","position":18},{"hierarchy":{"lvl1":"Calibration","lvl3":"Calculate calibration bias and trend","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"Uses a \n\nRANSAC regression, but provides comparisons to an Ordinary Least Squares regression calculation from statsmodel of the same parameters.\n\n# Read in paired MODIS/Landsat data created above\nsurf_temp = 'SST'\n\nif surf_temp=='LST':\n    thresh = -3.5 # -3.4 is ok too\n    pix_thresh = 1300\nelif surf_temp=='SST':\n    thresh = -3.1\n    pix_thresh = 1300\nmod_sst_thresh = -1.9\n\n# For Cosgrove region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Cosgrove.csv'\n    df1 = pd.read_csv(out_df)\n    lsat_mod_df_C = df1\nelse:   \n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Cosgrove_lin_scale.csv' \n    df1 = pd.read_csv(out_df)\n    lsat_mod_df_C = df1\n\nprint(f'Original # matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_pix']>=pix_thresh]\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C[f'L8_{surf_temp}']>=thresh]\n\n# For Dotson polynya region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Dotson.csv'\n    df5 = pd.read_csv(out_df)\n    lsat_mod_df_D = df5\nelse:\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Dotson_lin_scale.csv'  \n    df5 = pd.read_csv(out_df)\n    lsat_mod_df_D = df5\n\nprint(f'Original # matchups at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_pix']>=pix_thresh]\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D[f'L8_{surf_temp}']>=thresh]\n\n# For Burke region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Burke.csv'\n    df9 = pd.read_csv(out_df)\n    lsat_mod_df_B = df9\nelse:\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Burke_lin_scale.csv'\n    df9 = pd.read_csv(out_df)\n    lsat_mod_df_B = df9\n\nprint(f'Original # matchups at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_pix']>=pix_thresh]\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B[f'L8_{surf_temp}']>=thresh]\n\n# Concatenate data from both regions\nlsat_mod_df_n = pd.concat([lsat_mod_df_B,lsat_mod_df_C,lsat_mod_df_D]) \nlsat_mod_df_bc = pd.concat([lsat_mod_df_B,lsat_mod_df_C]) \nlsat_mod_df_cd = pd.concat([lsat_mod_df_C,lsat_mod_df_D])\nlsat_mod_df_bd = pd.concat([lsat_mod_df_B,lsat_mod_df_D])\nprint(f'Num. good matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}, at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}, at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')\n\n# sum_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([2])]\n# sum_c = lsat_mod_df_C[lsat_mod_df_C.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# sum_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([2])]\n# sum_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([2])]\n# sum_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([2])]\n\n# # ***check all the february images to see if we need to add a threshold of 2.0C or cut images or if the issue is clouds???\n# # shld\n# look = lsat_mod_df_n.sort_values('L8_filename')\n# look.head(20)\n\n# Orthoganal Regression \nif surf_temp=='LST':\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = lst_uncertainty\nelse:\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = sst_uncertainty\n\n# Original data\nx_original = np.array(data0[f'L8_{surf_temp}'])\ny_original = np.array(data0['MODIS_SST'])\n\n# Assume these are your uncertainty estimates per observation\nsy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\nsx = np.full_like(x_original, landsat_uncertainty)\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model\nlinear = Model(linear_model)\n\n# Create a RealData object using your DataFrame\ndata = RealData(x_original, y_original,sx=sx, sy=sy)\n\n# Set up ODR with the model and data\nodr = ODR(data, linear, beta0=[1., 0.])\n\n# Run the regression\nout = odr.run()\n\n# Use the output\nbeta = out.beta\nbeta_err = out.sd_beta\n\n# Print the summary\nout.pprint()\n\n# Predicting values using the ODR model\ny_pred = linear_model(beta, x_original)\n\n# Get R2\n# Calculate Total Sum of Squares (SST)\ny_mean = np.mean(y_original)\nSST = np.sum((y_original - y_mean)**2)\n\n# Calculate Residual Sum of Squares (SSR)\nSSR = np.sum((y_original - y_pred)**2)\n\n# Compute RMSE\nrmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n\n# Calculate R^2\nR2 = 1 - (SSR / SST)\nprint(\"R^2:\", np.around(R2,2))\nprint(f\"RMSE: {np.around(rmse,2)}\")\n\nif surf_temp=='LST':\n    # Plot regression\n    beta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    beta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    print(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\n    xfill = np.array([-4.5,1.5])\n    \n    fig, ax = plt.subplots(figsize=(8, 3.5))\n    ax.tick_params(labelsize=14)\n    \n    # LST data and regression\n    plt.scatter(x_original, y_original, s=12,color='mediumslateblue')\n    plt.plot(x_original, y_pred, color='mediumslateblue', label='LST ODR')\n    plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n    \n    # Comparison regressions\n    xi = np.arange(-7.0,5.0,1.0)\n    plt.plot(xi,xi * sstcalib_m + sstcalib_b,color='k',linewidth=2,label='SST ODR')\n    plt.plot(xi,xi,color='lightcoral',linewidth=2, label='MODIS 1:1')\n        \n    plt.legend(loc='lower right',fontsize=14)\n    plt.text(-2.7,-0.15,rf'$\\mathbf{{y={np.around(beta[0],2)}x+{np.around(beta[1],2)}\\quad r^2={np.around(R2,2)}}}$',color='mediumslateblue', fontweight='bold',fontsize=14)\n    plt.xlim([-3.5,-1.2])\n    plt.ylim([-3.05,0.8])\n    # else: \n    #     plt.plot(x_original, y_pred, color='k', label='NLSST Orthogonal Distance Regression')\n    #     plt.legend(loc='lower right',fontsize=12)\n    #     plt.text(-2.6,-0.2,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\n    #     plt.xlim([-3.2,-0.15])\n    #     plt.ylim([-2.4,0.9]) \n    plt.xlabel('Landsat ST [Â°C]',fontsize=16)\n    plt.ylabel('MODIS SST [Â°C]',fontsize=16)\n    plt.tight_layout()\n\n# Orthoganal Regression for SST only\ndataframes = [\n    ('Combined', lsat_mod_df_n),\n    ('Burke', lsat_mod_df_B),\n    ('Cosgrove', lsat_mod_df_C),\n    ('Dotson', lsat_mod_df_D),\n]\n\nif surf_temp=='LST':\n    landsat_uncertainty = lst_uncertainty\nelse:\n    landsat_uncertainty = sst_uncertainty\n\n# Dictionary to store the results from each DataFrame\nodr_results = {}\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model object\nlinear = Model(linear_model)\n\n# Loop over each DataFrame\nfor df_name, data0 in dataframes:\n    print(f\"\\n=== Processing {df_name} ===\")\n    \n    # Original data\n    x_original = np.array(data0[f'L8_{surf_temp}'])\n    y_original = np.array(data0['MODIS_SST'])\n\n    # Assume these are your uncertainty estimates per observation\n    sy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\n    sx = np.full_like(x_original, landsat_uncertainty)\n    \n    # Create a RealData object using your DataFrame\n    data = RealData(x_original, y_original,sx=sx, sy=sy)\n    \n    # Set up ODR with the model and data, providing an initial guess\n    odr = ODR(data, linear, beta0=[1., 0.])\n    \n    # Run the regression\n    out = odr.run()\n    \n    # Retrieve best-fit parameters and their std. dev.\n    beta = out.beta\n    beta_err = out.sd_beta\n    \n    # Print the summary\n    out.pprint()\n    \n    # Predicting values using the ODR model\n    y_pred = linear_model(beta, x_original)\n    \n    # Get R2\n    # Calculate Total Sum of Squares (SST)\n    y_mean = np.mean(y_original)\n    SST = np.sum((y_original - y_mean)**2)\n    \n    # Calculate Residual Sum of Squares (SSR)\n    SSR = np.sum((y_original - y_pred)**2)\n    \n    # Calculate R^2\n    R2 = 1 - (SSR / SST)\n\n    # Compute RMSE\n    rmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n    \n    # Print R^2\n    print(f\"{df_name} R^2:\", np.around(R2, 2))\n    print(f\"RMSE: {np.around(rmse,2)}\")\n    \n    # Store results in a dictionary for later use (plotting, etc.)\n    odr_results[df_name] = {\n        'beta': beta,\n        'beta_err': beta_err,\n        'R2': R2,\n        'x_original': x_original,\n        'y_original': y_original,\n        'y_pred': y_pred\n    }\n\n# Import the necessary ipywidgets components\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\n# The @interact decorator will automatically create widgets for the function arguments\n@interact(\n    show_burke=widgets.Checkbox(value=True, description=\"Burke Data\"),\n    show_cosgrove=widgets.Checkbox(value=True, description=\"Cosgrove Data\"),\n    show_dotson=widgets.Checkbox(value=True, description=\"Dotson Data\"),\n    show_combined_fit=widgets.Checkbox(value=True, description=\"Combined Fit\"),\n    show_confidence_interval=widgets.Checkbox(value=True, description=\"95% CI\")\n)\ndef interactive_sst_plot(show_burke, show_cosgrove, show_dotson, show_combined_fit, show_confidence_interval):\n    \n    # This is your original code, with plotting commands wrapped in if-statements\n    if surf_temp=='SST':\n        # Your original data calculation code (unchanged)\n        beta_mdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n        beta_mup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n        beta_bdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n        beta_bup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n        a1 = np.around(odr_results['Combined']['beta'][0],2)\n        a2 = np.around(odr_results['Combined']['beta'][1],2)\n        ar = np.around(odr_results['Combined']['R2'],2)\n        b1 = np.around(odr_results['Burke']['beta'][0],2)\n        b2 = np.around(odr_results['Burke']['beta'][1],2)\n        br = np.around(odr_results['Burke']['R2'],2)\n        c1 = np.around(odr_results['Cosgrove']['beta'][0],2)\n        c2 = np.around(odr_results['Cosgrove']['beta'][1],2)\n        cr = np.around(odr_results['Cosgrove']['R2'],2)\n        d1 = np.around(odr_results['Dotson']['beta'][0],2)\n        d2 = np.around(odr_results['Dotson']['beta'][1],2)\n        dr = np.around(odr_results['Dotson']['R2'],2)\n        xfill = np.array([-4.3,0.9])\n\n        # --- Plotting Section ---\n        fig, ax = plt.subplots(figsize=(8, 4)) # Increased height slightly for better text placement\n        ax.tick_params(labelsize=14)\n\n        if show_burke:\n            plt.scatter(np.array(lsat_mod_df_B[f'L8_{surf_temp}']), np.array(lsat_mod_df_B['MODIS_SST']), s=12,color='#00bf7d', label='Burke')\n            plt.plot(odr_results['Burke']['x_original'], odr_results['Burke']['y_pred'], ls='-',linewidth=1,color='#00bf7d')\n            plt.text(-2.9,0.0,f'y={b1}x+{b2}   $r^2$={br}',color='#00bf7d',fontsize=12)\n\n        if show_cosgrove:\n            plt.scatter(np.array(lsat_mod_df_C[f'L8_{surf_temp}']), np.array(lsat_mod_df_C['MODIS_SST']), s=12,color=sns.color_palette(\"colorblind\")[3], label='Cosgrove')\n            plt.plot(odr_results['Cosgrove']['x_original'], odr_results['Cosgrove']['y_pred'], ls='-',linewidth=1,color=sns.color_palette(\"colorblind\")[3])\n            plt.text(-2.9,-0.3,f'y={c1}x+{c2}   $r^2$={cr}',color=sns.color_palette(\"colorblind\")[3],fontsize=12)\n            \n        if show_dotson:\n            plt.scatter(np.array(lsat_mod_df_D[f'L8_{surf_temp}']), np.array(lsat_mod_df_D['MODIS_SST']), s=12,color='#0073e6', label='Dotson')\n            plt.plot(odr_results['Dotson']['x_original'], odr_results['Dotson']['y_pred'], ls='-',linewidth=1,color='#0073e6')\n            plt.text(-2.9,-0.6,f'y={d1}x+{d2}   $r^2$={dr}',color='#0073e6',fontsize=12)\n\n        if show_combined_fit:\n            plt.plot(odr_results['Combined']['x_original'], odr_results['Combined']['y_pred'], color='k')\n            plt.text(-2.9,0.3,f'y={a1}x+{a2}   $r^2$={ar}',color='k',fontsize=14)\n            if show_confidence_interval:\n                plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n\n        # General plot labels and limits (unchanged)\n        plt.xlim([-3.05,-0.15])\n        plt.ylim([-2.3,0.9])\n        plt.xlabel('Landsat SST [Â°C]',fontsize=16)\n        plt.ylabel('MODIS SST [Â°C]',fontsize=16)\n        plt.legend(loc='lower right',fontsize=10)\n        plt.tight_layout()\n        plt.show() # Make sure to show the plot\n\nodr_results['Combined']['beta_err']\n\nif surf_temp=='SST':\n    # Ordinary least squares regression between Landsat and MODIS SST matchups\n    resultC = sm.ols(formula=\"MODIS_SST ~ L8_SST\", data=data0).fit()\n    print (resultC.summary())\n\n","type":"content","url":"/notebooks/calibration#calculate-calibration-bias-and-trend","position":19},{"hierarchy":{"lvl1":"Calibration","lvl3":"Interactive Analysis Dashboard using Matplotlib","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#interactive-analysis-dashboard-using-matplotlib","position":20},{"hierarchy":{"lvl1":"Calibration","lvl3":"Interactive Analysis Dashboard using Matplotlib","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Imports for Interactive Dashboard\nimport ipywidgets as widgets\nfrom ipywidgets import interact, Layout\n\n# Matplotlib-based Interactive Dashboard Function\n\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\ndef interactive_calibration_dashboard_matplotlib(region, chart_type, pix_thresh, modis_sst_thresh, lsat_sst_thresh):\n    # 1. & 2. Data filtering and selection (Same as your original code)\n    df_C_filt = lsat_mod_df_C[(lsat_mod_df_C['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_C['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_C[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_C_filt['Region'] = 'Cosgrove'\n\n    df_D_filt = lsat_mod_df_D[(lsat_mod_df_D['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_D['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_D[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_D_filt['Region'] = 'Dotson'\n\n    df_B_filt = lsat_mod_df_B[(lsat_mod_df_B['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_B['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_B[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_B_filt['Region'] = 'Burke'\n\n    if region == 'All Regions':\n        df_filtered = pd.concat([df_B_filt, df_C_filt, df_D_filt])\n    elif region == 'Cosgrove':\n        df_filtered = df_C_filt\n    elif region == 'Dotson':\n        df_filtered = df_D_filt\n    elif region == 'Burke':\n        df_filtered = df_B_filt\n    \n    # Create the figure and axis for the plot\n    fig, ax = plt.subplots(figsize=(8, 6))\n\n    if len(df_filtered) < 2:\n        ax.text(0.5, 0.5, \"Not enough data with the current filter settings.\", ha='center', va='center')\n        ax.set_axis_off()\n        plt.show()\n        return\n\n    # 3. ODR Calculation (Same as your original code)\n    x_data = df_filtered[f'L8_{surf_temp}'].values\n    y_data = df_filtered['MODIS_SST'].values\n    sx = np.full_like(x_data, sst_uncertainty)\n    sy = np.full_like(y_data, modis_uncertainty * pix_uncertainty)\n    model = Model(linear_model)\n    data = RealData(x_data, y_data, sx=sx, sy=sy)\n    odr = ODR(data, model, beta0=[1., 0.])\n    output = odr.run()\n    slope, intercept = output.beta\n    y_pred = linear_model(output.beta, x_data)\n\n    # 4. Statistics Calculation (Same as your original code, but formatted for Matplotlib title)\n    bias = np.mean(y_data - x_data)\n    trend = slope\n    ss_total = np.sum((y_data - np.mean(y_data))**2)\n    ss_resid = np.sum((y_data - y_pred)**2)\n    r2 = 1 - (ss_resid / ss_total) if ss_total > 0 else 0\n    rmse = np.sqrt(np.mean((y_data - y_pred)**2))\n    # Note: Matplotlib title doesn't support HTML bold tags, so they are removed.\n    stats_text = (f\"Trend (Slope): {trend:.2f} | Bias (MODIS - Landsat): {bias:.2f}Â°C\\n\"\n                  f\"RÂ²: {r2:.2f} | RMSE: {rmse:.2f} | N: {len(df_filtered)}\")\n\n    # 5. Create Matplotlib figure based on chart_type\n    if chart_type == 'Scatter':\n        # Seaborn's scatterplot is a great way to handle coloring by category easily\n        sns.scatterplot(data=df_filtered, x=f'L8_{surf_temp}', y='MODIS_SST', hue='Region', ax=ax, s=50)\n    elif chart_type == 'Heatmap':\n        ax.hist2d(df_filtered[f'L8_{surf_temp}'], df_filtered['MODIS_SST'], bins=20, cmap='viridis')\n        fig.colorbar(ax.collections[0], ax=ax, label='Point Density')\n\n    # Add regression line\n    sorted_indices = np.argsort(x_data)\n    ax.plot(x_data[sorted_indices], y_pred[sorted_indices], color='black', linewidth=2, label='ODR Fit')\n\n    # Set titles, labels, and limits\n    ax.set_title(stats_text)\n    ax.set_xlabel(\"Landsat SST [Â°C]\")\n    ax.set_ylabel(\"MODIS SST [Â°C]\")\n    ax.set_xlim(-3.05, -0.15)\n    ax.set_ylim(-2.3, 0.9)\n    ax.legend()\n    ax.grid(True, linestyle='--', alpha=0.6)\n    \n    plt.show()\n\n# Define Widgets\nstyle = {'description_width': 'initial'}\nw_region = widgets.Dropdown(options=['All Regions', 'Cosgrove', 'Dotson', 'Burke'], value='All Regions', description='Select Region:', style=style)\nw_chart_type = widgets.ToggleButtons(options=['Scatter', 'Heatmap'], description='Chart Type:', button_style='info')\nw_pix_thresh = widgets.IntSlider(value=1300, min=0, max=5000, step=100, description='Min MODIS Pixels:', style=style, layout=Layout(width='500px'))\nw_modis_sst = widgets.FloatSlider(value=-1.9, min=-2.5, max=0, step=0.1, description='Min MODIS SST (Â°C):', style=style, layout=Layout(width='500px'))\nw_lsat_sst = widgets.FloatSlider(value=-3.1, min=-4.0, max=0, step=0.1, description='Min Landsat SST (Â°C):', style=style, layout=Layout(width='500px'))\n\n\n# Launch the new Matplotlib-based Dashboard\ninteract(interactive_calibration_dashboard_matplotlib, \n         region=w_region, \n         chart_type=w_chart_type,\n         pix_thresh=w_pix_thresh, \n         modis_sst_thresh=w_modis_sst, \n         lsat_sst_thresh=w_lsat_sst);","type":"content","url":"/notebooks/calibration#interactive-analysis-dashboard-using-matplotlib","position":21},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Preprocessing data"},"type":"lvl1","url":"/notebooks/preprocessing","position":0},{"hierarchy":{"lvl1":"Preprocessing data"},"content":"%pip install -q intake-stac\n\n","type":"content","url":"/notebooks/preprocessing","position":1},{"hierarchy":{"lvl1":"Preprocessing data","lvl2":"Preprocessing"},"type":"lvl2","url":"/notebooks/preprocessing#preprocessing","position":2},{"hierarchy":{"lvl1":"Preprocessing data","lvl2":"Preprocessing"},"content":"\n\nOnce you have acquired your data, the next step is preprocessingâ€”preparing the data for computing the retrieval and generating the final data product. Preprocessing will include one or more of the following tasks:\n\nCleaning\n\nUnit conversion\n\nReprojection\n\nRegridding\n\nNormalization\n\nEach of these steps helps standardize the data so it can be combined, compared, or analyzed reliably.","type":"content","url":"/notebooks/preprocessing#preprocessing","position":3},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"ðŸ”§ Preprocessing Steps","lvl2":"Preprocessing"},"type":"lvl3","url":"/notebooks/preprocessing#id-preprocessing-steps","position":4},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"ðŸ”§ Preprocessing Steps","lvl2":"Preprocessing"},"content":"ðŸ”¹ Cleaning\n\nData cleaning is required when the dataset contains missing values, outliers, or artifacts that could bias the analysis. This might include filtering NaNs, removing physically impossible values, or masking bad pixels.\n\nTo clean the data, you typically:\n\nIdentify invalid or missing values.\n\nMask or remove unreliable data.\n\nOptionally, interpolate or fill gaps as needed.\n\nðŸ“š \n\nTutorial: Data Cleaning with Pandas and NumPy (RealPython)\n\nðŸ”¹ Unit Conversion\n\nUnit conversion is needed when datasets use different physical units (e.g., Kelvin vs. Celsius, W/mÂ² vs. mW/cmÂ²) or when preparing inputs for physical equations that require standardized units.\n\nThis may also require spatial integration (e.g., converting a flux to energy) to match units over time and space.\n\nðŸ“š \n\nPint Documentation â€“ Units in Python\n\nðŸ”¹ Reprojection\n\nReprojection is required when datasets are provided in different coordinate reference systems (CRS). Working with mismatched projections can lead to spatial misalignmentâ€”features may not overlap or align correctly.\n\nTo reproject data:\n\nDetermine the CRS of each dataset.\n\nUse geospatial tools to transform to a common projection.\n\nðŸ“š \n\nPyproj Documentation\n\nðŸ”¹ Regridding\n\nRegridding is used when datasets have different spatial resolutions or grid layouts and need to be brought onto a common grid. For example, satellite data may be on a swath-based grid while model output is on a regular latitude-longitude grid.\n\nThis step ensures datasets are co-located in space and is critical for any pixel-wise comparison or combination.\n\nðŸ“š \n\nxESMF for Regridding\n\nðŸ”¹ Normalization\n\nNormalization rescales data so that it is on a consistent numerical scale, especially important when combining variables with different units or orders of magnitude as inputs to a model (e.g., temperature vs. elevation vs. reflectance).\n\nFor example, normalizing input features before passing them into a machine learning model helps ensure each variable contributes proportionally.\n\nðŸ“š \n\nscikit-learn Preprocessing: Normalization and Scaling\n\nIn the Sea Surface Temperature (SST) workflow demonstrated in this cookbook, we will be using all of the preprocessing steps.\n\n","type":"content","url":"/notebooks/preprocessing#id-preprocessing-steps","position":5},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Read in Landsat thermal data","lvl2":"Preprocessing"},"type":"lvl3","url":"/notebooks/preprocessing#read-in-landsat-thermal-data","position":6},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Read in Landsat thermal data","lvl2":"Preprocessing"},"content":"Letâ€™s begin by reading in the data we acquired previously in the Data Access notebook.\n\nWe read in all paths and parameters\n\ncd /home/jovyan/landsatproduct-cookbook/\n\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pathlib import Path\nimport os\nimport boto3\nfrom rasterio.session import AWSSession\nimport earthaccess\nimport intake\nimport xarray as xr\nfrom shapely.geometry.polygon import Polygon\nimport geopandas as gpd\n\nimport SSTutils as stu\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Define the landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\n\n# For atm correction\nbasepath = Path('/home/jovyan/Landsat_SST_algorithm')\nlsatpath = basepath / 'Data'\natmpath = lsatpath / 'AtmCorrection'\nmodout_path = lsatpath / 'MOD07_L2'\n\nWV = 'Water_Vapor'\n\n# For search and tile plot for Landsat\nsatellite = 'Landsat8'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1 - includes L8 and L9\ncolnm = ['landsat:wrs_path','landsat:wrs_row']\ngjson_outfile = lsatpath / f'{satellite}.geojson'\n\n# # For scene search and plot\n\ninterp = 1\n\nregion = 'Cosgrove'\n\nif region=='Cosgrove':\n    SSTpath = lsatpath / 'SST/MODcalib/Cosgrove/'\n    bbox = (-103.0, -73.5, -102.0, -73.42) # LatboundsC from LandsatCalibration20201031\n    # Cosgrove full run \n    timeRange = '2021-09-01/2023-04-07'\n    # [0:1] Cosgrove bbox\n    # timeRange = '2022-11-01/2023-03-27'\nelif region=='DotsonPolynya':\n    SSTpath = lsatpath / 'SST/MODcalib/DotsonPolynya/'\n    bbox = (-113, -73.9, -111.5, -73.59) # Dotson polynya\n    # Dotson full run\n    timeRange = '2021-09-01/2023-05-31'\n    # [0:1] Dotson bbox\n    # timeRange = '2022-11-01/2023-03-27'\nelif region=='PineIslandPlume':\n    SSTpath = lsatpath / 'SST/UncalibratedSST/PineIslandPlume/'\n    bbox = (-101.98,-75.09,-101.65,-75.05) # PIG plume for analysis - 2014\n    # bbox = (-101.88,-75.23,-100.35,-74.76) # PIG ice front for analysis\n    # bbox = (-101.8,-75.23,-100.50,-74.80) # PIG 2019?\n    # PIG full run - NOT narrowed down yet\n    timeRange = '2021-09-01/2023-04-07'\nelif region=='DotsonIntercomp':\n    SSTpath = lsatpath / 'SST/Validation/DotsonIntercomp/'\n    bbox = (-113.5,-74.20,-113.17,-74.11) # Dotson plume for analysis\n    # Dotson intercomp run\n    timeRange = '2021-09-01/2023-03-31'\nelif region=='Burke':\n    SSTpath = lsatpath / 'SST/MODcalib/Burke/'\n    bbox = (-104.2,-73.81, -103.8, -73.42) # Outside Cosgrove south of Burke  \n    # Burke full run\n    timeRange = '2021-09-01/2023-04-06'\n\nWe set up authentication for accessing all data\n\n# Authenticate for boto S3 access, etc.\nos.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\naws_session = AWSSession(boto3.Session(), requester_pays=True)\n\n# Setup and authenticate dask\nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient\n\n# Authenticate for accessing NASA data (MODIS)\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for desired Landsat scenes\nitems = stu.search_stac(url, collection, gjson_outfile=gjson_outfile, bbox=bbox, timeRange=timeRange)\n\n# Open stac catalog for some needed info\ncatalog = intake.open_stac_item_collection(items)\n\n# Load the geojson file\ngf = gpd.read_file(gjson_outfile)\n\n# Plot tiles of all scenes found\nstu.plot_search(gf,satellite,colnm)\n\nNote the bands you would like to include are assigned by passing the bandNames parameter to landsat_to_xarray using the following codes:\n\nâ€˜coastalâ€™, â€˜blueâ€™, â€˜greenâ€™, â€˜redâ€™, â€˜nir08â€™, â€˜swir16â€™, â€˜swir22â€™, â€˜panâ€™, â€˜cirrusâ€™, â€˜lwir11â€™, â€˜lwir12â€™, â€˜qa_pixelâ€™\n\n","type":"content","url":"/notebooks/preprocessing#read-in-landsat-thermal-data","position":7},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Process Landsat scenes to acquire sea surface temperature","lvl2":"Preprocessing"},"type":"lvl3","url":"/notebooks/preprocessing#process-landsat-scenes-to-acquire-sea-surface-temperature","position":8},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Process Landsat scenes to acquire sea surface temperature","lvl2":"Preprocessing"},"content":"\n\n# Convert bounding box to polar for checking if landsat has any data in bounding box\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the file\n\nsbox,checkbox = stu.lsat_reproj(source_crs,target_crs,(bbox[0],bbox[1],bbox[2],bbox[3]))\n\n# Create polygon for later cropping\npolygon = Polygon([(sbox[0][0],sbox[0][1]),(sbox[3][0],sbox[3][1]),(sbox[2][0],sbox[2][1]),(sbox[1][0],sbox[1][1])])\n\n# Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\nminx, miny, maxx, maxy = polygon.bounds\npolarx = [minx, maxx]\npolary = [miny, maxy]\n\n# Include only Landsat 8 scenes\ncatalog_list = [x for x in items if x.id[3]=='8']\n\nsceneid = catalog_list[0]\nprint(sceneid.id)\n    \nscene = catalog[sceneid.id]\ntimestr = scene.metadata['datetime'].strftime('%H%M%S')\n\noutFile = f'{SSTpath}/{sceneid.id}_{timestr}_Cel.tif'\n\n# Open all desired bands for one scene\nls_scene = stu.landsat_to_xarray(sceneid,catalog)\nls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n\n","type":"content","url":"/notebooks/preprocessing#process-landsat-scenes-to-acquire-sea-surface-temperature","position":9},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Masking Unwanted Pixels in Landsat Thermal Imagery","lvl2":"Preprocessing"},"type":"lvl3","url":"/notebooks/preprocessing#masking-unwanted-pixels-in-landsat-thermal-imagery","position":10},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Masking Unwanted Pixels in Landsat Thermal Imagery","lvl2":"Preprocessing"},"content":"In our Landsat SST algorithm, the first preprocessing step is to ensure that we only process ocean pixels.\n\nWhy?Thermal infrared measurements are highly sensitive to atmospheric effects, particularly water vapor, and cannot provide accurate surface temperature if clouds are present.Additionally, we donâ€™t want SST from land or ice pixels.\n\nThis means our first preprocessing task is maskingâ€”identifying and excluding pixels that shouldnâ€™t be processed.","type":"content","url":"/notebooks/preprocessing#masking-unwanted-pixels-in-landsat-thermal-imagery","position":11},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Sources for Pixel Classification","lvl2":"Preprocessing"},"type":"lvl3","url":"/notebooks/preprocessing#sources-for-pixel-classification","position":12},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Sources for Pixel Classification","lvl2":"Preprocessing"},"content":"Landsat imagery includes a qa_pixel band with bit flags that encode surface classification for each pixel.\n\nWe can:\n\nUse the qa_pixel band to mask unwanted pixels (our approach here).\n\nReplace or augment with a machine learning classifier (e.g., neural network) for more accurate cloud detection.\n\nNote: The standard Landsat cloud classification is not well-suited for detecting certain types of cloud. ML-based classifiers often outperform it for certain conditions.","type":"content","url":"/notebooks/preprocessing#sources-for-pixel-classification","position":13},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Step 1 â€“ Inspect the QA Band","lvl2":"Preprocessing"},"type":"lvl3","url":"/notebooks/preprocessing#step-1-inspect-the-qa-band","position":14},{"hierarchy":{"lvl1":"Preprocessing data","lvl3":"Step 1 â€“ Inspect the QA Band","lvl2":"Preprocessing"},"content":"Letâ€™s first inspect whatâ€™s inside the QA band:\n\nqa = ls_scene.sel(band='qa_pixel').astype('uint16')\nunique_values, counts = np.unique(qa, return_counts=True)\nprint(\"Unique QA codes:\", unique_values)\n\ncd /home/jovyan/landsatproduct-cookbook/\n\ndef create_masks(ls_scene, cloud_mask=True, ice_mask=False, ocean_mask=False):\n    \"\"\"\n    Creates cloud, ice, and ocean masks from a Landsat scene QA band. By default, \n    clouds are labeled as 1, ice as 2, ocean as 3, and all other pixels are NaN.\n\n    Parameters\n    ----------\n    ls_scene : xarray.DataArray\n        A Landsat scene loaded with a 'qa_pixel' band (as created by `landsat_to_xarray`).\n    cloud_mask : bool, optional\n        Whether to generate the cloud mask. Default is True.\n    ice_mask : bool, optional\n        Whether to generate the ice mask. Default is False.\n    ocean_mask : bool, optional\n        Whether to generate the ocean mask. Default is False.\n\n    Returns\n    -------\n    xarray.DataArray\n        The same input xarray object, but with an added `\"mask\"` coordinate. \n        In that mask, cloud pixels are assigned 1, ice pixels 2, ocean pixels 3, \n        and everything else is set to NaN.\n    \"\"\"\n    \n    cloud = []\n    ocean = []\n    ice = []\n\n    qa = ls_scene.sel(band='qa_pixel').astype('uint16')\n\n    n,c = np.unique(qa, return_counts=True)\n\n    for j in range(len(n)):\n        longform = f'{n[j]:016b}'\n        if (longform[-7]=='0')|(longform[-3]=='1'): #bit 2 and 6 are for cirrus and clear sky\n            cloud.append(n[j])\n        if longform[-8:]=='11000000': #bit 6 and 7 give clear sky and water, lower bits need to be 0 \n            ocean.append(n[j])\n        if longform[-7:]=='1100000': #bit 5 and 6 give ice and clear sky \n            ice.append(n[j])\n\n    if 0 in cloud:\n        cloud.remove(0)\n    if 1 in cloud:\n        cloud.remove(1)\n\n    # mask cloud, ice, and ocean\n    if cloud_mask==True:\n        # cloud is 2\n        mask_c = xr.where(qa.isin(cloud), 1, np.nan)\n\n    if ice_mask==True:\n        mask_c = xr.where(qa.isin(ice), 2, mask_c)\n\n    if ocean_mask==True:\n        mask_c = xr.where(qa.isin(ocean), 3, mask_c)\n\n    ls_scene.coords['mask'] = (('y', 'x'), mask_c.data)\n        \n    return ls_scene\n\n##########################\n\ndef normalize(array):\n    '''\n    normalize a dask array so all value are between 0 and 1\n    '''\n    array_min = array.min(skipna=True)\n    array_max = array.max(skipna=True)\n    return (array - array_min) / (array_max - array_min)\n\n##########################\n\ndef search_stac(url, collection, gjson_outfile=None, bbox=None, timeRange=None, filename=None):\n    \"\"\"\n    Search a STAC API for Landsat images based on either:\n    - Bounding box and time range, or\n    - Specific filename (STAC 'id').\n\n    Parameters:\n    -----------\n    url : str\n        URL to the STAC API.\n    collection : str\n        Collection name (e.g., \"landsat-c2-l2\").\n    gjson_outfile : str or None\n        Output file to save the search result as GeoJSON (optional).\n    bbox : list or None\n        Bounding box [west, south, east, north] (optional).\n    timeRange : str or None\n        Time range in ISO format, e.g., '2021-09-01/2023-03-31' (optional).\n    filename : str or None\n        Exact filename (product ID) to search for (optional).\n\n    Returns:\n    --------\n    item_collection : pystac.ItemCollection\n        Collection of matching STAC items.\n    \"\"\"\n    \n    api = pystac_client.Client.open(url)\n\n    if filename:\n        # Search by filename (ID)\n        search = api.search(\n            collections=[collection],\n            ids=[filename],\n        )\n        # print(f\"Searching for filename: {filename}\")\n    \n    elif bbox and timeRange:\n        # Search by bbox and timeRange\n        search = api.search(\n            bbox=bbox,\n            datetime=timeRange,\n            collections=[collection],\n        )\n        # print(f\"Searching for items in bbox {bbox} and timeRange {timeRange}\")\n    \n    else:\n        raise ValueError(\"Must provide either a filename, or both bbox and timeRange.\")\n\n    items = search.item_collection()\n\n    # print(f\"Found {len(items)} item(s)\")\n\n    if gjson_outfile:\n        items.save_object(gjson_outfile)\n    \n    return items","type":"content","url":"/notebooks/preprocessing#step-1-inspect-the-qa-band","position":15},{"hierarchy":{"lvl1":"Validation"},"type":"lvl1","url":"/notebooks/validation-p2","position":0},{"hierarchy":{"lvl1":"Validation"},"content":"","type":"content","url":"/notebooks/validation-p2","position":1},{"hierarchy":{"lvl1":"Validation","lvl2":"The Principle of Validation"},"type":"lvl2","url":"/notebooks/validation-p2#the-principle-of-validation","position":2},{"hierarchy":{"lvl1":"Validation","lvl2":"The Principle of Validation"},"content":"Validation in remote sensing is the process of independently assessing the accuracy of a data product. It is a very essential step that builds and quantifies the uncertainty of satellite-derived products.","type":"content","url":"/notebooks/validation-p2#the-principle-of-validation","position":3},{"hierarchy":{"lvl1":"Validation","lvl3":"Why Do We Validate?","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation-p2#why-do-we-validate","position":4},{"hierarchy":{"lvl1":"Validation","lvl3":"Why Do We Validate?","lvl2":"The Principle of Validation"},"content":"Satellites donâ€™t measure physical properties like temperature directly. They measure radiated energy, and we utilize complex models and algorithms to convert that energy measurement into a useful product, such as Sea Surface Temperature (SST). Validation is crucial for several reasons:\n\nQuantify Accuracy: Validation will provide a measure of success on how close the satellite product is to the ground-truth value (e.g., â€œaccurate to within Â±0.5Â°Câ€).\n\nIdentify and Correct Bias: This step can reveal various systematic errors where the satellite consistently measures too high or too low (spatial and temporal).\n\nUnderstand Limitations: Validation also helps define the conditions under which the product is reliable (e.g., â€œaccurate in open water but less so near coastlinesâ€). This would help other scientists or organizations to use the satellite data for climate modeling, weather forecasting, or policymaking.\n\n","type":"content","url":"/notebooks/validation-p2#why-do-we-validate","position":5},{"hierarchy":{"lvl1":"Validation","lvl3":"Possible Methods for Validation:","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation-p2#possible-methods-for-validation","position":6},{"hierarchy":{"lvl1":"Validation","lvl3":"Possible Methods for Validation:","lvl2":"The Principle of Validation"},"content":"Validation involves comparing the satellite product to ground truth data or any source data.\n\nPoint-to-Point Validation: This is the most common method and uses a high-quality in-situ measurement (like from a weather station, buoy, or Argo float for SST) and compares it to the value of the satellite pixel at the same location and time.\n\nSpatial Comparison: This method assesses how well the satellite captures spatial patterns. You compare the satellite image to a high-resolution map from another trusted source.\n\nCross-Satellite Comparison: This technique compares three independent datasets (e.g., your new product, another satellite product, and ground truth data) to estimate the error of each one.","type":"content","url":"/notebooks/validation-p2#possible-methods-for-validation","position":7},{"hierarchy":{"lvl1":"Validation","lvl3":"Statistical Tools:","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation-p2#statistical-tools","position":8},{"hierarchy":{"lvl1":"Validation","lvl3":"Statistical Tools:","lvl2":"The Principle of Validation"},"content":"To quantify the comparison, there is a standard set of statistical metrics:\n\nBias: The average difference between the satellite and ground truth data. It tells you if the product is systematically high or low.      Bias = mean (Satellite - GroundTruth)\n\nRoot Mean Square Error (RMSE): This is the most important metric that measures the typical magnitude of the error, regardless of whether it is positive or negative.      RMSE = sqrt (mean ((Satellite - GroundTruth)Â²))\n\nStandard Deviation: This measures the consistency of the error and a low standard deviation means the error is predictable.\n\nCorrelation Coefficient (r or RÂ²): This measures the degree to which the satellite data trends with the ground truth data.\n\nRegression Analysis for Cross-Validation: This can be achieved by plotting the satellite data (y-axis) against the ground truth data (x-axis) and fitting a linear regression line. In a perfect world, this line would be y = 1x + 0 (the 1:1 line). The actual slope and intercept reveal systematic biases.\n\n","type":"content","url":"/notebooks/validation-p2#statistical-tools","position":9},{"hierarchy":{"lvl1":"Validation","lvl3":"Steps in the Validation.pynb code:","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation-p2#steps-in-the-validation-pynb-code","position":10},{"hierarchy":{"lvl1":"Validation","lvl3":"Steps in the Validation.pynb code:","lvl2":"The Principle of Validation"},"content":"The proposed method developed a specific algorithm to derive SST from Landsat 8 data, which involves a cross-calibration with MODIS. The source code for the book is \n\nreleased on GitHub repository. The primary objective is to demonstrate that this specific method yields accurate results, particularly in the areas of study. In the validation script, there are several steps to consider:\n\nGround Truth Data: Systematically searches the iQuam dataset to find high-quality temperature measurements from Argo floats in Antarctica.\n\nSatellite Data: For each Argo measurement, it searches the Landsat STAC catalog to find a satellite image of the same location taken within Â±12 hours, which is called a â€œmatchup.â€\n\nProcess: Processes the Landsat image using its algorithm to create an SST value and then directly compares this value to the Argo floatâ€™s dataset.\n\nThe code implements the key statistical methods to assess the results of this comparison:\n\nData Compilation: It first gathers all the matchups into a single pandas DataFrame called valids.\n\nBias and Mean Difference: It calculates the mean values for both L8_SST and Argo_SST to get a general sense of the bias.\n\nScatter Plot and Regression: It plots Argo SST on the x-axis (ground truth) and Landsat SST on the y-axis (satellite product) and performs an Orthogonal Distance Regression (ODR), which is a robust form of linear regression, to find the best-fit line through the data points. It calculates and displays the RÂ² value and RMSE to quantify the average error of their product. By doing this, the code provides a comprehensive and statistically sound validation of the new Landsat SST product, demonstrating its accuracy and reliability.\n\n","type":"content","url":"/notebooks/validation-p2#steps-in-the-validation-pynb-code","position":11},{"hierarchy":{"lvl1":"Validation","lvl3":"Sample Validation Result","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation-p2#sample-validation-result","position":12},{"hierarchy":{"lvl1":"Validation","lvl3":"Sample Validation Result","lvl2":"The Principle of Validation"},"content":"Put a code box!\n\n","type":"content","url":"/notebooks/validation-p2#sample-validation-result","position":13},{"hierarchy":{"lvl1":"Validation","lvl2":"What is Next?"},"type":"lvl2","url":"/notebooks/validation-p2#what-is-next","position":14},{"hierarchy":{"lvl1":"Validation","lvl2":"What is Next?"},"content":"A Multivariate Regression model was used in the current work for Sea Surface Temperature modeling. The regression-based models typically present some results based on the residual values of modeled vs observed values. There are a lot of metrics available for the interpretation of results and showing the accuracy of the model. It can be noted that there are other methods, including some Machine Learning classification methods, that can be used for SST analysis to provide a better understanding of the physical processes contributing to SST values. Moreover, spatial analysis can be done by these models, besides having some spatial error or deviation mapping for the regression models.","type":"content","url":"/notebooks/validation-p2#what-is-next","position":15},{"hierarchy":{"lvl1":"Validation","lvl3":"Advanced Methods for Deeper Understanding","lvl2":"What is Next?"},"type":"lvl3","url":"/notebooks/validation-p2#advanced-methods-for-deeper-understanding","position":16},{"hierarchy":{"lvl1":"Validation","lvl3":"Advanced Methods for Deeper Understanding","lvl2":"What is Next?"},"content":"While regression models are excellent for prediction, other advanced methods can provide a more nuanced understanding of the physical processes and spatial dynamics of SST.\n\nMachine Learning Classification Methods:\n\nInstead of predicting the exact SST value, Machine Learning (ML) classification models can be used to identify and categorize distinct oceanographic features or thermal regimes. An ML model, such as a Random Forest or Support Vector Machine (SVM), can be trained on satellite data to recognize the unique signatures of different water masses. For example, it can learn to distinguish between a warm coastal current, a cold upwelling zone, and a stable open-ocean gyre based on a combination of SST, salinity, and sea surface height data. This approach moves beyond a single temperature value to provide a qualitative understanding of the SSTâ€™s concept. It can automatically map complex features that are crucial for understanding heat transport in marine ecosystems.\n\nSpatial Analysis and Error Mapping:\n\nStandard regression metrics provide a single accuracy number for the entire study area, but they donâ€™t reveal where the model performs well or poorly. Instead of averaging the residuals, they can be plotted at their geographic locations creating a spatial error map. Geostatistical tools can then be used to test for spatial autocorrelation, revealing if high or low errors are clustered together. This is critical for understanding model limitations, while an error map might show that a regression model performs very well in some regions but consistently fails near complex coastlines or river mouths. This insight is lost in non-spatial metrics and is vital for improving the model and correctly interpreting its outputs.\n\n","type":"content","url":"/notebooks/validation-p2#advanced-methods-for-deeper-understanding","position":17},{"hierarchy":{"lvl1":"Validation","lvl2":"Sample Visualization Mapping Result"},"type":"lvl2","url":"/notebooks/validation-p2#sample-visualization-mapping-result","position":18},{"hierarchy":{"lvl1":"Validation","lvl2":"Sample Visualization Mapping Result"},"content":"We can produce higher spatial resolution error maps if we have more validation data. So, these current maps are just based on a 5Â° resolution grid and show that tropical regions have higher standard deviation and lower bias error values because of higher water vapor and dust aerosols.\n\n","type":"content","url":"/notebooks/validation-p2#sample-visualization-mapping-result","position":19},{"hierarchy":{"lvl1":"Validation","lvl2":"Producing higher spatial resolution mapping results"},"type":"lvl2","url":"/notebooks/validation-p2#producing-higher-spatial-resolution-mapping-results","position":20},{"hierarchy":{"lvl1":"Validation","lvl2":"Producing higher spatial resolution mapping results"},"content":"","type":"content","url":"/notebooks/validation-p2#producing-higher-spatial-resolution-mapping-results","position":21},{"hierarchy":{"lvl1":"Validation","lvl3":"What is the common spatial resolution for SST error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"type":"lvl3","url":"/notebooks/validation-p2#what-is-the-common-spatial-resolution-for-sst-error-mapping","position":22},{"hierarchy":{"lvl1":"Validation","lvl3":"What is the common spatial resolution for SST error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"content":"The current 5Â° resolution grid mapping for spatial error analysis is somewhat coarse for model evaluation purposes. Therefore, there is a need to enhance the spatial evaluation in SST modeling.","type":"content","url":"/notebooks/validation-p2#what-is-the-common-spatial-resolution-for-sst-error-mapping","position":23},{"hierarchy":{"lvl1":"Validation","lvl3":"How to improve spatial resolution error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"type":"lvl3","url":"/notebooks/validation-p2#how-to-improve-spatial-resolution-error-mapping","position":24},{"hierarchy":{"lvl1":"Validation","lvl3":"How to improve spatial resolution error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"content":"By having more validation data for validating the Landsat (30m) SST product, we would be able to apply more advanced models to improve spatial error mapping results. One method would be to train an ML model (e.g. Random Forest (RF), and Gradient Boosting Regressor (GBR)) algorithms on the validated pixels and then produce the error mapping with finer resolution to have an improved spatial mapping of the results. (\n\nGitHub Link1, \n\nGitHub Link2).\n\nHaving the data fused with higher spatial error mapping would enable us to better understand the reliability of our high-resolution SST map by moving beyond a single accuracy evaluation. It would also help reveal more precisely where the proposed model works well and where it fails. Here is a sample demonstration of our expected results for the next step.","type":"content","url":"/notebooks/validation-p2#how-to-improve-spatial-resolution-error-mapping","position":25},{"hierarchy":{"lvl1":"Validating your data product"},"type":"lvl1","url":"/notebooks/validation-step1","position":0},{"hierarchy":{"lvl1":"Validating your data product"},"content":"#%pip install xarray==2024.05.0\n\n# Imports\n#%pip install pykrige\n#%pip install xarray\n# %pip install xarray==2024.05.0\n\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\nfrom mpl_toolkits.mplot3d import Axes3D\n#from skimage import exposure\n#from skimage.io import imsave, imread\n#from osgeo import ogr\nimport pystac_client\nfrom pyproj import Transformer\nfrom datetime import date, timedelta, datetime\nfrom dateutil.relativedelta import relativedelta\nimport geopandas as gpd\nimport pandas as pd\nimport geoviews as gv\nimport hvplot.pandas\nimport intake\nimport xarray as xr\nimport numpy as np\nfrom numpy.random import default_rng\nimport intake\nfrom pyproj import Proj, transform\n#from osgeo import gdal\nfrom sklearn.neighbors import BallTree\nimport earthaccess\nimport gzip\nimport s3fs\n\n# for progress bar\nfrom ipywidgets import IntProgress\nfrom IPython.display import display\nfrom ipywidgets import interact, Dropdown\nimport time\nfrom tqdm.notebook import trange, tqdm\n\nimport boto3\nimport rasterio as rio\nfrom rasterio.features import rasterize\nfrom rasterio.session import AWSSession\nimport dask\nimport os\nimport rioxarray\nfrom rasterio.enums import Resampling\nfrom rasterio.warp import reproject\nfrom rasterio.warp import Resampling as resample\nimport cartopy.crs as ccrs\nimport cartopy\n#from pykrige.ok import OrdinaryKriging\nfrom sklearn.linear_model import LinearRegression, RANSACRegressor\nfrom scipy.odr import Model, RealData, ODR\nimport scipy.odr as odr\nimport scipy\nimport statsmodels.formula.api as smf\nfrom shapely.geometry.polygon import Polygon, Point\nimport pygmt\nimport gc\nimport pytz\nimport pyproj\nimport math\nfrom pathlib import Path\nfrom matplotlib.patches import Polygon as Pgon\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\n\nimport SSTutils as sut\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","type":"content","url":"/notebooks/validation-step1","position":1},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Why do we need to validate?"},"type":"lvl3","url":"/notebooks/validation-step1#why-do-we-need-to-validate","position":2},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Why do we need to validate?"},"content":"Now we have our calibrated SST data product! ðŸ¥³ Weâ€™re almost ready to use this data product for our scientific analysis, but there is still one more important step. As a quick reminder, our data product was derived from top-of-atmosphere radiance measurements. We then converted these radiances into actual SST values (in units of temperature) by calibrating with another satellite (MODIS). But can we trust that these derived SST values are accurately reflecting real ocean surface temperatures? Validation allows us to quantitfy the uncertainty of our product.\n\n","type":"content","url":"/notebooks/validation-step1#why-do-we-need-to-validate","position":3},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data to validate with"},"type":"lvl3","url":"/notebooks/validation-step1#finding-data-to-validate-with","position":4},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data to validate with"},"content":"When validating satellite products, we typically want to use in situ measurements: i.e., direct measurements taken in the field. For the ocean, these measurements come from buoys, ship-based thermometers and autonomous floats. An important thing to keep in mind is that while satellites measure the skin temperature (top ~10â€“20 microns), in situ platforms measure bulk SST (a few cm to 1 m depth).\n\nShould be high quality!\n\nFinding a good validation dataset can be tricky. Hereâ€™s are some lists of commonly-used validation datasets to help get you started:\n\nTO DO: These links need to be checked\n\nðŸŒŠ Ocean\n\nDataset\n\nAccess\n\nVariables\n\nArgo\n\nargo.ucsd.edu  â€” DOI: \n\nArgo (2025)  \n\nNOAA archive â€” DOI: \n\n10.25921/q97eâ€‘d719\n\nSea surface temperature, salinity\n\nGHRSST iQuam\n\nGHRSST iQuam website  \n\nGHRSST documentation (Zenodo)\n\nSea surface temperature\n\nGTSPP\n\nNCEI GTSPP access\n\nTemperature, salinity profiles\n\nSPURS\n\nSPURS homepage (NASA)\n\nSea surface salinity\n\nSeaBASS\n\nseabassâ€‹.gsfcâ€‹.nasaâ€‹.gov\n\nOcean color, chlorophyll-a\n\nNOMAD\n\nNOMAD at NOAA STAR\n\nOcean color, chlorophyll-a\n\nBOUSSOLE\n\nBOUSSOLE Project\n\nOcean color, optics, chlorophyll\n\nGDP (Drifters)\n\nGlobal Drifter Program\n\nOcean surface currents\n\nHF Radar\n\nHFRNet Portal\n\nOcean surface currents\n\nADCP\n\nNOAA ADCP Program\n\nWater column currents\n\nâ›…ï¸ Atmosphere\n\nDataset\n\nAccess\n\nVariables\n\nAERONET\n\naeronetâ€‹.gsfcâ€‹.nasaâ€‹.gov  \n\nre3data entry\n\nAerosol optical depth (AOD), aerosol type\n\nIGRA\n\nIGRA at NOAA\n\nAtmospheric temperature, pressure\n\nGRUAN\n\nGRUAN\n\nTemperature, humidity, pressure\n\nMETAR/ASOS\n\nIowa State Mesonet\n\nSurface temperature, pressure\n\nGPM-GV\n\nNASA GPM Ground Validation\n\nPrecipitation\n\nGPCC\n\nGPCC at DWD\n\nPrecipitation\n\nSKYNET\n\nChiba University SKYNET\n\nAerosols, AOD\n\nMPLNET\n\nMPLNET at NASA\n\nAerosols, clouds\n\nTCCON\n\nTCCON Data Portal\n\nCOâ‚‚, CHâ‚„, other trace gases\n\nPandora\n\nPandora Project\n\nNOâ‚‚, Oâ‚ƒ, trace gases\n\nMAX-DOAS\n\nMAX-DOAS Network\n\nNOâ‚‚, SOâ‚‚, HCHO\n\nðŸŒ³ Land\n\nDataset\n\nAccess\n\nVariables\n\nSURFRAD\n\nNOAA SURFRAD\n\nLand surface temperature, radiation\n\nBSRN\n\nBSRN\n\nSolar radiation, surface energy fluxes\n\nFLUXNET\n\nfluxnet.org\n\nLST, vegetation indices, fluxes\n\nSCAN\n\nUSDA SCAN\n\nSoil moisture\n\nISMN\n\nInternational Soil Moisture Network\n\nSoil moisture\n\nPhenocam\n\nPhenocam Network\n\nVegetation phenology (NDVI proxy)\n\nNEON\n\nNEON Data Portal\n\nVegetation indices, climate variables\n\nBELMANIP\n\nCopernicus Land Service\n\nLeaf area index (LAI)\n\nVALERI\n\nVALERI Project\n\nLAI, fAPAR\n\nDIRECT\n\nVALERI/DIRECT Info\n\nLAI\n\nâ„ï¸ Cryosphere\n\nDataset\n\nAccess\n\nVariables\n\nSnowEx\n\nNASA SnowEx\n\nSnow depth, snow cover, SWE\n\nCALVAL (NSIDC)\n\nNSIDC Cal/Val\n\nSnow, cryosphere\n\nGSNOW\n\nNOAA GSNOW\n\nSnow cover\n\nNSIDC\n\nNSIDC\n\nSea ice, snow cover\n\nIABP (Ice Buoys)\n\nInternational Arctic Buoy Program\n\nSea ice concentration, drift\n\nIceBridge\n\nNASA IceBridge\n\nIce sheet elevation, thickness\n\nATM\n\nAirborne Topographic Mapper (ATM)\n\nIce elevation profiles\n\nNOHRSC\n\nNOAA NOHRSC\n\nSnow depth and snow water equivalent\n\nCCSN (Canada)\n\nCanadian Cryospheric Snow Network\n\nSnow depth, SWE\n\n","type":"content","url":"/notebooks/validation-step1#finding-data-to-validate-with","position":5},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Example: GHRSST iQUAM data","lvl3":"Finding data to validate with"},"type":"lvl4","url":"/notebooks/validation-step1#example-ghrsst-iquam-data","position":6},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Example: GHRSST iQUAM data","lvl3":"Finding data to validate with"},"content":"For our new SST product, weâ€™ll use the GHRSST iQUAM dataset for validation. GHRSST is the Group for High Resolution Sea Surface Temperature â€“ an international collaboration supporting high-quality SST products for research and operational use â€“ and iQuam is a system developed by NOAA to collect, quality-control (QC), and distribute in situ SST observations in near real-time and delayed mode. This dataset aggregates SST measurements from a variety of in situ platforms, such as drifting buoys, moored buoys, shipboard sensors, and Argo floats.\n\nhttps://â€‹wwwâ€‹.starâ€‹.nesdisâ€‹.noaaâ€‹.govâ€‹/socdâ€‹/sstâ€‹/iquamâ€‹/â€‹?tabâ€‹=â€‹0â€‹&â€‹dateinputâ€‹_yearâ€‹=â€‹2023â€‹&â€‹dateinputâ€‹_monthâ€‹=â€‹02â€‹&â€‹dayofmoninputâ€‹_dayâ€‹=â€‹26â€‹&â€‹dateinputâ€‹_hourâ€‹=â€‹00â€‹&â€‹dayofmonâ€‹=â€‹monthlyâ€‹&â€‹qcrefsstâ€‹=â€‹â€‹_qcreyâ€‹&â€‹qcrefsstâ€‹=â€‹â€‹_qccmcâ€‹&â€‹outlierâ€‹=â€‹qcedâ€‹#qmap\n\n","type":"content","url":"/notebooks/validation-step1#example-ghrsst-iquam-data","position":7},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data matchups"},"type":"lvl3","url":"/notebooks/validation-step1#finding-data-matchups","position":8},{"hierarchy":{"lvl1":"Validating your data product","lvl3":"Finding data matchups"},"content":"\n\nHere are some important considerations we need to make when finding matchups between the satellite product and in situ datasets:\n\nðŸ”¹ 1. Spatial Collocation\n\nFootprint Differences: Satellite pixels often represent an area (e.g., 1 kmÂ² or more), while in situ data may be point measurements.\n\nSolution: Use in situ data averaged over the satellite footprint or compare satellite data averaged over multiple pixels surrounding the in situ point.\n\nGeolocation Accuracy: Both satellite and in situ positions should be accurately known, especially in dynamic environments (e.g., drifting buoys).\n\nEnvironmental Variability: Spatial gradients (e.g., near coastlines or fronts) can lead to mismatches even with close locations.\n\nðŸ”¹ 2. Temporal Matching\n\nTemporal Resolution: Satellites provide snapshots (sometimes daily, sometimes instantaneous), while in situ data may be continuous or periodic.\n\nSolution: Match satellite observation time as closely as possible to in situ sampling time (e.g., within Â±1 hour).\n\nDiurnal Effects: Some variables (e.g., SST, radiative fluxes) vary significantly throughout the day.\n\nSolution: Use diurnal correction or only match at known overpass times (e.g., MODIS ~1:30 pm local time).\n\nðŸ”¹ 3. Variable Definitions and Depths\n\nDepth Differences: For example, satellite SST represents skin temperature (top ~10â€“20 Î¼m), whereas in situ sensors often measure at ~1 m.\n\nSolution: Apply a skin-to-bulk correction or compare to â€œfoundation temperatureâ€ from models.\n\nVariable Representation: Ensure the in situ measurement is of the same quantity the satellite estimates (e.g., top-of-canopy reflectance vs. leaf-level LAI).\n\nðŸ”¹ 4. Quality Control\n\nFlagging: Use only high-quality satellite and in situ data (e.g., use quality flags to exclude cloud-contaminated pixels or questionable sensor readings).\n\nConsistency in Units and Calibration: Verify that data are in the same units and reference systems (e.g., radiance vs. reflectance, SI units).\n\nError Estimates: Consider measurement uncertainty and noise in both datasets.\n\nðŸ”¹ 5. Statistical Considerations\n\nMatchup Volume: A large number of matchup pairs increases robustness.\n\nBias and RMSE Analysis: Use metrics like bias, RMSE, and correlation to assess agreement.\n\nOutlier Handling: Identify and analyze outliers to understand limitations or failure modes.\n\nðŸ”¹ 6. Sensor Calibration\n\nEnsure both satellite and in situ instruments are properly calibrated and traceable to standards.\n\nðŸ”¹ 7. Geophysical Context\n\nGeographical Diversity: Validation should include diverse regions (e.g., open ocean, coastal, tropical, polar) to capture algorithm performance globally. In our example, we are only validating our product near Antarctica, so we should only use this product in that region.\n\nIn order to maximize the number of data matchups while still making a fair comparison, we need to determine an appropriate window in space and time. In our example, we set our spatial window to 1 km and our temporal window to half of a day:dist = 1.0\ntime_add = 0.5\n\n# Landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\n\n# Add Jetstream2 access\njetstream_url = 'https://js2.jetstream-cloud.org:8001/'\ns3 = s3fs.S3FileSystem(anon=True, client_kwargs=dict(endpoint_url=jetstream_url))\niQfiles=s3.ls('pythia/landsat8/iQuam') \n#print(iQfiles)\n\n# Paths\n# note, only the iQuam path will run correctly\nbasepath = Path('/home/jovyan/landsatproduct-cookbook')\nlsatpath = basepath / 'Data'\natmpath = lsatpath / 'AtmCorrection'\nmodout_path = lsatpath / 'MOD07_L2'\nSSTpath = lsatpath / 'SST/Validation/iQuamIntercomp/'\n#iQpath = lsatpath / 'iQuam'\n\n# Set up the directory structure to hold ERA5 atmospheric profiles and SST data\n!mkdir Data\n%cd Data\n!mkdir iQuam\n%cd iQuam\n\nWV = 'Water_Vapor'\n\n# For geopandas and tile plots\nsatellite = 'Landsat8'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1\ncolnm = ['landsat:wrs_path','landsat:wrs_row']\ngjson_outfile = lsatpath / f'{satellite}_iQuam.geojson'\n\n# Buffer around iquam point used to create a bounding box for Landsat sample\ndist = 1.0 # km\n\n# Temporal search range (days) before/after iquam measurement for finding Landsat image\ntime_add = 0.5\n\nlthresh = -1.9\n\ninterp = 1\n\n# Year and months desired (multiple years)\nstart_yr = 2013\nend_yr = 2023\n\n# Note these will get months from the later part of the year to early next\nstart_mo = '09'\nend_mo = '03'\n\n# Headers for the saved outputs\nheaders = ['DateTime','L8_filename','L8_SST','L8_std','center','N','S','E','W','NE','SE','NW','SW','L8_SST_max','L8_SST_min','Argo_id','Argo_SST','A_lat','A_lon']\n\n# Desired projection transformation\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the Landsat file\n\nNow weâ€™re ready to find our matchups!\n\nWeâ€™re repeating the retrieval step for the locations where we have data matchups.\n\n%%time\n\n# Multiple years\n\n# Set up projections\ntransformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)\n\n# Get iQuam file paths in directory between desired dates and find and produce matching Landsat SSTs \nfor year in range(start_yr, end_yr):  \n    yrmo = []\n    start_yrmo = f\"{year}{start_mo}\"  # Start from September of the current year\n    end_yrmo = f\"{year+1}{end_mo}\"  # End in March of the next year\n\n    m0 = start_yrmo\n    \n    # Make a list of months between start and end\n    while int(m0) <= int(end_yrmo):\n        calc_dt = datetime.strptime(f'{m0[:4]}-{m0[4:]}', '%Y-%m')\n        yrmo.append(calc_dt.strftime(\"%Y%m\"))\n        m0 = (calc_dt + relativedelta(months=1)).strftime(\"%Y%m\")\n    \n    # Get file names and select only those matching dates from yrmo  \n    #iQfiles = os.listdir(iQpath)\n    s3path = 's3://pythia/landsat8/iQuam/*.nc'\n    iQfiles = s3.glob(s3path)\n    #s3.invalidate_cache()\n\n    #iQfiles = [x for x in iQfiles if x[:6] in yrmo]\n    iQfiles = [x for x in iQfiles if x[22:22+6] in yrmo]\n    iQfiles.sort(reverse=True)\n    print (f'{year}: {len(iQfiles)}')\n    \n    #os.chdir(iQpath)\n\n    # For each iquam file, pair West Antarctic Argo buoy data with Landsat data and create calibrated SSTs\n    valid = []\n    \n    for iquam_file in iQfiles:\n        print(iquam_file)\n        print('s3://'+iquam_file)\n        \n        # Open Argos data from iQuam file\n        s3file = s3.open('s3://'+iquam_file)\n        \n        df = xr.open_dataset(s3file)\n        iquam = df.to_dataframe()\n        \n        # Subset to Antarctica\n        ant = iquam[(iquam.lat<-65)&(iquam.lon>-142)&(iquam.lon<-72)&(iquam.platform_type==5.0)&(iquam.quality_level==5.0)]  # Entire West Antarctica (later)\n        # ant = iquam[(iquam.lat<-69)&(iquam.lon>-125)&(iquam.lon<-98)&(iquam.platform_type==5.0)&(iquam.quality_level==5.0)] # Amundsen Sea\n        \n        # To remove a landsat day that is coming up with a 403 error\n        if ant['year'].iloc[0] == 2020 and ant['month'].iloc[0] == 12:\n            ant = ant[ant.day != 9.0] # for 202012 because otherwise will fail\n        \n        print('')\n        print(f'{iquam_file[:6]}: {ant.shape[0]} measurements')\n    \n        for idx in tqdm(range(ant.shape[0]), desc=\"Processing\"):\n    \n            # Create search area\n            ilat = ant['lat'].iloc[idx]\n            ilon = ant['lon'].iloc[idx]\n    \n            lat_add = sut.km_to_decimal_degrees(dist, ilat, direction='latitude')\n            lon_add = sut.km_to_decimal_degrees(dist, ilat, direction='longitude')\n            bboxV = (ilon-lon_add,ilat-lat_add,ilon+lon_add,ilat+lat_add)\n    \n            # Create Landsat temporal search range in correct format\n            ihr = int(ant.hour.iloc[idx])\n            iyr = int(ant.year.iloc[idx])\n            imo = int(ant.month.iloc[idx])\n    \n            calc_dt = datetime.strptime(f'{iyr}-{imo}-{int(ant.day.iloc[idx])} {ihr}', '%Y-%m-%d %H')\n            start_dt = (calc_dt + timedelta(days=-time_add)).strftime('%Y-%m-%dT%H:%M:%SZ')\n            end_dt = (calc_dt + timedelta(days=time_add)).strftime('%Y-%m-%dT%H:%M:%SZ')\n    \n            timeRangeV = f'{start_dt}/{end_dt}'\n    \n            # Search for desired Landsat scenes\n            items = sut.search_stac(url,collection,gjson_outfile=gjson_outfile,bbox=bboxV,timeRange=timeRangeV)\n    \n            # Load the geojson file and open stac catalog\n            catalog = intake.open_stac_item_collection(items)\n            gf = gpd.read_file(gjson_outfile)\n    \n            # Exclude Landsat 9\n            catalog_list = [x for x in items if x.id[3]=='8']\n            num_scene = len(catalog_list)\n            # print(f'{num_scene} Landsat 8 items')\n    \n            # If any matching landsat scenes are found create calibrated SSTs for them\n            if num_scene>0:\n    \n                # Reproject to determine bounding box in espg 3031\n                sbox,checkbox = sut.lsat_reproj(source_crs,target_crs,(bboxV[0],bboxV[1],bboxV[2],bboxV[3]))\n    \n                # Create polygon for later cropping\n                polygon = Polygon([(sbox[0][0],sbox[0][1]),(sbox[3][0],sbox[3][1]),(sbox[2][0],sbox[2][1]),(sbox[1][0],sbox[1][1])])\n                \n                # Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\n                minx, miny, maxx, maxy = polygon.bounds\n                polarx = [minx, maxx]\n                polary = [miny, maxy]\n    \n                # Create calibrated SSTs for each matching landsat scene\n                for sceneid in catalog_list:\n                    print(sceneid.id)\n    \n                    scene = catalog[sceneid.id]\n                    timestr = scene.metadata['datetime'].strftime('%H%M%S')\n    \n                    outFile = f'{SSTpath}/{sceneid.id}_{timestr}_Cel.tif'\n    \n                    if os.path.isfile(outFile):\n                        print (f'{sceneid.id} - atm corr exists')\n                        ls_scene = xr.open_dataset(outFile,chunks=dict(x=512, y=512),engine='rasterio')\n                        ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n    \n                        # Subset all scenes and check for right dimensions because y order changes sometimes\n                        ls_sub = sut.subset_img(ls_scene['band_data'].sel(band=1),polarx,polary) # subset so easier to work with\n    \n                    else:\n                        # try:\n                        # Open all desired bands for one scene\n                        ls_scene = sut.landsat_to_xarray(sceneid,catalog)\n                        ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n        \n                        # Create classification mask\n                        ls_scene = sut.create_masks(ls_scene, cloud_mask=True, ice_mask=True, ocean_mask=True)\n\n                        # Check for any open ocean pixels - go to next image if none - ??? s\n                        mask = np.ones(ls_scene.shape[1:])\n                        mask[ls_scene.mask!=3] = np.nan\n                        ls_thermal = ls_scene.sel(band='lwir11').compute()\n\n                        # Check in bounding box or for entire Landsat image depending on whether doing calibration runs or not\n                        ls_box = sut.subset_img(ls_thermal*mask,polarx,polary)\n\n                        if ((ls_box).notnull()).sum().values==0:\n                            print (f'{sceneid.id} has no SSTs')\n                            try:\n                                del ls_scene, scene, mask, ls_thermal, ls_box\n                            except:\n                                pass\n                            gc.collect()\n                            continue\n\n                        # Use band ratios for RF cloud pixel classification\n                        ####\n\n                        # Atmospheric correction using MODIS\n                        # Acquire and align MODIS water vapor (MOD/MYD07) to Landsat\n                        mod07,modfilenm = sut.open_MODIS(ls_scene,scene,modout_path)\n                        print(\"1\")\n\n                        # Create water vapor files aligned and subsampled to Landsat\n                        spacing = [300,-300] # 300m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\n                        WV_xr = sut.get_wv(ls_scene,mod07,spacing,WV,scene,interp=interp)\n                        print(\"2\")\n                        # Create SST by masking and using water vapor to apply atmospheric correction\n                        SST = sut.apply_retrieval(ls_thermal,scene,mask,WV_xr,atmcor,simT_transformer,simTOA_transformer,simWV_transformer)\n\n                        # Record MODIS water vapor image used in atmospheric correction, will find this info save under band_data in\n                        # data variables in COG (click on white paper info button in xarray readout)\n                        SST.attrs['MODIS_WV'] = modfilenm\n\n                        # Save to a cloud-optimized Geotiff\n                        SST.rio.to_raster(raster_path=outFile, driver=\"COG\")\n                        print (f'Mean SST: {np.nanmean(SST)}')\n\n                        # Subset all scenes and check for right dimensions because y order changes sometimes\n                        ls_sub = sut.subset_img(SST,polarx,polary) # subset so easier to work with \n\n                        try:\n                            del mask, ls_thermal, mod07, WV_xr, SST\n                        except:\n                            pass\n    \n                        # except Exception as e:\n                        #     print (sceneid.id, e)\n                        #     lsat = np.nan\n                        #     lstd = np.nan\n    \n                    # Crop data to exact bounding box\n                    ls_sub = sut.crop_xarray_dataarray_with_polygon(ls_sub, polygon) \n    \n                    # Calibrate using MODIS\n                    ls_sub = ls_sub * calib_m + calib_b\n    \n                    # Remove all pixels that are too cold\n                    ls_sub = ls_sub.where(ls_sub>=lthresh,np.nan)\n    \n                    lsat = np.around(np.nanmean(ls_sub),2)\n                    lstd = np.around(np.nanstd(ls_sub),2)\n    \n                    # Convert Argo lat/lon to Landsat's EPSG:3031\n                    argo_px, argo_py = transformer.transform(ilon, ilat)\n    \n                    # 1) Find the nearest center pixel\n                    center_val = ls_sub.sel(x=argo_px, y=argo_py, method=\"nearest\")\n                    \n                    # Extract the x/y coordinate values as plain floats\n                    center_x = center_val.x.item()\n                    center_y = center_val.y.item()\n                    \n                    # 2) Get integer indices from the coordinate indexes\n                    #    This uses ls_sub.get_index('dim_name') -> pandas.Index -> get_indexer(...)\n                    center_x_idx = ls_sub.get_index(\"x\").get_indexer([center_x])[0]\n                    center_y_idx = ls_sub.get_index(\"y\").get_indexer([center_y])[0]\n                    \n                    # 3) Gather offsets for the 3x3 neighborhood\n                    offsets = [\n                        ( 0,  0, \"center\"),\n                        ( 0,  1, \"N\"),\n                        ( 0, -1, \"S\"),\n                        ( 1,  0, \"E\"),\n                        (-1,  0, \"W\"),\n                        ( 1,  1, \"NE\"),\n                        ( 1, -1, \"SE\"),\n                        (-1,  1, \"NW\"),\n                        (-1, -1, \"SW\"),\n                    ]\n                    \n                    neighbors = {}\n                    for dx, dy, name in offsets:\n                        nx = center_x_idx + dx\n                        ny = center_y_idx + dy\n                        # Ensure we're within the array bounds\n                        if (0 <= nx < ls_sub.sizes['x']) and (0 <= ny < ls_sub.sizes['y']):\n                            # xarray dimension order is typically (y, x), so use isel(y=ny, x=nx):\n                            neighbors[name] = ls_sub.isel(y=ny, x=nx).values.item()\n                        else:\n                            neighbors[name] = np.nan\n                    \n                    # 4) Record coincident data from Landsat and Argo float\n                    argo_temp = np.around((ant.sst.iloc[idx] - 273.15),2)  # convert to Celsius\n                    times = pd.to_datetime(calc_dt, format='%Y%m%d%H')  # standardize time\n                    \n                    valid.append([\n                        times,\n                        sceneid.id,\n                        lsat,\n                        lstd,\n                        neighbors['center'],\n                        neighbors['N'],\n                        neighbors['S'],\n                        neighbors['E'],\n                        neighbors['W'],\n                        neighbors['NE'],\n                        neighbors['SE'],\n                        neighbors['NW'],\n                        neighbors['SW'],\n                        ls_sub.max().values.item(),\n                        ls_sub.min().values.item(),\n                        ant.iloc[idx].name,  # Argo ID or whichever label you prefer\n                        argo_temp,\n                        ilat,\n                        ilon\n                    ])\n                    print (f'Argo temp: {argo_temp}, Landsat 8 mean: {lsat}+/-{lstd}')\n    \n                    try:\n                        del ls_scene, scene, ls_thermal, ls_box, mod07, WV_xr, SST, ls_sub, neighbors\n                    except:\n                        pass\n    \n                    gc.collect()\n\n    # Put data into DataFrame and save    \n    lsat_mod_df = pd.DataFrame(valid,columns=headers)\n    out_df = f'Landsat_validation_{start_yrmo}_{end_yrmo}_{dist}.csv'\n    lsat_mod_df.to_csv(out_df)\n\n","type":"content","url":"/notebooks/validation-step1#finding-data-matchups","position":9},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Landsat-iQUAM validation assessment","lvl3":"Finding data matchups"},"type":"lvl4","url":"/notebooks/validation-step1#landsat-iquam-validation-assessment","position":10},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Landsat-iQUAM validation assessment","lvl3":"Finding data matchups"},"content":"\n\n# Nothing has been tested below this point after accessing iQuam data from Jetstream\n# KM 8/8/25\n\n# Read in processed matchups\n\n# 20250107 is threshold=-1.9, 20250114 is thresh=-1.94, 20250205 is thresh=-1.9\nout_df = lsatpath / 'Landsat_validation_202009_202103_1.0.csv'\nvalids = pd.read_csv(out_df)\n\nvalids = valids.set_index('DateTime')\nvalids = valids.sort_index()\nvalids['Argo_id'] = valids['Argo_id'].astype(int)\n\n# Remove the non-numeric column for calculating daily means\nnumeric_valids = valids.select_dtypes(include=[np.number])\nvalidmn = numeric_valids.groupby(numeric_valids['Argo_id']).mean()\nvalids = valids.reset_index()\n\n# Group by the date component of the datetime and calculate the difference\nvalids['temp_dif'] = valids.groupby(valids['Argo_id'])[f'L8_SST'].diff()\nvalidmn['temp_dif'] = valids.groupby(valids['Argo_id'])['temp_dif'].first()\nvalids = valids.set_index('DateTime')\n\nvalidmn['std'] = valids.groupby([valids['Argo_id']])[f'L8_SST'].std()\nvalidmn['xaxis'] = pd.to_datetime(validmn.index).dayofyear\nvalidmn['xaxis'][validmn['xaxis']<(365/2)] = validmn['xaxis'] + 365\n\nvalids['xaxis'] = pd.to_datetime(valids.index).dayofyear\nvalids['xaxis'][valids['xaxis']<(365/2)] = valids['xaxis'] + 365\n\nvalidmn = validmn.dropna(subset=['L8_SST'])\n\nvalids\n\n","type":"content","url":"/notebooks/validation-step1#landsat-iquam-validation-assessment","position":11},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Visualize all validation matchups for manual QC","lvl3":"Finding data matchups"},"type":"lvl4","url":"/notebooks/validation-step1#visualize-all-validation-matchups-for-manual-qc","position":12},{"hierarchy":{"lvl1":"Validating your data product","lvl4":"Visualize all validation matchups for manual QC","lvl3":"Finding data matchups"},"content":"\n\n# Setup and authenticate \nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient\n\npwd\n\nos.chdir(lsatpath)\nlsatfiles = os.listdir(lsatpath)\nlsatfiles = [i for i in lsatfiles if i[0]=='L']\n\n# Remove all files from the list with repeats and Landsat mean = nan\nremove = [\n'LC08_L1GT_029109_20160922_20200906_02_T2', \n'LC08_L1GT_022110_20181029_20201016_02_T2', \n'LC08_L1GT_005110_20181209_20201016_02_T2',\n'LC08_L1GT_228108_20200123_20201016_02_T2',\n'LC08_L1GT_001108_20200929_20201006_02_T2',\n'LC08_L1GT_002109_20201022_20201105_02_T2',\n'LC08_L1GT_233108_20201109_20210317_02_T2',\n'LC08_L1GT_233109_20201109_20210317_02_T2',\n'LC08_L1GT_001109_20201202_20210312_02_T2',\n'LC08_L1GT_027112_20220128_20220204_02_T2',\n'LC08_L1GT_002109_20210331_20210408_02_T2'\n]\n\nlsatfiles = [i for i in lsatfiles if i[:-15] not in remove]\nif len(lsatfiles)!=12:\n    print('Wrong number of Landsat scenes!!!')\n\n# Number of columns/rows for subplots\nn_cols = 3\nn_rows = 4\n\n# Create one figure and a 4x7 grid of subplots\n# The figsize is 10 across; adjust height as needed for clarity\nfig, axes = plt.subplots(\n    nrows=n_rows,\n    ncols=n_cols,\n    figsize=(11, 8.5),   \n    subplot_kw={'projection': ccrs.PlateCarree()}\n)\n\n# Optional: if you want them *really* close, you can fine-tune spacing:\nplt.subplots_adjust(wspace=0.05, hspace=0.03)\n# plt.subplots_adjust(bottom=0.15)\n\n# Counter for subplot index, and a handle to store the last \"imshow\" (for colorbar)\ni = 0\nim_obj = None\n\nfor lsatfile in lsatfiles:\n    lsID = lsatfile\n    print(lsID)\n    \n    mrow = valids[valids['L8_filename'].str.contains(lsatfile[:-15])]\n    \n    for idx, row in mrow.iterrows():\n        # Check if L8_SST is NaN\n        if pd.isnull(row['L8_SST']):\n            # If it is NaN, skip this iteration and do not plot\n            continue\n        \n        # --- Prepare data and coordinates ---\n        ilat = row['A_lat']\n        ilon = row['A_lon']\n        \n        lat_add = km_to_decimal_degrees(dist, ilat, direction='latitude')\n        lon_add = km_to_decimal_degrees(dist, ilat, direction='longitude')\n        xmin, ymin, xmax, ymax = (ilon - lon_add, ilat - lat_add, \n                                  ilon + lon_add, ilat + lat_add)\n        \n        # Load the Landsat file\n        ds = xr.open_dataset(lsatfile, chunks=dict(x=512, y=512), engine='rasterio')\n        ls_scene = ds['band_data'].sel(band=1).rio.write_crs(\"epsg:3031\", inplace=True)\n        \n        # Assign time coordinate\n        times = pd.to_datetime(lsatfile[17:25] + lsatfile[41:47], format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times, ID=lsatfile[:-8])\n        \n        # Reproject to EPSG:4326\n        ls_scene = ls_scene.rio.reproject(\"EPSG:4326\")\n\n        # Calibrate using MODIS\n        ls_scene = ls_scene * calib_m + calib_b\n\n        # Remove all pixels that are too cold\n        ls_scene = ls_scene.where(ls_scene>=lthresh,np.nan)\n        \n        # Select the subplot axis\n        ax = axes[i // n_cols, i % n_cols]\n        \n        # Plot on that axis, without a colorbar\n        # Store the \"imshow\" result in im_obj so we can build one colorbar later\n        im_obj = ls_scene.plot.imshow(\n            x='x', y='y',\n            vmin=-2.0, vmax=1.5,\n            ax=ax,\n            transform=ccrs.PlateCarree(),\n            origin='upper',\n            add_colorbar=False  # <- No individual colorbar\n        )\n        \n        # Remove titles completely (xarray may add one by default)\n        ax.set_title('')\n        \n        # Set extent\n        ax.set_extent([ilon - 0.4, ilon + 0.4, ilat - 0.2, ilat + 0.2], crs=ccrs.PlateCarree())\n        \n        # Argo observation\n        ax.scatter([ilon], [ilat], c='r', s=3, transform=ccrs.PlateCarree(), label='Argo location')\n        \n        # Draw bounding box\n        polygon_show = Pgon([(xmin, ymin), (xmin, ymax), \n                             (xmax, ymax), (xmax, ymin)],\n                            closed=True, edgecolor='red', facecolor='none')\n        ax.add_patch(polygon_show)\n        \n        # Text label\n        text_str = (\n            f\"Argo ID: {row['Argo_id']}\\n\"\n            f\"Argo Temp: {np.around(row['Argo_SST'], 2)}\\n\"\n            f\"Landsat SST: {np.around(row['L8_SST'], 2)}\"\n        )\n        ax.text(\n            0.02, 0.95,\n            text_str,\n            transform=ax.transAxes,\n            fontsize=10,\n            va='top',\n            ha='left'\n        )\n\n        gc.collect()\n        \n        # Move to next subplot index\n        i += 1\n        \n\n# --- Add a single colorbar for the entire figure ---\n# We use the last \"imshow\" (im_obj) and attach to all subplot axes\ncbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.03])\n\ncbar = fig.colorbar(\n    im_obj, \n    ax=axes.ravel().tolist(),  # or just ax=axes if axes is 2D\n    cax=cbar_ax,\n    orientation='horizontal',  # 'vertical' or 'horizontal'\n    fraction=0.025,            # how long the colorbar is relative to axes\n    pad=0.05                   # space between colorbar and subplots\n)\ncbar.set_label(\"Temperature [Â°C]\", fontsize=12)\n\n# plt.tight_layout()\nplt.show() \n\n","type":"content","url":"/notebooks/validation-step1#visualize-all-validation-matchups-for-manual-qc","position":13},{"hierarchy":{"lvl1":"Validating your data product","lvl2":"Use matchups to compare modeled and observed data"},"type":"lvl2","url":"/notebooks/validation-step1#use-matchups-to-compare-modeled-and-observed-data","position":14},{"hierarchy":{"lvl1":"Validating your data product","lvl2":"Use matchups to compare modeled and observed data"},"content":"Here, we are going to use a linear regression\n\n# Remove low quality validation data from the valids data\nrm_ids = [1460597, 1614080, 2143782, 2016236, 1790883]\nrm = validmn[validmn.index.isin(rm_ids)]\nvalidmn = validmn.drop(index=rm_ids, errors='ignore')\nvalids = valids[~valids['Argo_id'].isin(rm_ids)]\n\n# Orthoganal Regression \ndata = validmn\n\n# Original data\nx_original = np.array(data['Argo_SST'])\ny_original = np.array(data['L8_SST'])\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model\nlinear = Model(linear_model)\n\n# Create a RealData object using your DataFrame\ndata = RealData(x_original, y_original)\n\n# Set up ODR with the model and data\nodr = ODR(data, linear, beta0=[1., 0.])\n\n# Run the regression\nout = odr.run()\n\n# Use the output\nbeta = out.beta\nbeta_err = out.sd_beta\n\n# Print the summary\nout.pprint()\n\n# Predicting values using the ODR model\ny_pred = linear_model(beta, x_original)\n\n# Get R2\n# Calculate Total Sum of Squares (SST)\ny_mean = np.mean(y_original)\nSST = np.sum((y_original - y_mean)**2)\n\n# Calculate Residual Sum of Squares (SSR)\nSSR = np.sum((y_original - y_pred)**2)\n\n# Compute RMSE\nrmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n\n# Calculate R^2\nR2 = 1 - (SSR / SST)\nprint(\"R^2:\", np.around(R2,2))\nprint(f\"RMSE: {np.around(rmse,2)}\")\n\nbeta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\nbeta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\nbeta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\nbeta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\nprint(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\nxfill = np.array([-4.3,0.9])\n\n\n# Plot data points and 1:1 line\nfig, ax = plt.subplots(figsize=(5, 4))\nax.tick_params(labelsize=14)\n\nxi = np.arange(-7.0,5.0,1.0)\n\n# lower_err = abs(data['L8_SST'] - data['L8_SST_min'])  # distance to lower bound\n# upper_err = abs(data['L8_SST_max'] - data['L8_SST'])  # distance to upper bound\n\nax.scatter(x_original,y_original,color='k',linewidth=0,s=35,label='High quality')\nax.errorbar(x_original,y_original,yerr=validmn['std'],color='k',fmt='o',ecolor='k',elinewidth=1,capthick=1,marker='o',ms=3,capsize=5,label='_no legend_')\n# ax.errorbar(data['Argo_SST'],data['L8_SST'],yerr=[lower_err,upper_err],color='k',fmt='o',ecolor='k',elinewidth=1,capthick=1,marker='o',ms=3,capsize=5,label='_no legend_')\n# ax.scatter(data['Argo_SST'],data['center'],color='r',linewidth=0,s=25,label='_no label_')\nax.scatter(rm['Argo_SST'],rm['L8_SST'],color='0.7', s=35, label='Removed',zorder=2)\nax.plot(xi,xi,color='k',linewidth=2, label='1:1')\nax.plot(x_original, y_pred, color='k', ls=':', label='Validation ODR')\nax.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.1, facecolor='0.3')\n# a1.plot(xi,xi*lreg.coef_[0]+lreg.intercept_[0],color='r',linewidth=2,label='RANSAC regression')\n# a1.scatter(xC,yLC,color='r',linewidth=0,s=35,label='_no label_')\n# a1.plot(xi,xi*resultC.params.L8_SST+resultC.params.Intercept,color='k',linewidth=2,label='OLS regression')\n# a1.text(-2.1,-2.85,f'y={np.around(resultC.params.L8_SST,2)}x+{np.around(resultC.params.Intercept,2)}   p={p_val}',fontsize=12)\nax.text(-1.1,-1.5,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_ylim([-1.95,1.5])\nax.set_xlim([-1.95,1.5])\nax.set_xlabel('Argo Temperature [Â°C]',fontsize=16)\nax.set_ylabel('Landsat SST [Â°C]',fontsize=16)\nax.legend(markerscale=1,fontsize=12,loc='upper left')\n\nplt.tight_layout()\n# plt.savefig('/Users/tsnow03/GoogleDrive/User/Docs/PhD_Project/Manuscripts/AmundsenCC_Manuscript/Figures/LMCalibration.jpg', format='jpg', dpi=1000)\nplt.show()","type":"content","url":"/notebooks/validation-step1#use-matchups-to-compare-modeled-and-observed-data","position":15}]}