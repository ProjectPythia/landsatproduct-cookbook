{"version":"1","records":[{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nSee the \n\nCookbook Contributor‚Äôs Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!\n\nThis Project Pythia Cookbook covers ... (replace ... with the main subject of your cookbook ... e.g., working with radar data in Python)","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Motivation"},"content":"(Add a few sentences stating why this cookbook will be useful. What skills will you, ‚Äúthe chef‚Äù, gain once you have reached the end of the cookbook?)","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Authors"},"content":"First Author, \n\nSecond Author, etc. Acknowledge primary content authors here","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Structure"},"content":"(State one or more sections that will comprise the notebook. E.g., This cookbook is broken up into two main sections - ‚ÄúFoundations‚Äù and ‚ÄúExample Workflows.‚Äù Then, describe each section below.)","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. ‚ÄúFoundations‚Äù )","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":10},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. ‚ÄúFoundations‚Äù )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"The foundational content includes ... \")","type":"content","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":11},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. ‚ÄúExample workflows‚Äù )","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":12},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. ‚ÄúExample workflows‚Äù )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"Example workflows include ... \")","type":"content","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":13},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n‚Äúlaunch Binder‚Äù. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you‚Äôll be able to execute\nand even change the example programs. You‚Äôll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"From Raw Pixels to Products Landsat Sea Surface Temperature Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace ‚Äúcookbook-example‚Äù with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"Calibrate a physical model"},"type":"lvl1","url":"/notebooks/calibration","position":0},{"hierarchy":{"lvl1":"Calibrate a physical model"},"content":"","type":"content","url":"/notebooks/calibration","position":1},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"ü§î Why Calibrate?"},"type":"lvl3","url":"/notebooks/calibration#id-why-calibrate","position":2},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"ü§î Why Calibrate?"},"content":"\n\nCalibration of a physical model is the process of tuning its parameters to ensure its outputs accurately match real-world measurements. It‚Äôs about bridging the gap between theoretical calculations and physical reality.\n\nKey Goal: The primary goal is to improve predictive accuracy, transforming a model from a theoretical construct into a reliable tool for analysis and design.\n\n","type":"content","url":"/notebooks/calibration#id-why-calibrate","position":3},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"üìù What Do You Need?"},"type":"lvl3","url":"/notebooks/calibration#id-what-do-you-need","position":4},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"üìù What Do You Need?"},"content":"\n\nTo calibrate a model, you need four key components:\n\n1. A Physical ModelA set of mathematical equations or simulation software.\n\n2. Tunable ParametersThe specific \"knobs\" in your model that you can adjust.\n\n3. Experimental DataHigh-quality measurements from the real-world system.\n\n4. An Objective FunctionA metric that quantifies the error (e.g., RMSE).\n\n","type":"content","url":"/notebooks/calibration#id-what-do-you-need","position":5},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚öôÔ∏è How to Calibrate?"},"type":"lvl3","url":"/notebooks/calibration#id-how-to-calibrate","position":6},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚öôÔ∏è How to Calibrate?"},"content":"\n\nThere are two main approaches to calibration: by hand (trial and error) or by using a smart computer search (optimization algorithms). Optimization is highly recommended for its efficiency and accuracy.\n\nClick to see details on different optimization methods\n\nGradient-Based Methods: Use the error gradient for efficient searching (e.g., Levenberg-Marquardt).\n\nGradient-Free Methods: Do not require gradients, essential for ‚Äúblack-box‚Äù simulations (e.g., Nelder-Mead).\n\nBayesian Calibration: Treats parameters as probability distributions to quantify uncertainty.\n\nCross-Calibration: Calibrates one model against a trusted reference model to ensure consistency.\n\n","type":"content","url":"/notebooks/calibration#id-how-to-calibrate","position":7},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"type":"lvl3","url":"/notebooks/calibration#id-how-do-you-know-its-calibrated","position":8},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"content":"\n\nA successful calibration can be verified by analyzing the errors and by validating the model against new data. A common way to visualize the result is by plotting the model‚Äôs output against the experimental data.\n\n","type":"content","url":"/notebooks/calibration#id-how-do-you-know-its-calibrated","position":9},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl4":"Interactive Example: Adjusting Model Parameters","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"type":"lvl4","url":"/notebooks/calibration#interactive-example-adjusting-model-parameters","position":10},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl4":"Interactive Example: Adjusting Model Parameters","lvl3":"‚úÖ How Do You Know It‚Äôs Calibrated?"},"content":"To make this concept interactive, you can run the code cell below. It will create the same plot but with sliders that let you manually adjust the model‚Äôs parameters (slope and intercept). Try to move the sliders to make the red line fit the blue dots. This gives you a hands-on feel for the ‚ÄúBy Hand‚Äù calibration process.\n\n# First, let's install ipywidgets for the interactive sliders\n#%pip install -q ipywidgets\n#%pip install -q scikit-image\n#%pip install seaborn\n# %pip install plotly\n%pip install xarray==2024.05.0\nimport earthaccess\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, fixed\n\n# 1. Create the sample \"Experimental Data\"\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 20)\ntrue_slope = 2.5\ntrue_intercept = 1.5\ny_data = true_slope * x_data + true_intercept + np.random.normal(0, 2, size=x_data.shape)\n\n# 2. Define a function to plot the data and our adjustable model\ndef plot_model(x, y, slope, intercept):\n    \"\"\"Plots the experimental data against the model line defined by slope and intercept.\"\"\"\n    y_model = slope * x + intercept\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(x, y, 'o', label='Experimental Data', markersize=8, color='royalblue')\n    plt.plot(x, y_model, '-', label='Adjustable Model', linewidth=3, color='red')\n    \n    # Calculate and display the RMSE as our objective function score\n    rmse = np.sqrt(np.mean((y - y_model)**2))\n    plt.title(f'Comparison of Model vs. Data (RMSE: {rmse:.2f})', fontsize=16)\n    \n    plt.xlabel('Independent Variable', fontsize=12)\n    plt.ylabel('Dependent Variable', fontsize=12)\n    plt.ylim(min(y_data)-2, max(y_data)+2)\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.6)\n    plt.show()\n\n# 3. Create the interactive plot!\n# The 'interact' function automatically creates sliders for the numerical arguments.\ninteract(plot_model, x=fixed(x_data), y=fixed(y_data), slope=(0.0, 5.0, 0.1), intercept=(-5.0, 5.0, 0.1));\n\n","type":"content","url":"/notebooks/calibration#interactive-example-adjusting-model-parameters","position":11},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl2","url":"/notebooks/calibration#example-landsat-calibration-using-modis-sst","position":12},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"Create matchups between Landsat and MODIS SST data near Cosgrove, West Antarctica\nto produce a calibration for Landsat SSTs\n\n# Import libraries and modules\n%config InlineBackend.figure_format = 'svg'\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport xarray as xr\nimport geopandas as gpd\nfrom datetime import date, timedelta, datetime\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom matplotlib import colors\nfrom matplotlib.pylab import rcParams\nfrom matplotlib.patches import Polygon as Pgon\nimport cartopy.crs as ccrs\nimport cartopy\n\nimport os\nfrom cycler import cycler\nimport pyproj\nfrom pyproj import Proj, transform\nfrom sklearn.neighbors import BallTree\nimport pytz\nimport pygmt\nimport gc\nimport copy\nimport random\nimport statsmodels.formula.api as sm\nimport scipy.stats as stats\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom shapely.geometry import Point, Polygon\nfrom pathlib import Path\nimport math\nfrom scipy.odr import Model, RealData, ODR\nfrom tqdm.notebook import trange, tqdm\nimport seaborn as sns\n\nimport earthaccess\n\n# For LST file masking\nimport pystac_client\nimport intake\nfrom rasterio.session import AWSSession\nimport boto3\n\nimport SSTutils as stu\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#For color cycling in plots that is color blind friendly...make new ones at \"I want hue\" tools.medialab.sciences-po.fr/iwanthue\ncolor_cycler = cycler(color=[\"#6777cf\",\"#adba49\",\"#c65ca0\",\"#5fa042\",\"#683287\",\"#72ce7b\",\"#c44a48\",\"#45c7a9\",\"#933c1d\",\"#d0803f\",\"#ac9239\",\"#317c39\"])\ncolorline_cycler = (cycler(color=[\"#75a141\",\"#6c61b9\",\"#bc4d45\",\"#c1913d\",\"#b85298\",\"#4aa8e8\"]) +\n                 cycler(linestyle=['-','--',':','-.','-','--']))\nrcParams['axes.prop_cycle'] = cycler('color', color_cycler)\n\n","type":"content","url":"/notebooks/calibration#example-landsat-calibration-using-modis-sst","position":13},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Build Landsat - MODIS SST matchups","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#build-landsat-modis-sst-matchups","position":14},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Build Landsat - MODIS SST matchups","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Set paths and important variables and Calibration region bounding box\n\nbasepath = Path('/home/jovyan/landsatproduct-cookbook')\nspacing = [990,-990] # 990m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\nparam = 'sea_surface_temperature'\nsize_threshold = 30\n\nlocation = 0             # 0 and 1 are the Cosgrove and Dotson Polynya calibration areas, respectively\nsurf_temp = 'SST'        # 'SST' and 'LST' are for the Landsat SST and LST algorithms respectively\n\n# Set location bounds\nif location==1:\n    pathdir = 'DotsonPolynya'\n    latboundsC = [ -73.9 , -73.5 ] # Dotson polynya\n    lonboundsC = [ -113 , -111.5 ]\n    dfloc = 'Dotson'\nelif location==0:\n    pathdir = 'Cosgrove'\n    latboundsC = [ -73.5 , -73.42 ] # near Cosgrove\n    lonboundsC = [ -103.0 , -102.0 ]\n    dfloc = 'Cosgrove'\nelif location==2:\n    pathdir = 'Burke'\n    latboundsC = [ -73.81 , -73.42 ] # south of Burke\n    lonboundsC = [ -104.2 , -103.8 ]\n    dfloc = 'Burke'\nif location==3:\n    pathdir = 'DotsonIntercomp'\n    latboundsC = [ -74.2 , -74.11 ] # Dotson plume for intercomparison\n    lonboundsC = [ -113.5 , -113.17 ]\n    dfloc = 'DotsonIntercomp'\n\n# Coefficients for calibration\n# SST\nsstcalib_m = 0.76 \nsstcalib_b = 0.55 \n\n# LST\nlstcalib_m = 0.80\nlstcalib_b = 1.00\n\nmodmin = -1.9\nLSTmin = np.around(modmin/lstcalib_m - lstcalib_b,2) \nSSTmin = np.around(modmin/sstcalib_m - sstcalib_b,2) # should be about -2.0\n\n# Uncertainties used in ODR propagation of error\nmodis_uncertainty = 0.44  # long wave sst ocean color atbd\nsst_uncertainty = 0.3 # USGS Landsat stray light notice\nlst_uncertainty = 1.0 # gerace 2020\npix_uncertainty = np.sqrt((1000*1000)/(100*100)) # MODIS 1km x 1km and Landsat 100m x 100m\n\n\n# For calibrated SST runs\nif surf_temp=='SST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/Validation/{pathdir}/'\n    else:\n        sstpath = basepath / f'Data/SST/MODcalib/{pathdir}/'\n    tif = 'tif'\n    thresh = SSTmin\n    calib_m = sstcalib_m\n    calib_b = sstcalib_b\n    \n# If running for LST comparisons\nelif surf_temp=='LST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/LST/Calibration/DotsonPolynya/'\n    else:\n        sstpath = basepath / f'Data/SST/LST/Calibration/{pathdir}/'\n    tif = 'TIF'\n    thresh = LSTmin\n    calib_m = lstcalib_m\n    calib_b = lstcalib_b\n\n# Authenticate for accessing NASA data (MODIS)\nauth = earthaccess.login(strategy=\"interactive\")\n\n# If we are not authenticated\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\n# Convert bounding box to south polar stereo for checking if landsat has any data in bounding box\n# Speeds up process a lot\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the file   \n\nbbox,checkbox = stu.lsat_reproj(source_crs,target_crs,(lonboundsC[0],latboundsC[0],lonboundsC[1],latboundsC[1]))\n\n# Create polygon for later cropping\npolygon = Polygon([(bbox[0][0],bbox[0][1]),(bbox[3][0],bbox[3][1]),(bbox[2][0],bbox[2][1]),(bbox[1][0],bbox[1][1])])\n\n# Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\nminx, miny, maxx, maxy = polygon.bounds\npolarx = [minx, maxx]\npolary = [miny, maxy]\n\n# Get Landsat file paths in directory\nlsatfiles = os.listdir(sstpath)\nlsatfiles = [x for x in lsatfiles if x[-3:] == tif]\nlsatfiles.sort()\nprint (len(lsatfiles))\nos.chdir(sstpath)\n\nSSTfails = [\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n]\nLSTfails = [\n 'LC08_L1GT_007112_20211215_20211223_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20220201_20220211_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20221202_20221212_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20230204_20230209_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220105_20220114_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220121_20220128_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221105_20221115_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230108_20230124_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230313_20230321_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF'\n]\n\n","type":"content","url":"/notebooks/calibration#build-landsat-modis-sst-matchups","position":15},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Search for desired Landsat scenes","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#search-for-desired-landsat-scenes","position":16},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Search for desired Landsat scenes","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Authenticate for boto S3 access, etc.\nos.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\naws_session = AWSSession(boto3.Session(), requester_pays=True)\n\n# Setup and authenticate \nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient\n\n# Define the landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1 - includes L8 and L9\n\ni=0\nls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\nls_scene\n\n%%time\n# ~1 min 32 sec per image\n# If number of MODIS images per satellite is much more than 25, its because there is a ULY,LRY issue\nos.chdir('/home/jovyan/landsatproduct-cookbook/Data/SST/MODcalib/Cosgrove/')\n\nlsat_mod = []\n#for i in tqdm(range(len(lsatfiles)), desc=\"Processing\"):\nfor i in tqdm(range(1), desc=\"Processing the first image\"):\n    # Check for known repeatedly bad files that will kill the code\n    if surf_temp == 'SST':    \n        if lsatfiles[i] in SSTfails:\n            continue\n    elif surf_temp == 'LST':\n        if lsatfiles[i] in LSTfails:\n            continue\n        \n    # Concatenate all landsat files into xarray with a time dimension\n    ls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\n    ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n    print(\"1\")\n    if surf_temp == 'SST':\n        times = pd.to_datetime(lsatfiles[i][17:25]+lsatfiles[i][41:47], format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-8])\n    elif surf_temp == 'LST':\n        # Need to mask LST because not done previously\n        mask = stu.get_lst_mask(lsatfiles[i])\n        ls_scene = ls_scene * mask\n        \n        times = pd.to_datetime(lsatfiles[i][17:25]+'120000', format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-4])\n        ls_scene = ls_scene - 273.15\n\n    # Subset scene and check that it has the correct dimensions because y order changes sometimes\n    ls_scene = stu.subset_img(ls_scene,polarx,polary) # subset so easier to work with\n    ls_scene = stu.crop_xarray_dataarray_with_polygon(ls_scene, polygon) # crop data to exact bounding box\n\n    # if location==3:\n    # # Calibrate\n    # ls_scene = ls_scene * calib_m + calib_b\n    \n    # # Remove SSTs that are unrealistically cool\n    # ls_scene = ls_scene.where(ls_scene >= thresh, np.nan)\n\n    lsID = lsatfiles[i]\n    print (lsID)\n    \n    # Take mean temp, will skip the modis stage if no Landsat data in the calibration region\n    try:\n        lsat = np.nanmean(ls_scene)\n        ls_num = ls_scene.notnull().values.sum()\n    except Exception as e:\n        print (lsID, e)\n        lsat = np.nan\n\n    print(lsat)\n    if ~np.isfinite(lsat):\n        continue\n\n    # Find coincident MODIS SST scene\n    mod_scene, mod_file,time_dif = stu.find_MODIS(lonboundsC,latboundsC,ls_scene)\n    print(mod_file)\n\n    try:\n        # Acquire and align MODIS data to Landsat\n\n        # To subset to only high quality MODIS temp measurements which doesn't seem to be useful\n        # print(mod_scene.quality_level.max().values)\n        # mod_temps = mod_scene.sea_surface_temperature.where(mod_scene.quality_level>=4)\n\n        MODsst_xr = stu.get_sst(ls_scene,mod_scene.sea_surface_temperature,spacing,param) #mod_scene.sea_surface_temperature\n\n        # Remove SSTs that are unrealistically cool\n        MODsst_xr = MODsst_xr.where(MODsst_xr >= -1.9, np.nan)\n\n        # Crop Landsat image to meet the slightly smaller MODIS image (smaller image results from upsample methods in get_wv2)\n        ls_scene = stu.subset_img(ls_scene,[MODsst_xr.x.min(),MODsst_xr.x.max()],[MODsst_xr.y.min(),MODsst_xr.y.max()])\n\n        # Only use MODIS data where cropped Landsat data is also available\n        MODsst_xr_sub = MODsst_xr.where(ls_scene.notnull(),np.nan)\n\n        # Take mean temp\n        modis = np.nanmean(MODsst_xr_sub)\n        MOD_num = MODsst_xr_sub.notnull().values.sum()\n    except Exception as e:\n        print (mod_file, e)\n        modis = np.nan\n        MOD_num = 0\n\n    # Take mean using Landsat data only where cropped MODIS data is also available (need to do both)\n    try:\n        ls_scene_sub = ls_scene.where(MODsst_xr_sub.notnull(),np.nan)\n        lsat = np.nanmean(ls_scene_sub)\n        ls_num = ls_scene_sub.notnull().values.sum()\n    except Exception as e:\n        print (lsID, e)\n        lsat = np.nan\n\n    # Append file names with SST means from the Cosgrove box\n    lsat_mod.append([times,mod_file,modis,MOD_num,lsID,lsat,ls_num,time_dif])\n    print (f'MODIS mean: {modis}, Landsat 8: {lsat}')\n\n    try:\n        del ls_scene, ls_sub, mod_scene, MODsst_xr, MODsst_xr_sub\n    except:\n        pass\n\n    gc.collect()\n\n# # Put data into DataFrame and save    \n# headers = ['DateTime','MODIS_filename','MODIS_SST','MODIS_pix','L8_filename',f'L8_{surf_temp}','L8_pix','time_dif']\n# lsat_mod_df = pd.DataFrame(lsat_mod,columns=headers)\n# out_df = basepath / f'Data/MODISvLandsat_{surf_temp}_{dfloc}_20250500.csv'\n# lsat_mod_df.to_csv(out_df, index=False)\n\n","type":"content","url":"/notebooks/calibration#search-for-desired-landsat-scenes","position":17},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Calculate calibration bias and trend","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#calculate-calibration-bias-and-trend","position":18},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Calculate calibration bias and trend","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"Uses a \n\nRANSAC regression, but provides comparisons to an Ordinary Least Squares regression calculation from statsmodel of the same parameters.\n\n# Read in paired MODIS/Landsat data created above\nsurf_temp = 'SST'\n\nif surf_temp=='LST':\n    thresh = -3.5 # -3.4 is ok too\n    pix_thresh = 1300\nelif surf_temp=='SST':\n    thresh = -3.1\n    pix_thresh = 1300\nmod_sst_thresh = -1.9\n\n# For Cosgrove region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Cosgrove.csv'\n    df1 = pd.read_csv(out_df)\n    lsat_mod_df_C = df1\nelse:   \n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Cosgrove_lin_scale.csv' \n    df1 = pd.read_csv(out_df)\n    lsat_mod_df_C = df1\n\nprint(f'Original # matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_pix']>=pix_thresh]\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C[f'L8_{surf_temp}']>=thresh]\n\n# For Dotson polynya region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Dotson.csv'\n    df5 = pd.read_csv(out_df)\n    lsat_mod_df_D = df5\nelse:\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Dotson_lin_scale.csv'  \n    df5 = pd.read_csv(out_df)\n    lsat_mod_df_D = df5\n\nprint(f'Original # matchups at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_pix']>=pix_thresh]\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D[f'L8_{surf_temp}']>=thresh]\n\n# For Burke region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Burke.csv'\n    df9 = pd.read_csv(out_df)\n    lsat_mod_df_B = df9\nelse:\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Burke_lin_scale.csv'\n    df9 = pd.read_csv(out_df)\n    lsat_mod_df_B = df9\n\nprint(f'Original # matchups at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_pix']>=pix_thresh]\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B[f'L8_{surf_temp}']>=thresh]\n\n# Concatenate data from both regions\nlsat_mod_df_n = pd.concat([lsat_mod_df_B,lsat_mod_df_C,lsat_mod_df_D]) \nlsat_mod_df_bc = pd.concat([lsat_mod_df_B,lsat_mod_df_C]) \nlsat_mod_df_cd = pd.concat([lsat_mod_df_C,lsat_mod_df_D])\nlsat_mod_df_bd = pd.concat([lsat_mod_df_B,lsat_mod_df_D])\nprint(f'Num. good matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}, at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}, at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')\n\n# sum_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([2])]\n# sum_c = lsat_mod_df_C[lsat_mod_df_C.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# sum_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([2])]\n# sum_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([2])]\n# sum_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([2])]\n\n# # ***check all the february images to see if we need to add a threshold of 2.0C or cut images or if the issue is clouds???\n# # shld\n# look = lsat_mod_df_n.sort_values('L8_filename')\n# look.head(20)\n\n# Orthoganal Regression \nif surf_temp=='LST':\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = lst_uncertainty\nelse:\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = sst_uncertainty\n\n# Original data\nx_original = np.array(data0[f'L8_{surf_temp}'])\ny_original = np.array(data0['MODIS_SST'])\n\n# Assume these are your uncertainty estimates per observation\nsy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\nsx = np.full_like(x_original, landsat_uncertainty)\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model\nlinear = Model(linear_model)\n\n# Create a RealData object using your DataFrame\ndata = RealData(x_original, y_original,sx=sx, sy=sy)\n\n# Set up ODR with the model and data\nodr = ODR(data, linear, beta0=[1., 0.])\n\n# Run the regression\nout = odr.run()\n\n# Use the output\nbeta = out.beta\nbeta_err = out.sd_beta\n\n# Print the summary\nout.pprint()\n\n# Predicting values using the ODR model\ny_pred = linear_model(beta, x_original)\n\n# Get R2\n# Calculate Total Sum of Squares (SST)\ny_mean = np.mean(y_original)\nSST = np.sum((y_original - y_mean)**2)\n\n# Calculate Residual Sum of Squares (SSR)\nSSR = np.sum((y_original - y_pred)**2)\n\n# Compute RMSE\nrmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n\n# Calculate R^2\nR2 = 1 - (SSR / SST)\nprint(\"R^2:\", np.around(R2,2))\nprint(f\"RMSE: {np.around(rmse,2)}\")\n\nif surf_temp=='LST':\n    # Plot regression\n    beta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    beta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    print(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\n    xfill = np.array([-4.5,1.5])\n    \n    fig, ax = plt.subplots(figsize=(8, 3.5))\n    ax.tick_params(labelsize=14)\n    \n    # LST data and regression\n    plt.scatter(x_original, y_original, s=12,color='mediumslateblue')\n    plt.plot(x_original, y_pred, color='mediumslateblue', label='LST ODR')\n    plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n    \n    # Comparison regressions\n    xi = np.arange(-7.0,5.0,1.0)\n    plt.plot(xi,xi * sstcalib_m + sstcalib_b,color='k',linewidth=2,label='SST ODR')\n    plt.plot(xi,xi,color='lightcoral',linewidth=2, label='MODIS 1:1')\n        \n    plt.legend(loc='lower right',fontsize=14)\n    plt.text(-2.7,-0.15,rf'$\\mathbf{{y={np.around(beta[0],2)}x+{np.around(beta[1],2)}\\quad r^2={np.around(R2,2)}}}$',color='mediumslateblue', fontweight='bold',fontsize=14)\n    plt.xlim([-3.5,-1.2])\n    plt.ylim([-3.05,0.8])\n    # else: \n    #     plt.plot(x_original, y_pred, color='k', label='NLSST Orthogonal Distance Regression')\n    #     plt.legend(loc='lower right',fontsize=12)\n    #     plt.text(-2.6,-0.2,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\n    #     plt.xlim([-3.2,-0.15])\n    #     plt.ylim([-2.4,0.9]) \n    plt.xlabel('Landsat ST [¬∞C]',fontsize=16)\n    plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n    plt.tight_layout()\n\n# Orthoganal Regression for SST only\ndataframes = [\n    ('Combined', lsat_mod_df_n),\n    ('Burke', lsat_mod_df_B),\n    ('Cosgrove', lsat_mod_df_C),\n    ('Dotson', lsat_mod_df_D),\n]\n\nif surf_temp=='LST':\n    landsat_uncertainty = lst_uncertainty\nelse:\n    landsat_uncertainty = sst_uncertainty\n\n# Dictionary to store the results from each DataFrame\nodr_results = {}\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model object\nlinear = Model(linear_model)\n\n# Loop over each DataFrame\nfor df_name, data0 in dataframes:\n    print(f\"\\n=== Processing {df_name} ===\")\n    \n    # Original data\n    x_original = np.array(data0[f'L8_{surf_temp}'])\n    y_original = np.array(data0['MODIS_SST'])\n\n    # Assume these are your uncertainty estimates per observation\n    sy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\n    sx = np.full_like(x_original, landsat_uncertainty)\n    \n    # Create a RealData object using your DataFrame\n    data = RealData(x_original, y_original,sx=sx, sy=sy)\n    \n    # Set up ODR with the model and data, providing an initial guess\n    odr = ODR(data, linear, beta0=[1., 0.])\n    \n    # Run the regression\n    out = odr.run()\n    \n    # Retrieve best-fit parameters and their std. dev.\n    beta = out.beta\n    beta_err = out.sd_beta\n    \n    # Print the summary\n    out.pprint()\n    \n    # Predicting values using the ODR model\n    y_pred = linear_model(beta, x_original)\n    \n    # Get R2\n    # Calculate Total Sum of Squares (SST)\n    y_mean = np.mean(y_original)\n    SST = np.sum((y_original - y_mean)**2)\n    \n    # Calculate Residual Sum of Squares (SSR)\n    SSR = np.sum((y_original - y_pred)**2)\n    \n    # Calculate R^2\n    R2 = 1 - (SSR / SST)\n\n    # Compute RMSE\n    rmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n    \n    # Print R^2\n    print(f\"{df_name} R^2:\", np.around(R2, 2))\n    print(f\"RMSE: {np.around(rmse,2)}\")\n    \n    # Store results in a dictionary for later use (plotting, etc.)\n    odr_results[df_name] = {\n        'beta': beta,\n        'beta_err': beta_err,\n        'R2': R2,\n        'x_original': x_original,\n        'y_original': y_original,\n        'y_pred': y_pred\n    }\n\n# Import the necessary ipywidgets components\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\n# The @interact decorator will automatically create widgets for the function arguments\n@interact(\n    show_burke=widgets.Checkbox(value=True, description=\"Burke Data\"),\n    show_cosgrove=widgets.Checkbox(value=True, description=\"Cosgrove Data\"),\n    show_dotson=widgets.Checkbox(value=True, description=\"Dotson Data\"),\n    show_combined_fit=widgets.Checkbox(value=True, description=\"Combined Fit\"),\n    show_confidence_interval=widgets.Checkbox(value=True, description=\"95% CI\")\n)\ndef interactive_sst_plot(show_burke, show_cosgrove, show_dotson, show_combined_fit, show_confidence_interval):\n    \n    # This is your original code, with plotting commands wrapped in if-statements\n    if surf_temp=='SST':\n        # Your original data calculation code (unchanged)\n        beta_mdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n        beta_mup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n        beta_bdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n        beta_bup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n        a1 = np.around(odr_results['Combined']['beta'][0],2)\n        a2 = np.around(odr_results['Combined']['beta'][1],2)\n        ar = np.around(odr_results['Combined']['R2'],2)\n        b1 = np.around(odr_results['Burke']['beta'][0],2)\n        b2 = np.around(odr_results['Burke']['beta'][1],2)\n        br = np.around(odr_results['Burke']['R2'],2)\n        c1 = np.around(odr_results['Cosgrove']['beta'][0],2)\n        c2 = np.around(odr_results['Cosgrove']['beta'][1],2)\n        cr = np.around(odr_results['Cosgrove']['R2'],2)\n        d1 = np.around(odr_results['Dotson']['beta'][0],2)\n        d2 = np.around(odr_results['Dotson']['beta'][1],2)\n        dr = np.around(odr_results['Dotson']['R2'],2)\n        xfill = np.array([-4.3,0.9])\n\n        # --- Plotting Section ---\n        fig, ax = plt.subplots(figsize=(8, 4)) # Increased height slightly for better text placement\n        ax.tick_params(labelsize=14)\n\n        if show_burke:\n            plt.scatter(np.array(lsat_mod_df_B[f'L8_{surf_temp}']), np.array(lsat_mod_df_B['MODIS_SST']), s=12,color='#00bf7d', label='Burke')\n            plt.plot(odr_results['Burke']['x_original'], odr_results['Burke']['y_pred'], ls='-',linewidth=1,color='#00bf7d')\n            plt.text(-2.9,0.0,f'y={b1}x+{b2}   $r^2$={br}',color='#00bf7d',fontsize=12)\n\n        if show_cosgrove:\n            plt.scatter(np.array(lsat_mod_df_C[f'L8_{surf_temp}']), np.array(lsat_mod_df_C['MODIS_SST']), s=12,color=sns.color_palette(\"colorblind\")[3], label='Cosgrove')\n            plt.plot(odr_results['Cosgrove']['x_original'], odr_results['Cosgrove']['y_pred'], ls='-',linewidth=1,color=sns.color_palette(\"colorblind\")[3])\n            plt.text(-2.9,-0.3,f'y={c1}x+{c2}   $r^2$={cr}',color=sns.color_palette(\"colorblind\")[3],fontsize=12)\n            \n        if show_dotson:\n            plt.scatter(np.array(lsat_mod_df_D[f'L8_{surf_temp}']), np.array(lsat_mod_df_D['MODIS_SST']), s=12,color='#0073e6', label='Dotson')\n            plt.plot(odr_results['Dotson']['x_original'], odr_results['Dotson']['y_pred'], ls='-',linewidth=1,color='#0073e6')\n            plt.text(-2.9,-0.6,f'y={d1}x+{d2}   $r^2$={dr}',color='#0073e6',fontsize=12)\n\n        if show_combined_fit:\n            plt.plot(odr_results['Combined']['x_original'], odr_results['Combined']['y_pred'], color='k')\n            plt.text(-2.9,0.3,f'y={a1}x+{a2}   $r^2$={ar}',color='k',fontsize=14)\n            if show_confidence_interval:\n                plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n\n        # General plot labels and limits (unchanged)\n        plt.xlim([-3.05,-0.15])\n        plt.ylim([-2.3,0.9])\n        plt.xlabel('Landsat SST [¬∞C]',fontsize=16)\n        plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n        plt.legend(loc='lower right',fontsize=10)\n        plt.tight_layout()\n        plt.show() # Make sure to show the plot\n\nodr_results['Combined']['beta_err']\n\nif surf_temp=='SST':\n    # Ordinary least squares regression between Landsat and MODIS SST matchups\n    resultC = sm.ols(formula=\"MODIS_SST ~ L8_SST\", data=data0).fit()\n    print (resultC.summary())\n\n","type":"content","url":"/notebooks/calibration#calculate-calibration-bias-and-trend","position":19},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Interactive Analysis Dashboard using Matplotlib","lvl2":"Example: Landsat calibration using MODIS SST"},"type":"lvl3","url":"/notebooks/calibration#interactive-analysis-dashboard-using-matplotlib","position":20},{"hierarchy":{"lvl1":"Calibrate a physical model","lvl3":"Interactive Analysis Dashboard using Matplotlib","lvl2":"Example: Landsat calibration using MODIS SST"},"content":"\n\n# Imports for Interactive Dashboard\nimport ipywidgets as widgets\nfrom ipywidgets import interact, Layout\n\n# Matplotlib-based Interactive Dashboard Function\n\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\ndef interactive_calibration_dashboard_matplotlib(region, chart_type, pix_thresh, modis_sst_thresh, lsat_sst_thresh):\n    # 1. & 2. Data filtering and selection (Same as your original code)\n    df_C_filt = lsat_mod_df_C[(lsat_mod_df_C['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_C['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_C[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_C_filt['Region'] = 'Cosgrove'\n\n    df_D_filt = lsat_mod_df_D[(lsat_mod_df_D['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_D['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_D[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_D_filt['Region'] = 'Dotson'\n\n    df_B_filt = lsat_mod_df_B[(lsat_mod_df_B['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_B['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_B[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_B_filt['Region'] = 'Burke'\n\n    if region == 'All Regions':\n        df_filtered = pd.concat([df_B_filt, df_C_filt, df_D_filt])\n    elif region == 'Cosgrove':\n        df_filtered = df_C_filt\n    elif region == 'Dotson':\n        df_filtered = df_D_filt\n    elif region == 'Burke':\n        df_filtered = df_B_filt\n    \n    # Create the figure and axis for the plot\n    fig, ax = plt.subplots(figsize=(8, 6))\n\n    if len(df_filtered) < 2:\n        ax.text(0.5, 0.5, \"Not enough data with the current filter settings.\", ha='center', va='center')\n        ax.set_axis_off()\n        plt.show()\n        return\n\n    # 3. ODR Calculation (Same as your original code)\n    x_data = df_filtered[f'L8_{surf_temp}'].values\n    y_data = df_filtered['MODIS_SST'].values\n    sx = np.full_like(x_data, sst_uncertainty)\n    sy = np.full_like(y_data, modis_uncertainty * pix_uncertainty)\n    model = Model(linear_model)\n    data = RealData(x_data, y_data, sx=sx, sy=sy)\n    odr = ODR(data, model, beta0=[1., 0.])\n    output = odr.run()\n    slope, intercept = output.beta\n    y_pred = linear_model(output.beta, x_data)\n\n    # 4. Statistics Calculation (Same as your original code, but formatted for Matplotlib title)\n    bias = np.mean(y_data - x_data)\n    trend = slope\n    ss_total = np.sum((y_data - np.mean(y_data))**2)\n    ss_resid = np.sum((y_data - y_pred)**2)\n    r2 = 1 - (ss_resid / ss_total) if ss_total > 0 else 0\n    rmse = np.sqrt(np.mean((y_data - y_pred)**2))\n    # Note: Matplotlib title doesn't support HTML bold tags, so they are removed.\n    stats_text = (f\"Trend (Slope): {trend:.2f} | Bias (MODIS - Landsat): {bias:.2f}¬∞C\\n\"\n                  f\"R¬≤: {r2:.2f} | RMSE: {rmse:.2f} | N: {len(df_filtered)}\")\n\n    # 5. Create Matplotlib figure based on chart_type\n    if chart_type == 'Scatter':\n        # Seaborn's scatterplot is a great way to handle coloring by category easily\n        sns.scatterplot(data=df_filtered, x=f'L8_{surf_temp}', y='MODIS_SST', hue='Region', ax=ax, s=50)\n    elif chart_type == 'Heatmap':\n        ax.hist2d(df_filtered[f'L8_{surf_temp}'], df_filtered['MODIS_SST'], bins=20, cmap='viridis')\n        fig.colorbar(ax.collections[0], ax=ax, label='Point Density')\n\n    # Add regression line\n    sorted_indices = np.argsort(x_data)\n    ax.plot(x_data[sorted_indices], y_pred[sorted_indices], color='black', linewidth=2, label='ODR Fit')\n\n    # Set titles, labels, and limits\n    ax.set_title(stats_text)\n    ax.set_xlabel(\"Landsat SST [¬∞C]\")\n    ax.set_ylabel(\"MODIS SST [¬∞C]\")\n    ax.set_xlim(-3.05, -0.15)\n    ax.set_ylim(-2.3, 0.9)\n    ax.legend()\n    ax.grid(True, linestyle='--', alpha=0.6)\n    \n    plt.show()\n\n# Define Widgets\nstyle = {'description_width': 'initial'}\nw_region = widgets.Dropdown(options=['All Regions', 'Cosgrove', 'Dotson', 'Burke'], value='All Regions', description='Select Region:', style=style)\nw_chart_type = widgets.ToggleButtons(options=['Scatter', 'Heatmap'], description='Chart Type:', button_style='info')\nw_pix_thresh = widgets.IntSlider(value=1300, min=0, max=5000, step=100, description='Min MODIS Pixels:', style=style, layout=Layout(width='500px'))\nw_modis_sst = widgets.FloatSlider(value=-1.9, min=-2.5, max=0, step=0.1, description='Min MODIS SST (¬∞C):', style=style, layout=Layout(width='500px'))\nw_lsat_sst = widgets.FloatSlider(value=-3.1, min=-4.0, max=0, step=0.1, description='Min Landsat SST (¬∞C):', style=style, layout=Layout(width='500px'))\n\n\n# Launch the new Matplotlib-based Dashboard\ninteract(interactive_calibration_dashboard_matplotlib, \n         region=w_region, \n         chart_type=w_chart_type,\n         pix_thresh=w_pix_thresh, \n         modis_sst_thresh=w_modis_sst, \n         lsat_sst_thresh=w_lsat_sst);","type":"content","url":"/notebooks/calibration#interactive-analysis-dashboard-using-matplotlib","position":21},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Validation"},"type":"lvl1","url":"/notebooks/validation","position":0},{"hierarchy":{"lvl1":"Validation"},"content":"","type":"content","url":"/notebooks/validation","position":1},{"hierarchy":{"lvl1":"Validation","lvl2":"The Principle of Validation"},"type":"lvl2","url":"/notebooks/validation#the-principle-of-validation","position":2},{"hierarchy":{"lvl1":"Validation","lvl2":"The Principle of Validation"},"content":"Validation in remote sensing is the process of independently assessing the accuracy of a data product. It is a very essential step that builds and quantifies the uncertainty of satellite-derived products.","type":"content","url":"/notebooks/validation#the-principle-of-validation","position":3},{"hierarchy":{"lvl1":"Validation","lvl3":"Why Do We Validate?","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation#why-do-we-validate","position":4},{"hierarchy":{"lvl1":"Validation","lvl3":"Why Do We Validate?","lvl2":"The Principle of Validation"},"content":"Satellites don‚Äôt measure physical properties like temperature directly. They measure radiated energy, and we utilize complex models and algorithms to convert that energy measurement into a useful product, such as Sea Surface Temperature (SST). Validation is crucial for several reasons:\n\nQuantify Accuracy: Validation will provide a measure of success on how close the satellite product is to the ground-truth value (e.g., ‚Äúaccurate to within ¬±0.5¬∞C‚Äù).\n\nIdentify and Correct Bias: This step can reveal various systematic errors where the satellite consistently measures too high or too low (spatial and temporal).\n\nUnderstand Limitations: Validation also helps define the conditions under which the product is reliable (e.g., ‚Äúaccurate in open water but less so near coastlines‚Äù). This would help other scientists or organizations to use the satellite data for climate modeling, weather forecasting, or policymaking.\n\n","type":"content","url":"/notebooks/validation#why-do-we-validate","position":5},{"hierarchy":{"lvl1":"Validation","lvl3":"Possible Methods for Validation:","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation#possible-methods-for-validation","position":6},{"hierarchy":{"lvl1":"Validation","lvl3":"Possible Methods for Validation:","lvl2":"The Principle of Validation"},"content":"Validation involves comparing the satellite product to ground truth data or any source data.\n\nPoint-to-Point Validation: This is the most common method and uses a high-quality in-situ measurement (like from a weather station, buoy, or Argo float for SST) and compares it to the value of the satellite pixel at the same location and time.\n\nSpatial Comparison: This method assesses how well the satellite captures spatial patterns. You compare the satellite image to a high-resolution map from another trusted source.\n\nCross-Satellite Comparison: This technique compares three independent datasets (e.g., your new product, another satellite product, and ground truth data) to estimate the error of each one.","type":"content","url":"/notebooks/validation#possible-methods-for-validation","position":7},{"hierarchy":{"lvl1":"Validation","lvl3":"Statistical Tools:","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation#statistical-tools","position":8},{"hierarchy":{"lvl1":"Validation","lvl3":"Statistical Tools:","lvl2":"The Principle of Validation"},"content":"To quantify the comparison, there is a standard set of statistical metrics:\n\nBias: The average difference between the satellite and ground truth data. It tells you if the product is systematically high or low.      Bias = mean (Satellite - GroundTruth)\n\nRoot Mean Square Error (RMSE): This is the most important metric that measures the typical magnitude of the error, regardless of whether it is positive or negative.      RMSE = sqrt (mean ((Satellite - GroundTruth)¬≤))\n\nStandard Deviation: This measures the consistency of the error and a low standard deviation means the error is predictable.\n\nCorrelation Coefficient (r or R¬≤): This measures the degree to which the satellite data trends with the ground truth data.\n\nRegression Analysis for Cross-Validation: This can be achieved by plotting the satellite data (y-axis) against the ground truth data (x-axis) and fitting a linear regression line. In a perfect world, this line would be y = 1x + 0 (the 1:1 line). The actual slope and intercept reveal systematic biases.\n\n","type":"content","url":"/notebooks/validation#statistical-tools","position":9},{"hierarchy":{"lvl1":"Validation","lvl3":"Steps in the Validation.pynb code:","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation#steps-in-the-validation-pynb-code","position":10},{"hierarchy":{"lvl1":"Validation","lvl3":"Steps in the Validation.pynb code:","lvl2":"The Principle of Validation"},"content":"The proposed method developed a specific algorithm to derive SST from Landsat 8 data, which involves a cross-calibration with MODIS. The source code for the book is \n\nreleased on GitHub repository. The primary objective is to demonstrate that this specific method yields accurate results, particularly in the areas of study. In the validation script, there are several steps to consider:\n\nGround Truth Data: Systematically searches the iQuam dataset to find high-quality temperature measurements from Argo floats in Antarctica.\n\nSatellite Data: For each Argo measurement, it searches the Landsat STAC catalog to find a satellite image of the same location taken within ¬±12 hours, which is called a ‚Äúmatchup.‚Äù\n\nProcess: Processes the Landsat image using its algorithm to create an SST value and then directly compares this value to the Argo float‚Äôs dataset.\n\nThe code implements the key statistical methods to assess the results of this comparison:\n\nData Compilation: It first gathers all the matchups into a single pandas DataFrame called valids.\n\nBias and Mean Difference: It calculates the mean values for both L8_SST and Argo_SST to get a general sense of the bias.\n\nScatter Plot and Regression: It plots Argo SST on the x-axis (ground truth) and Landsat SST on the y-axis (satellite product) and performs an Orthogonal Distance Regression (ODR), which is a robust form of linear regression, to find the best-fit line through the data points. It calculates and displays the R¬≤ value and RMSE to quantify the average error of their product. By doing this, the code provides a comprehensive and statistically sound validation of the new Landsat SST product, demonstrating its accuracy and reliability.\n\n","type":"content","url":"/notebooks/validation#steps-in-the-validation-pynb-code","position":11},{"hierarchy":{"lvl1":"Validation","lvl3":"Sample Validation Result","lvl2":"The Principle of Validation"},"type":"lvl3","url":"/notebooks/validation#sample-validation-result","position":12},{"hierarchy":{"lvl1":"Validation","lvl3":"Sample Validation Result","lvl2":"The Principle of Validation"},"content":"Put a code box!\n\n","type":"content","url":"/notebooks/validation#sample-validation-result","position":13},{"hierarchy":{"lvl1":"Validation","lvl2":"What is Next?"},"type":"lvl2","url":"/notebooks/validation#what-is-next","position":14},{"hierarchy":{"lvl1":"Validation","lvl2":"What is Next?"},"content":"A Multivariate Regression model was used in the current work for Sea Surface Temperature modeling. The regression-based models typically present some results based on the residual values of modeled vs observed values. There are a lot of metrics available for the interpretation of results and showing the accuracy of the model. It can be noted that there are other methods, including some Machine Learning classification methods, that can be used for SST analysis to provide a better understanding of the physical processes contributing to SST values. Moreover, spatial analysis can be done by these models, besides having some spatial error or deviation mapping for the regression models.","type":"content","url":"/notebooks/validation#what-is-next","position":15},{"hierarchy":{"lvl1":"Validation","lvl3":"Advanced Methods for Deeper Understanding","lvl2":"What is Next?"},"type":"lvl3","url":"/notebooks/validation#advanced-methods-for-deeper-understanding","position":16},{"hierarchy":{"lvl1":"Validation","lvl3":"Advanced Methods for Deeper Understanding","lvl2":"What is Next?"},"content":"While regression models are excellent for prediction, other advanced methods can provide a more nuanced understanding of the physical processes and spatial dynamics of SST.\n\nMachine Learning Classification Methods:\n\nInstead of predicting the exact SST value, Machine Learning (ML) classification models can be used to identify and categorize distinct oceanographic features or thermal regimes. An ML model, such as a Random Forest or Support Vector Machine (SVM), can be trained on satellite data to recognize the unique signatures of different water masses. For example, it can learn to distinguish between a warm coastal current, a cold upwelling zone, and a stable open-ocean gyre based on a combination of SST, salinity, and sea surface height data. This approach moves beyond a single temperature value to provide a qualitative understanding of the SST‚Äôs concept. It can automatically map complex features that are crucial for understanding heat transport in marine ecosystems.\n\nSpatial Analysis and Error Mapping:\n\nStandard regression metrics provide a single accuracy number for the entire study area, but they don‚Äôt reveal where the model performs well or poorly. Instead of averaging the residuals, they can be plotted at their geographic locations creating a spatial error map. Geostatistical tools can then be used to test for spatial autocorrelation, revealing if high or low errors are clustered together. This is critical for understanding model limitations, while an error map might show that a regression model performs very well in some regions but consistently fails near complex coastlines or river mouths. This insight is lost in non-spatial metrics and is vital for improving the model and correctly interpreting its outputs.\n\n","type":"content","url":"/notebooks/validation#advanced-methods-for-deeper-understanding","position":17},{"hierarchy":{"lvl1":"Validation","lvl2":"Sample Visualization Mapping Result"},"type":"lvl2","url":"/notebooks/validation#sample-visualization-mapping-result","position":18},{"hierarchy":{"lvl1":"Validation","lvl2":"Sample Visualization Mapping Result"},"content":"We can produce higher spatial resolution error maps if we have more validation data. So, these current maps are just based on a 5¬∞ resolution grid and show that tropical regions have higher standard deviation and lower bias error values because of higher water vapor and dust aerosols.\n\n","type":"content","url":"/notebooks/validation#sample-visualization-mapping-result","position":19},{"hierarchy":{"lvl1":"Validation","lvl2":"Producing higher spatial resolution mapping results"},"type":"lvl2","url":"/notebooks/validation#producing-higher-spatial-resolution-mapping-results","position":20},{"hierarchy":{"lvl1":"Validation","lvl2":"Producing higher spatial resolution mapping results"},"content":"","type":"content","url":"/notebooks/validation#producing-higher-spatial-resolution-mapping-results","position":21},{"hierarchy":{"lvl1":"Validation","lvl3":"What is the common spatial resolution for SST error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"type":"lvl3","url":"/notebooks/validation#what-is-the-common-spatial-resolution-for-sst-error-mapping","position":22},{"hierarchy":{"lvl1":"Validation","lvl3":"What is the common spatial resolution for SST error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"content":"The current 5¬∞ resolution grid mapping for spatial error analysis is somewhat coarse for model evaluation purposes. Therefore, there is a need to enhance the spatial evaluation in SST modeling.","type":"content","url":"/notebooks/validation#what-is-the-common-spatial-resolution-for-sst-error-mapping","position":23},{"hierarchy":{"lvl1":"Validation","lvl3":"How to improve spatial resolution error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"type":"lvl3","url":"/notebooks/validation#how-to-improve-spatial-resolution-error-mapping","position":24},{"hierarchy":{"lvl1":"Validation","lvl3":"How to improve spatial resolution error mapping?","lvl2":"Producing higher spatial resolution mapping results"},"content":"By having more validation data for validating the Landsat (30m) SST product, we would be able to apply more advanced models to improve spatial error mapping results. One method would be to train an ML model (e.g. Random Forest (RF), and Gradient Boosting Regressor (GBR)) algorithms on the validated pixels and then produce the error mapping with finer resolution to have an improved spatial mapping of the results. (\n\nGitHub Link1, \n\nGitHub Link2).\n\nHaving the data fused with higher spatial error mapping would enable us to better understand the reliability of our high-resolution SST map by moving beyond a single accuracy evaluation. It would also help reveal more precisely where the proposed model works well and where it fails. Here is a sample demonstration of our expected results for the next step.","type":"content","url":"/notebooks/validation#how-to-improve-spatial-resolution-error-mapping","position":25}]}