{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b5386b-4d94-4173-a2cb-9685d11081cb",
   "metadata": {},
   "source": [
    "# Landsat SST utility functions\n",
    "Author: Tasha Snow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738f8d8-f73c-41c3-9fbd-2855046d2b40",
   "metadata": {},
   "source": [
    "Note: After making changes to the `.ipynb` version of SSTutils, `File > Save notebook as`, \n",
    "change extension to `.py`, make executable in terminal with `chmod +x SSTutils.py`, and rerun `imports` cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9be0a-057c-4ea9-8a53-65ea5b37bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage import exposure\n",
    "from skimage.io import imsave, imread\n",
    "from osgeo import ogr\n",
    "import pystac_client\n",
    "from pyproj import Transformer\n",
    "from datetime import date, timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import geoviews as gv\n",
    "import hvplot.pandas\n",
    "import intake\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import intake\n",
    "from pyproj import Proj, transform\n",
    "from osgeo import gdal\n",
    "from sklearn.neighbors import BallTree\n",
    "import earthaccess\n",
    "import gzip\n",
    "\n",
    "# for progress bar\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, Dropdown\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import boto3\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.session import AWSSession\n",
    "import dask\n",
    "import os\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject\n",
    "from rasterio.warp import Resampling as resample\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from scipy.odr import Model, RealData, ODR\n",
    "import scipy.odr as odr\n",
    "import scipy\n",
    "import statsmodels.formula.api as smf\n",
    "from shapely.geometry.polygon import Polygon, Point\n",
    "import pygmt\n",
    "import gc\n",
    "import pytz\n",
    "import pyproj\n",
    "import math\n",
    "from pathlib import Path\n",
    "from matplotlib.patches import Polygon as Pgon\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc9faaa8-c4e6-4577-84cf-7fa1989adb01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to search and open Lansat scenes\n",
    "'''\n",
    "Functions to search, open, and analyze Landsat scenes.\n",
    "Search_stac finds the Landsat scene based on user parameters, \n",
    "plot_search plots the locations of the landsat scenes from the search,\n",
    "landsat_to_xarray takes one of those scenes and puts all bands into an xarray,\n",
    "and create_masks produces cloud/ice/water masks for the scene. Subset_img \n",
    "subsets a landsat scene with coordinates that have been reprojected from lat/lon\n",
    "and may be flipped in which is larger in the pair. Lsat_reproj can be used to reproject\n",
    "while ensuring x and y pairs don't get flipped (common converting between espg 3031 and wgs84.\n",
    "'''\n",
    "\n",
    "def landsat_to_xarray(sceneid, catalog, bandNames=None):\n",
    "    \"\"\"\n",
    "    Loads selected Landsat bands (and QA layers for later cloud masking) from an \n",
    "    AWS S3 bucket (via the STAC item's alternate href) into an xarray Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sceneid : intake.STAC item\n",
    "        A single STAC item pointing to Landsat assets.\n",
    "    catalog : ?????\n",
    "    bandNames : list of str, optional\n",
    "        Names of bands to load (e.g., ['red', 'swir16']). If None, all non-thermal\n",
    "        bands are included by default.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        A 3D xarray DataArray (dimensions: band, y, x) with a scalar coordinate\n",
    "        for the observation time. The bands will include 'qa_pixel', 'qa_radsat',\n",
    "        and 'VZA' in addition to any requested reflectance/thermal bands.\n",
    "    \n",
    "    Notes\n",
    "    -------\n",
    "    If multiple scenes are merged later on, xarray will fill non-overlapping areas with NaNs.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the STAC item from the catalog by its ID\n",
    "    item = catalog[sceneid.id]\n",
    "\n",
    "    bands = []\n",
    "    band_names = []\n",
    "\n",
    "    if bandNames is None:\n",
    "        # Get band names\n",
    "        for k in item.keys():\n",
    "            M = getattr(item, k).metadata\n",
    "            if 'eo:bands' in M:\n",
    "                resol = M['eo:bands'][0]['gsd']\n",
    "                if resol >= 30: # thermal bands are up sampled from 100 to 30\n",
    "                    band_names.append(k)\n",
    "    else:\n",
    "        band_names = bandNames\n",
    "\n",
    "    # Add QA bands for creating cloud mask later\n",
    "    if 'qa_pixel' not in band_names:\n",
    "        band_names.append('qa_pixel')\n",
    "    \n",
    "    band_names.append('VZA')\n",
    "    band_names.append('qa_radsat')\n",
    "\n",
    "    # Construct xarray for scene by concatenating all desired bands (including QA)\n",
    "    for band_name in band_names:\n",
    "        asset = sceneid.assets[band_name]\n",
    "        href = asset.extra_fields['alternate']['s3']['href']\n",
    "        band = xr.open_dataset(href, engine='rasterio', chunks=dict(band=1, x=512, y=512))\n",
    "        band['band'] = [band_name]\n",
    "        bands.append(band)\n",
    "    ls_scene = xr.concat(bands, dim='band')\n",
    "    ls_scene.coords['id'] = sceneid.id\n",
    "    ls_scene.coords['time'] = item.metadata['datetime'].strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    ls_scene = ls_scene['band_data']\n",
    "\n",
    "    return ls_scene\n",
    "\n",
    "##########################\n",
    "\n",
    "def create_masks(ls_scene, cloud_mask=True, ice_mask=False, ocean_mask=False):\n",
    "    \"\"\"\n",
    "    Creates cloud, ice, and ocean masks from a Landsat scene QA band. By default, \n",
    "    clouds are labeled as 1, ice as 2, ocean as 3, and all other pixels are NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ls_scene : xarray.DataArray\n",
    "        A Landsat scene loaded with a 'qa_pixel' band (as created by `landsat_to_xarray`).\n",
    "    cloud_mask : bool, optional\n",
    "        Whether to generate the cloud mask. Default is True.\n",
    "    ice_mask : bool, optional\n",
    "        Whether to generate the ice mask. Default is False.\n",
    "    ocean_mask : bool, optional\n",
    "        Whether to generate the ocean mask. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        The same input xarray object, but with an added `\"mask\"` coordinate. \n",
    "        In that mask, cloud pixels are assigned 1, ice pixels 2, ocean pixels 3, \n",
    "        and everything else is set to NaN.\n",
    "    \"\"\"\n",
    "    \n",
    "    cloud = []\n",
    "    ocean = []\n",
    "    ice = []\n",
    "\n",
    "    qa = ls_scene.sel(band='qa_pixel').astype('uint16')\n",
    "\n",
    "    n,c = np.unique(qa, return_counts=True)\n",
    "\n",
    "    for j in range(len(n)):\n",
    "        longform = f'{n[j]:016b}'\n",
    "        if (longform[-7]=='0')|(longform[-3]=='1'): #bit 2 and 6 are for cirrus and clear sky\n",
    "            cloud.append(n[j])\n",
    "        if longform[-8:]=='11000000': #bit 6 and 7 give clear sky and water, lower bits need to be 0 \n",
    "            ocean.append(n[j])\n",
    "        if longform[-7:]=='1100000': #bit 5 and 6 give ice and clear sky \n",
    "            ice.append(n[j])\n",
    "\n",
    "    if 0 in cloud:\n",
    "        cloud.remove(0)\n",
    "    if 1 in cloud:\n",
    "        cloud.remove(1)\n",
    "\n",
    "    # mask cloud, ice, and ocean\n",
    "    if cloud_mask==True:\n",
    "        # cloud is 2\n",
    "        mask_c = xr.where(qa.isin(cloud), 1, np.nan)\n",
    "\n",
    "    if ice_mask==True:\n",
    "        mask_c = xr.where(qa.isin(ice), 2, mask_c)\n",
    "\n",
    "    if ocean_mask==True:\n",
    "        mask_c = xr.where(qa.isin(ocean), 3, mask_c)\n",
    "\n",
    "    ls_scene.coords['mask'] = (('y', 'x'), mask_c.data)\n",
    "        \n",
    "    return ls_scene\n",
    "\n",
    "##########################\n",
    "\n",
    "def normalize(array):\n",
    "    '''\n",
    "    normalize a dask array so all value are between 0 and 1\n",
    "    '''\n",
    "    array_min = array.min(skipna=True)\n",
    "    array_max = array.max(skipna=True)\n",
    "    return (array - array_min) / (array_max - array_min)\n",
    "\n",
    "##########################\n",
    "\n",
    "def search_stac(url, collection, gjson_outfile=None, bbox=None, timeRange=None, filename=None):\n",
    "    \"\"\"\n",
    "    Search a STAC API for Landsat images based on either:\n",
    "    - Bounding box and time range, or\n",
    "    - Specific filename (STAC 'id').\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    url : str\n",
    "        URL to the STAC API.\n",
    "    collection : str\n",
    "        Collection name (e.g., \"landsat-c2-l2\").\n",
    "    gjson_outfile : str or None\n",
    "        Output file to save the search result as GeoJSON (optional).\n",
    "    bbox : list or None\n",
    "        Bounding box [west, south, east, north] (optional).\n",
    "    timeRange : str or None\n",
    "        Time range in ISO format, e.g., '2021-09-01/2023-03-31' (optional).\n",
    "    filename : str or None\n",
    "        Exact filename (product ID) to search for (optional).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    item_collection : pystac.ItemCollection\n",
    "        Collection of matching STAC items.\n",
    "    \"\"\"\n",
    "    \n",
    "    api = pystac_client.Client.open(url)\n",
    "\n",
    "    if filename:\n",
    "        # Search by filename (ID)\n",
    "        search = api.search(\n",
    "            collections=[collection],\n",
    "            ids=[filename],\n",
    "        )\n",
    "        # print(f\"Searching for filename: {filename}\")\n",
    "    \n",
    "    elif bbox and timeRange:\n",
    "        # Search by bbox and timeRange\n",
    "        search = api.search(\n",
    "            bbox=bbox,\n",
    "            datetime=timeRange,\n",
    "            collections=[collection],\n",
    "        )\n",
    "        # print(f\"Searching for items in bbox {bbox} and timeRange {timeRange}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Must provide either a filename, or both bbox and timeRange.\")\n",
    "\n",
    "    items = search.item_collection()\n",
    "\n",
    "    # print(f\"Found {len(items)} item(s)\")\n",
    "\n",
    "    if gjson_outfile:\n",
    "        items.save_object(gjson_outfile)\n",
    "    \n",
    "    return items\n",
    "\n",
    "###############\n",
    "\n",
    "def get_lst_mask(lstfile):\n",
    "    \"\"\"\n",
    "    Generates an open ocean mask from a Landsat scene based on the QA band information.\n",
    "\n",
    "    This function searches for a Landsat scene using a provided filename, loads the \n",
    "    'qa_pixel' band, applies cloud, ice, and ocean masking, and then extracts only \n",
    "    the open ocean pixels. The output is a mask where open ocean pixels are 1, and \n",
    "    all other pixels are NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lstfile : str\n",
    "        Path or name of the Landsat file used to derive the corresponding STAC search ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 2D mask array where open ocean pixels are 1, and all other pixels are NaN.\n",
    "    \"\"\"\n",
    "    filename = lstfile[:-11]\n",
    "    items = search_stac(url,collection,filename=filename)\n",
    "    \n",
    "    # Open stac catalog for some needed info\n",
    "    catalog = intake.open_stac_item_collection(items)\n",
    "    sceneid = items[0]\n",
    "    print(sceneid.id)\n",
    "    \n",
    "    scene = catalog[sceneid.id]\n",
    "    \n",
    "    # Open all desired bands for one scene\n",
    "    ls_scene0 = landsat_to_xarray(sceneid,catalog,bandNames=['qa_pixel'])\n",
    "    ls_scene0 = ls_scene0.rio.write_crs(\"epsg:3031\", inplace=True)\n",
    "    \n",
    "    # Create a classification mask, applying cloud, ice, and ocean masks\n",
    "    ls_scene0 = create_masks(ls_scene0, cloud_mask=True, ice_mask=True, ocean_mask=True)\n",
    "    \n",
    "    # Initialize a mask array and set all pixels not classified as open ocean (mask != 3) to NaN\n",
    "    mask = np.ones(ls_scene0.shape[1:])\n",
    "    mask[ls_scene0.mask!=3] = np.nan\n",
    "\n",
    "    try:\n",
    "        del ls_scene0\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    return mask\n",
    "\n",
    "##########################\n",
    "\n",
    "def plot_search(gf,satellite,colnm):\n",
    "    # Plot search AOI and frames on a map using Holoviz Libraries (more on these later)\n",
    "    cols = gf.loc[:,('id',colnm[0],colnm[1],'geometry')]\n",
    "    alpha = 1/gf.shape[0]**0.5 # transparency scales w number of images\n",
    "\n",
    "    footprints = cols.hvplot(geo=True, line_color='k', hover_cols=[colnm[0],colnm[1]], alpha=alpha, title=satellite,tiles='ESRI')\n",
    "    tiles = gv.tile_sources.CartoEco.options(width=700, height=500) \n",
    "    labels = gv.tile_sources.StamenLabels.options(level='annotation')\n",
    "    tiles * footprints * labels\n",
    "    \n",
    "    return footprints\n",
    "\n",
    "##########################\n",
    "\n",
    "def subset_img(da,polarx,polary):\n",
    "    '''\n",
    "    ***Only works for square grid cropping along the orientation of the grid (not when cropping along lat/lon in a 3031 grid\n",
    "    \n",
    "    Subset image in xarray to desired coordinates. Because Landsat polar stereo projection can be oriented\n",
    "    in many different directions, when coordinates to subset an image are reprojected from lat/lon they may get \n",
    "    flipped for which is larger in the pair. This function checks to make sure we are getting a proper subset and \n",
    "    avoids 0 pixels on the x or y axis. \n",
    "    \n",
    "    Note: Input shape dimensions and dataarray v. dataset changes things so input needs to be a dataarray w \n",
    "          2 dimensions (x,y)\n",
    "    \n",
    "    Input:\n",
    "    da = xarray DataArray to be subset\n",
    "    polarx = x coordinates to subset by in polar stereographic projection\n",
    "    polary = y coordinates to subset by in polar stereographic projection\n",
    "    \n",
    "    Output:\n",
    "    ls_sub = subset xarray DataArray\n",
    "    \n",
    "    '''\n",
    "    # ***Landsat shape dimensions are one fewer than they are for LandsatCalibration [0,1] not [1,2], no .to_array() or Band\n",
    "    ls_sub = da.sel(y=slice(polary[1],polary[0]),x=slice(polarx[0],polarx[1]))\n",
    "\n",
    "    # Check for right dimensions because y order changes sometimes\n",
    "    if (ls_sub.x.shape[0]==0) & (ls_sub.y.shape[0]==0):\n",
    "        # print ('L8 x and y shapes are 0')\n",
    "        ls_sub = da.sel(y=slice(polary[0],polary[1]),x=slice(polarx[1],polarx[0]))\n",
    "    elif ls_sub.y.shape[0]==0:\n",
    "        # print ('L8 y shape is 0')\n",
    "        ls_sub = da.sel(y=slice(polary[0],polary[1]),x=slice(polarx[0],polarx[1]))\n",
    "    elif ls_sub.x.shape[0]==0:\n",
    "        # print ('L8 x shape is 0')\n",
    "        ls_sub = da.sel(y=slice(polary[1],polary[0]),x=slice(polarx[1],polarx[0]))\n",
    "    # print(ls_sub.shape)\n",
    "    \n",
    "    return ls_sub\n",
    "\n",
    "##########################\n",
    "\n",
    "def lsat_reproj(old_cs,new_cs,lbox):\n",
    "    '''\n",
    "    Reprojects a bounding box from an old coordinate system to a new one, and checks\n",
    "    for round-trip transformation errors. The resulting bounding box coordinate order\n",
    "    may be flipped if the input coordinates indicate an inverted orientation. \n",
    "    Diagnostic information is printed, and the transformed bounding box is returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    old_cs : str\n",
    "        The Proj4 or EPSG string for the original (source) coordinate system.\n",
    "        For example: 'epsg:4326' or '+proj=longlat +datum=WGS84 +no_defs'.\n",
    "    new_cs : str\n",
    "        The Proj4 or EPSG string for the target coordinate system.\n",
    "    lbox : list or tuple of float\n",
    "        A bounding box specified as [ULX, LRY, LRX, ULY] in the old coordinate system.\n",
    "        - ULX: Upper Left X\n",
    "        - LRY: Lower Right Y\n",
    "        - LRX: Lower Right X\n",
    "        - ULY: Upper Left Y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bbox : list of tuples\n",
    "        The transformed bounding box in the new coordinate system. The point order\n",
    "        depends on whether the original bounding box was flipped or not:\n",
    "        - Flipped orientation: [(lULX, lLLY), (lLLX, lULY), (lLRX, lURY), (lURX, lLRY)]\n",
    "        - Normal orientation:  [(lULX, lULY), (lLLX, lLLY), (lLRX, lLRY), (lURX, lURY)]\n",
    "    checkbox : numpy.ndarray\n",
    "        An array of the round-trip check coordinates in the old coordinate system\n",
    "        after transforming back from the new coordinate system. Used to verify\n",
    "        the accuracy of the transformation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - A threshold of 0.5 (`test_threshold`) is used to check whether the\n",
    "      round-trip transformation error is too high. If the Euclidean distance\n",
    "      between the original coordinates and the transformed-back coordinates\n",
    "      exceeds this threshold, a warning is printed.\n",
    "    - The function prints diagnostic messages, including orientation checks\n",
    "      and the final bounding box. If the original bounding box was inverted\n",
    "      (LRY > ULY), a 'flipped orientation' message is displayed, and the points\n",
    "      are reordered accordingly.\n",
    "    - The function has not been extensively tested with grids that are rotated\n",
    "      or otherwise do not follow the normal bounding-box assumptions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> old_cs = 'epsg:4326'\n",
    "    >>> new_cs = 'epsg:3031'\n",
    "    >>> lbox = [-60, -85, 30, -70]  # [ULX, LRY, LRX, ULY]\n",
    "    >>> bbox, checkbox = lsat_reproj(old_cs, new_cs, lbox)\n",
    "    >>> bbox\n",
    "    [(-6671686.551, 241102.289), ... ]  # Example coordinates\n",
    "    >>> checkbox\n",
    "    array([-60.3, -70.1,  30.2, -84.9]) # Round-trip result\n",
    "\n",
    "    bbox comes out with the points out of order for making a polygon though pairs are correct. Order is 0,3,1,2 when done in normal projection. \n",
    "    Haven't tested for flipped grid.\n",
    "    '''\n",
    "    \n",
    "    test_threshold = 0.5\n",
    "    \n",
    "    # Create a transform object to convert between coordinate systems\n",
    "    inProj = Proj(init=old_cs)\n",
    "    outProj = Proj(init=new_cs)\n",
    "    \n",
    "    ULX,LRY,LRX,ULY = lbox\n",
    "\n",
    "    [lULX,lLRX], [lULY,lLRY] =  transform(inProj,outProj,[ULX,LRX], [ULY,LRY], always_xy=True)\n",
    "    [cULX,cLRX], [cULY,cLRY] =  transform(outProj,inProj,[lULX,lLRX], [lULY,lLRY], always_xy=True)\n",
    "    [lLLX,lURX], [lLLY,lURY] =  transform(inProj,outProj,[ULX,LRX], [LRY,ULY], always_xy=True)\n",
    "    [cLLX,cURX], [cLLY,cURY] =  transform(outProj,inProj,[lLLX,lURX], [lLLY,lURY], always_xy=True)\n",
    "\n",
    "    if LRY>ULY:\n",
    "        bbox = [(lULX,lLLY),(lLLX,lULY),(lLRX,lURY),(lURX,lLRY)]\n",
    "        # print('lsat_reproj flipped orientation')\n",
    "    else:\n",
    "        bbox = [(lULX,lULY),(lLLX,lLLY),(lLRX,lLRY),(lURX,lURY)]\n",
    "        # print('lsat_reproj normal orientation')\n",
    "\n",
    "    checkbox = np.array([cULX,cULY,cLRX,cLRY])\n",
    "    if np.linalg.norm(checkbox - np.array([ULX,ULY,LRX,LRY])) > test_threshold:\n",
    "        print(f\"Round-trip transformation error 1 of {np.linalg.norm(checkbox - np.array([ULX,ULY,LRX,LRY]))}\")\n",
    "    checkbox = np.array([cLLX,cLLY,cURX,cURY])\n",
    "    if np.linalg.norm(checkbox - np.array([ULX,LRY,LRX,ULY])) > test_threshold:\n",
    "        print(f\"Round-trip transformation error 2 of {np.linalg.norm(checkbox - np.array([ULX,LRY,LRX,ULY]))}\")\n",
    "    # print (f'bbox={bbox}')\n",
    "    # print (f'lbox={lbox}')\n",
    "    # print (f'checkbox={checkbox}')\n",
    "    \n",
    "    return bbox,checkbox\n",
    "\n",
    "##########################\n",
    "\n",
    "def crop_xarray_dataarray_with_polygon(dataarray, polygon):\n",
    "    \"\"\"\n",
    "    Crop an xarray.DataArray using a polygon.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataarray: xarray.DataArray with x and y coordinates.\n",
    "    - polygon: Shapely Polygon object defining the crop area.\n",
    "    \n",
    "    Returns:\n",
    "    - Cropped xarray.DataArray.\n",
    "    \"\"\"\n",
    "    # Generate a 2D array of shapely Point objects for each grid point\n",
    "    lon, lat = np.meshgrid(dataarray.x.values, dataarray.y.values)\n",
    "    points = np.vectorize(Point)(lon, lat)\n",
    "    \n",
    "    # Create a mask where points within the polygon are True\n",
    "    mask_func = np.vectorize(polygon.contains)\n",
    "    mask = mask_func(points)\n",
    "    \n",
    "    # Convert the mask to an xarray.DataArray\n",
    "    mask_da = xr.DataArray(mask, dims=[\"y\", \"x\"], coords={\"y\": dataarray.y, \"x\": dataarray.x})\n",
    "    \n",
    "    # Apply the mask to the dataarray, cropping to the polygon\n",
    "    # Use where method with drop=True to drop values outside the polygon\n",
    "    cropped_dataarray = dataarray.where(mask_da, drop=True)\n",
    "    \n",
    "    return cropped_dataarray\n",
    "\n",
    "##########################\n",
    "\n",
    "def km_to_decimal_degrees(km, latitude, direction='latitude'):\n",
    "    \"\"\"\n",
    "    Convert a distance in kilometers to decimal degrees of latitude or longitude,\n",
    "    given a specific latitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    km : float\n",
    "        The distance in kilometers to be converted.\n",
    "    latitude : float\n",
    "        The latitude (in decimal degrees, from -90 to +90) where the conversion\n",
    "        is being applied. Used only if direction='longitude'.\n",
    "    direction : str, optional\n",
    "        Either 'latitude' or 'longitude'. Determines whether to convert\n",
    "        km to decimal degrees of latitude or longitude. Default is 'latitude'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The approximate decimal degrees that correspond to the given distance in km\n",
    "        at the specified latitude (for longitude) or globally (for latitude).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    1° latitude ~ 111.32 km everywhere on Earth.\n",
    "    1° longitude ~ 111.32 km * cos(latitude), which is why the\n",
    "        conversion depends on the specified latitude for 'longitude'.\n",
    "    This function uses a spherical Earth approximation and is not exact\n",
    "    at very high latitudes or for large distances.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Convert 10 km to decimal degrees of latitude (anywhere)\n",
    "    >>> km_to_decimal_degrees(10, latitude=0, direction='latitude')\n",
    "    0.0898...\n",
    "\n",
    "    >>> # Convert 10 km to decimal degrees of longitude at latitude 69°S\n",
    "    >>> km_to_decimal_degrees(10, latitude=-69, direction='longitude')\n",
    "    0.2515...\n",
    "    \"\"\"\n",
    "    if direction.lower() == 'latitude':\n",
    "        # 1 degree of latitude ≈ 111.32 km (on average)\n",
    "        deg = km / 111.32\n",
    "    elif direction.lower() == 'longitude':\n",
    "        # 1 degree of longitude ≈ 111.32 km * cos(lat)\n",
    "        deg = km / (111.32 * math.cos(math.radians(latitude)))\n",
    "    else:\n",
    "        raise ValueError(\"direction must be 'latitude' or 'longitude'\")\n",
    "    return deg\n",
    "\n",
    "##########################\n",
    "\n",
    "def crosses_idl(coords):\n",
    "    '''\n",
    "    Determine if the set of coordinates crosses the International Dateline in a way that will mess up the creation of a polygon\n",
    "    \n",
    "    Variables:\n",
    "    coords = list of lon, lat tuples\n",
    "    \n",
    "    Output:\n",
    "    True or False\n",
    "    '''\n",
    "    \n",
    "    for (lon1, lat1), (lon2, lat2) in zip(coords, coords[1:]):\n",
    "        if abs(lon1 - lon2) >= 180:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "##########################\n",
    "\n",
    "def plot_geotiff(filepath):\n",
    "    # Open the geotiff file\n",
    "    with rio.open(filepath) as src:\n",
    "        # Reproject the dataset to lat/lon\n",
    "        transform, width, height = rio.warp.calculate_default_transform(\n",
    "            src.crs, 'EPSG:4326', src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': 'EPSG:4326',\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        # Read the data and reproject\n",
    "        with rio.MemoryFile() as memfile:\n",
    "            with memfile.open(**kwargs) as dst:\n",
    "                rio.warp.reproject(\n",
    "                    source=rio.band(src, 1),\n",
    "                    destination=rio.band(dst, 1),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs='EPSG:4326',\n",
    "                    resampling=rio.enums.Resampling.nearest\n",
    "                )\n",
    "                data = dst.read(1)\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax.set_global()\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "    ax.imshow(data, transform=ccrs.PlateCarree(), origin='upper', extent=dst.bounds, cmap='viridis')\n",
    "    ax.set_title(os.path.basename(filepath))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "def create_geotiff_dropdown(directory):\n",
    "    # Create a dropdown widget with all GeoTIFF files in the directory\n",
    "    tif_files = [f for f in os.listdir(directory) if f.endswith('.tif')]\n",
    "    dropdown = Dropdown(options=tif_files, description='Select a file:')\n",
    "    \n",
    "    # Update function to plot based on the selected file\n",
    "    def update_plot(selected_file):\n",
    "        plot_geotiff(os.path.join(directory, selected_file))\n",
    "    \n",
    "    interact(update_plot, selected_file=dropdown)\n",
    "\n",
    "##########################\n",
    "\n",
    "# Preprocess to add time dimension and the file name to open_mfdataset for landsat using the filename\n",
    "def add_time_dim(ds):\n",
    "    lstr = ds.encoding[\"source\"].split(\"LC0\",1)[1]\n",
    "    times = pd.to_datetime(lstr[14:22]+lstr[38:44], format='%Y%m%d%H%M%S')\n",
    "    idee = ds.encoding[\"source\"].split(\"/\")[8][:-4] # The first number depends on how many subdirectories the file is in\n",
    "    return ds.assign_coords(time=times,ID=idee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b303d9d-256f-4365-85b6-04a5230b851e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Atmospheric correction and production of SST\n",
    "'''\n",
    "Functions to find the matching MODIS water vapor image for atmospheric correction and production of SST.\n",
    "Open_MODIS finds and downloads the closest MODIS water vapor image to a specific landsat image. Get_wv\n",
    "aligns and subsets the modis image grid to landsat using MODISlookup and subsamples and extracts the data \n",
    "onto the Landsat grid using uniqueMODIS\n",
    "'''\n",
    "\n",
    "# def open_MODIS(ls_scene,scene,modout_path):\n",
    "#     '''\n",
    "#     Search MOD/MDY07 atmospheric data and open water vapor for data collected closest in time to \n",
    "#     Landsat scene.\n",
    "    \n",
    "#     Input:\n",
    "#     ls_scene = xarray dataset with Landsat scene\n",
    "#     modout_path = directory path for MODIS data\n",
    "#     scene = STAC catalog item\n",
    "    \n",
    "#     Output:\n",
    "#     mod07 = xarray dataset with MODIS (MOD/MDY07) water vapor \n",
    "#     modfilenm = MODIS filename for image used in atm correction\n",
    "#     '''\n",
    "\n",
    "#     # Get spatial extent of Landsat scene in lat/lon\n",
    "#     mbbox = (scene.metadata['bbox'][0], scene.metadata['bbox'][1], scene.metadata['bbox'][2], scene.metadata['bbox'][3]) #(west, south, east, north) \n",
    "#     lsatpoly = Polygon([(mbbox[0],mbbox[1]),(mbbox[0],mbbox[3]),(mbbox[2],mbbox[3]),(mbbox[2],mbbox[1]),(mbbox[0],mbbox[1])]) # ensure full lineup between landsat and modis\n",
    "\n",
    "#     ls_time = pd.to_datetime(ls_scene.time.values)\n",
    "#     calc_dt = datetime.strptime(ls_time.strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S')\n",
    "#     start_dt = (calc_dt + timedelta(days=-0.5)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     end_dt = (calc_dt + timedelta(days=0.5)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#     # Gather all files from search location from Terra and Aqua for the same day as the Landsat image\n",
    "#     results = earthaccess.search_data(\n",
    "#         short_name='MOD07_L2',\n",
    "#         bounding_box=mbbox,\n",
    "#         # Day of a landsat scene to day after - searches day of only\n",
    "#         temporal=(start_dt,end_dt)\n",
    "#     )\n",
    "#     results2 = earthaccess.search_data(\n",
    "#         short_name='MYD07_L2',\n",
    "#         bounding_box=mbbox,\n",
    "#         # Day of a landsat scene to day after - searches day of only\n",
    "#         temporal=(start_dt,end_dt)\n",
    "#     )\n",
    "#     results = results + results2\n",
    "#     print (f'{len(results)} TOTAL granules')\n",
    "\n",
    "#     # Accept only granules that overlap at least 100% with Landsat (percent_dif<0.1 is the other option)\n",
    "#     best_grans = []\n",
    "#     for granule in results:\n",
    "#         try:\n",
    "#             granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons']\n",
    "#         except Exception as error:\n",
    "#             print(error)\n",
    "#             continue\n",
    "#         for num in range(len(granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons'])):\n",
    "#             try:\n",
    "#                 map_points = [(xi['Longitude'],xi['Latitude']) for xi in granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons'][num]['Boundary']['Points']]\n",
    "#                 pgon = Polygon(map_points)\n",
    "#                 percent_dif = lsatpoly.difference(pgon).area/lsatpoly.area\n",
    "#                 if percent_dif < 0.1:\n",
    "#                     if crosses_idl(map_points):\n",
    "#                         print (f'A granule has messed up polygon that likely crosses the International DateLine')\n",
    "#                     else:\n",
    "#                         best_grans.append(granule)\n",
    "#                         continue\n",
    "#             except Exception as error:\n",
    "#                 print(error)\n",
    "#                 # Would love to raise an exception for a valueerror except for GEOSError but not sure how \n",
    "#     print(f'{len(best_grans)} TOTAL granules w overlap')\n",
    "\n",
    "#     # Find MODIS image closest in time to the Landsat image\n",
    "#     Mdates = [pd.to_datetime(granule['umm']['TemporalExtent']['RangeDateTime']['BeginningDateTime']) for granule in best_grans]\n",
    "#     ind = Mdates.index(min( Mdates, key=lambda x: abs(x - pytz.utc.localize(pd.to_datetime(ls_time)))))\n",
    "#     print(f'Time difference between MODIS and Landsat: {abs(Mdates[ind] - pytz.utc.localize(pd.to_datetime(ls_time)))}')\n",
    "\n",
    "#     # Download MODIS data if needed\n",
    "\n",
    "#     # # This doesn't work because xarray can't open legacy HDF EOS data formats\n",
    "#     # mod07 = xr.open_mfdataset(earthaccess.open(results))\n",
    "\n",
    "#     # Use these access pathways while S3 streaming is not working\n",
    "#     data_links = [granule.data_links(access=\"external\") for granule in best_grans[ind:ind+1]]\n",
    "#     netcdf_list = [g._filter_related_links(\"USE SERVICE API\")[0].replace(\".html\", \".nc4\") for g in best_grans[ind:ind+1]]\n",
    "#     # This is going to be slow as we are asking Opendap to format HDF into NetCDF4 so we only processing 3 granules\n",
    "#     # and Opendap is very prone to failures due concurrent connections, not ideal.\n",
    "#     file_handlers = earthaccess.download(netcdf_list,modout_path,provider='NSIDC')\n",
    "\n",
    "#     # Open MODIS data\n",
    "#     mod_list = os.listdir(modout_path)\n",
    "#     mod_list = [file for file in mod_list if file[-3:]=='nc4']\n",
    "#     print(mod_list)\n",
    "#     modfilenm = mod_list[0]\n",
    "    \n",
    "#     os.rename(f'{modout_path}/{modfilenm}', f'{modout_path}/{modfilenm}.gz')\n",
    "#     with gzip.open(f'{modout_path}/{modfilenm}.gz', 'rb') as f_in:\n",
    "#         with open(f'{modout_path}/{modfilenm}', 'wb') as f_out:\n",
    "#             f_out.write(f_in.read())\n",
    "\n",
    "#     mod07 = xr.open_dataset(f'{modout_path}/{modfilenm}')\n",
    "#     mod07 = mod07.rio.write_crs('epsg:4326')\n",
    "\n",
    "#     # Delete MODIS file\n",
    "#     os.remove(f'{modout_path}/{modfilenm}')\n",
    "#     os.remove(f'{modout_path}/{modfilenm}.gz')\n",
    "    \n",
    "#     return mod07,modfilenm\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# # Notes for changes - MODISlookup2 doesn't need to output lat/lon, but if want to do the check, \n",
    "# # can take the lat/lon check out of aligne and do it in \n",
    "# def get_wv(ls_scene,mod07,spacing,param,scene,interp=0):\n",
    "#     '''\n",
    "#     Aligns and resamples MODIS water vapor data to match the spatial resolution and \n",
    "#     alignment of a given Landsat scene. The function optionally applies interpolation \n",
    "#     to improve the data quality.\n",
    "\n",
    "#     Parameters:\n",
    "#     ls_scene (xarray.Dataset): The Landsat scene dataset containing spatial coordinates.\n",
    "#     mod07 (xarray.Dataset): The MODIS dataset containing water vapor data and coordinates (MOD/MDY07).\n",
    "#     spacing (list): Desired spatial resolution (y, x) for alignment with MODIS data in meters.\n",
    "#     param (str): Parameter name for the desired dataset within the MODIS file.\n",
    "#     scene: \n",
    "#     interp (int): Controls interpolation mode - 0 for none, 1 for bicubic kriging interpolation.\n",
    "\n",
    "#     Returns:\n",
    "#     WV_xr (xarray.DataArray): The processed xarray data array containing the Landsat-aligned \n",
    "#                               and resampled water vapor data from MODIS.\n",
    "\n",
    "#     Note:\n",
    "#     This function is also used in LandsatCalibration; any changes here should consider potential impacts there \n",
    "#     - may need to be copied/generalized.\n",
    "\n",
    "#     The function performs several key operations:\n",
    "#     1. Defines the bounding box for the Landsat scene based on its spatial coordinates.\n",
    "#     2. Extracts the relevant water vapor data from the MODIS dataset using the specified parameter key.\n",
    "#     3. Validates the geographic coordinate ranges (latitude and longitude) of the MODIS data.\n",
    "#     4. Applies PyGMT interpolation if requested to generate a smoother water vapor data surface.\n",
    "#     5. Utilizes a lookup function to align MODIS data indices with the Landsat grid based on the specified spatial resolution.\n",
    "#     6. Aligns and resamples the MODIS data to match the Landsat scene's grid and spatial resolution.\n",
    "#     7. Adjusts the coordinate system of the output to ensure compatibility with further processing or analysis.\n",
    "\n",
    "#     Difference: no bicubic spline interpolation in LsatCalib during the upsampling, don't set new indexes at the end\n",
    "#     '''\n",
    "#     # Read in desired variables\n",
    "#     ULX = ls_scene.x[0] \n",
    "#     ULY = ls_scene.y[0]  \n",
    "#     LRX = ls_scene.x[-1] \n",
    "#     LRY = ls_scene.y[-1] \n",
    "#     box = [ULX,LRX,ULY,LRY]\n",
    "    \n",
    "#     #Extract desired datasets from MODIS file from lookup key\n",
    "#     data = mod07[param].values\n",
    "#     lat, lon = mod07.Latitude, mod07.Longitude\n",
    "#     #data.attributes()\n",
    "\n",
    "#     # Test lat is in correct range\n",
    "#     if ~((lat <= 90) & (lat >= -90)).all():\n",
    "#         print('MODIS latitude not between -90 and 90')\n",
    "#     # Test lon is in correct range\n",
    "#     if ~((lon <= 180) & (lon >= -180)).all():\n",
    "#         print('MODIS longitude not between -180 and 180')\n",
    "\n",
    "#     # ***Need to use climatology to retrieve quantile data from this area\n",
    "    \n",
    "#     # # Get rid of low outliers from over ice, cutoff for 98.5%\n",
    "#     # outlier = np.quantile(data[np.isfinite(data)],0.015) #0.015\n",
    "#     # mask2 = np.ones(data.shape)\n",
    "#     # mask2[data<outlier] = np.nan\n",
    "#     # data = np.around(mask2*data,decimals=5)\n",
    "\n",
    "#     # Interpolate using PyGMT\n",
    "#     if interp==1:  \n",
    "#         grid = interpMOD(data,lat,lon)\n",
    "        \n",
    "#         # Produce indicies for aligning MODIS pixel subset to match Landsat image at 4000m (or 300)resolution\n",
    "#         indiciesMOD,lines,samples,lat,lon = MODISlookup(mod07,ls_scene,box,spacing,scene,interpgrid=grid)\n",
    "#         data = grid.values\n",
    "        \n",
    "#     else:\n",
    "#         # Produce indicies for aligning MODIS pixel subset to match Landsat image at 4000m (or 300)resolution\n",
    "#         indiciesMOD,lines,samples,lat,lon = MODISlookup(mod07,ls_scene,box,spacing,scene)\n",
    "\n",
    "#     # Align and resample MODIS WV to Landsat at indicated spacing with correct axes\n",
    "#     dataOutWV_xr = alignMODIS(data,lat,lon,param,indiciesMOD,lines,samples,mod07,ls_scene,spacing)\n",
    "    \n",
    "#     # # Resample WV to Landsat resolution and interpolate with B-spline\n",
    "#     # # Need to use 0.1k (this samples at .1 of the grid)\n",
    "#     # # Output of shape fits and need to adjust x and y coords cuz are wrong\n",
    "#     ups_factor = 30/spacing[0]\n",
    "#     WV_upsample = pygmt.grdsample(grid=dataOutWV_xr, spacing=f'{ups_factor}k', interpolation='c')\n",
    "#     # WV_upsample = xr.open_dataarray(lsatpath+'WV_upsample_B-spline_'+str(ls_scene.id.values))\n",
    "#     # # Resample WV to Landsat resolution manual - no interpolation\n",
    "#     # WV_resamp = MODresample(ls_scene,dataOutWV,y1,x1,spacing)\n",
    "\n",
    "#     # Put into Xarray\n",
    "#     # Sometimes spacing works properly with -1 and sometimes not\n",
    "#     latnew = np.arange(dataOutWV_xr.latitude[0],dataOutWV_xr.latitude[-1]+1,(dataOutWV_xr.latitude[-1]-dataOutWV_xr.latitude[0])/(WV_upsample.shape[0]-1))\n",
    "#     if (WV_upsample.shape[0]!=latnew.shape[0]):\n",
    "#         latnew = np.arange(dataOutWV_xr.latitude[0],dataOutWV_xr.latitude[-1]+1,(dataOutWV_xr.latitude[-1]-dataOutWV_xr.latitude[0])/(WV_upsample.shape[0]))\n",
    "\n",
    "#     # Put into Xarray\n",
    "#     latnew = ls_scene.y[:WV_upsample.shape[0]].values\n",
    "#     lonnew = ls_scene.x[:WV_upsample.shape[1]].values\n",
    "#     if dataOutWV_xr.latitude[0]!=latnew[0]:\n",
    "#         print('Aligned y dim needs to start with the same coordinate as ls_scene')\n",
    "#     if dataOutWV_xr.longitude[0]!=lonnew[0]:\n",
    "#         print('Aligned x dim needs to start with the same coordinate as ls_scene')\n",
    "    \n",
    "#     WV_xr = xr.DataArray(WV_upsample,name='SST',dims=[\"y\",\"x\"], coords={\"latitude\": ([\"y\"],latnew), \"longitude\": ([\"x\"],lonnew)})\n",
    "\n",
    "#     WV_xr = WV_xr.rio.write_crs(\"epsg:3031\", inplace=True)\n",
    "#     WV_xr = WV_xr.rename({'longitude':'x','latitude':'y'})\n",
    "    \n",
    "#     return WV_xr\n",
    "\n",
    "# ##########################\n",
    "            \n",
    "# def interpMOD(data,lat,lon):\n",
    "#     \"\"\"\n",
    "#     Interpolate spatial water vapor data using PyGMT.\n",
    "\n",
    "#     This function takes arrays of water vapor data along with corresponding latitude and longitude values,\n",
    "#     performs interpolation to fill in gaps in the data, and produces a continuous surface representation of water vapor.\n",
    "\n",
    "#     Args:\n",
    "#         data (numpy.ndarray): 2D array of water vapor measurements.\n",
    "#         lat (numpy.ndarray): 2D array of latitude values corresponding to `data`.\n",
    "#         lon (numpy.ndarray): 2D array of longitude values corresponding to `data`.\n",
    "\n",
    "#     Returns:\n",
    "#         grid (xarray.DataArray): A PyGMT grid object representing the interpolated surface of water vapor data.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Interpolate using PyGMT\n",
    "#     # Extract necessary data into Pandas DataFrame (required for PyGMT)\n",
    "#     df = pd.DataFrame({\n",
    "#         'longitude': lon.values.flatten(), # Flatten to convert from 2D to 1D array\n",
    "#         'latitude': lat.values.flatten(),\n",
    "#         'water_vapor': data.flatten() # Actual data values to be interpolated\n",
    "#     })\n",
    "\n",
    "#     # Remove missing or NaN values from DataFrame, as `surface` cannot handle them\n",
    "#     df = df.dropna(subset=['water_vapor'])\n",
    "\n",
    "#     # Determine the geographical extent for the interpolation based on the provided data points.\n",
    "#     # This is necessary to define the spatial domain over which PyGMT will perform interpolation.\n",
    "#     # [xmin, xmax, ymin, ymax] - made this the full image\n",
    "#     region = [df.longitude.min(), df.longitude.max(), df.latitude.min(), df.latitude.max()]\n",
    "#     # Alternatively, if the region is predefined (e.g., from metadata), it can be set directly.\n",
    "\n",
    "#     # Use PyGMT to interpolate the data. PyGMT requires a session context to manage memory and configuration\n",
    "#     # settings efficiently during its operations.\n",
    "#     with pygmt.clib.Session() as session:\n",
    "#         # Perform grid-based surface interpolation.\n",
    "#         # The `data` parameter takes longitude, latitude, and water vapor as a NumPy array.\n",
    "#         # `region` specifies the geographical extent.\n",
    "#         # `spacing` sets the resolution of the output grid, here 0.3 km for high resolution.\n",
    "#         # `tension` controls the stiffness of the interpolating surface. A value of 0.25 gives a balance between\n",
    "#         # fitting the data closely and producing a smooth surface.\n",
    "#         grid = pygmt.surface(\n",
    "#             data=df[['longitude', 'latitude', 'water_vapor']].to_numpy(),  # Input data as NumPy array\n",
    "#             region=region,  \n",
    "#             spacing=['0.15k','0.05k'],  # f'0.3k'\n",
    "#             tension=0.95,  \n",
    "#         )   \n",
    "    \n",
    "#     return grid\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# def MODISlookup(mod07,lsat_filt_msk,box,spacing,scene,interpgrid=None):\n",
    "#     '''\n",
    "#     Look up indices for aligning MODIS product to the Landsat grid\n",
    "#     # Modified from http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file \n",
    "#     # and Shane Grigsby\n",
    "\n",
    "#     Variables:    \n",
    "#     mod07 = xarray with MODIS data with crs 4326 assigned\n",
    "#     lsat_filt_msk =  Landsat xarray DataArray\n",
    "#     box = list with [left easting,right easting,top northing,bottom northing]\n",
    "#     spacing = desired pixel size for extraction, list of [east/west, north/south] \n",
    "#           (recommend choosing a number that allows for fast calculations and even division by 30)\n",
    "#     scene = \n",
    "#     interpgrid = xarray of mod07 data that has been through interpolation in PyGMT (optional)\n",
    "\n",
    "#     Output:\n",
    "#     indiciesMOD = indicies used to project MODIS pixels to match Landsat pixels\n",
    "#     lines = number of lines in Landsat file/MODIS output shape\n",
    "#     samples = number of samples in Landsat file/MODIS output shape\n",
    "#     lon,lat = 2D lon and lat coordinates for grid\n",
    "#     '''\n",
    "#     test_threshold = 5\n",
    "    \n",
    "#     if interpgrid is None:\n",
    "#         lat, lon = mod07.Latitude.values, mod07.Longitude.values\n",
    "#     else:\n",
    "#         lat, lon = interpgrid.lat, interpgrid.lon\n",
    "#         lon, lat = np.meshgrid(lon,lat)\n",
    "\n",
    "#     # Test lat is in correct range\n",
    "#     if ~((lat <= 90) & (lat >= -90)).all():\n",
    "#         print('MODIS latitude not between -90 and 90')\n",
    "#     # Test lon is in correct range\n",
    "#     if ~((lon <= 180) & (lon >= -180)).all():\n",
    "#         print('MODIS longitude not between -180 and 180')\n",
    "\n",
    "#     # Get the existing coordinate system\n",
    "#     old_cs = ls_scene.rio.crs # 'epsg:3031'\n",
    "#     new_cs = mod07.rio.crs # 'epsg:4326'\n",
    "\n",
    "#     # Create a transform object to convert between coordinate systems\n",
    "#     inProj = Proj(init=old_cs)\n",
    "#     outProj = Proj(init=new_cs)\n",
    "\n",
    "#     # Parse coordinates and spacing to different variables\n",
    "#     west,east,north,south = box\n",
    "#     ewspace,nsspace = spacing\n",
    "\n",
    "#     # Setting up grid, x coord from here to here at this spacing, mesh grid makes 2D\n",
    "#     samples = len(np.r_[west:east+1:ewspace])\n",
    "#     lines = len(np.r_[north:south-1:nsspace])#ns space is -300, could also do 30 instead of 300, but would just have duplicate pixels\n",
    "#     if lines==0:\n",
    "#         lines = len(np.r_[south:north-1:nsspace])\n",
    "\n",
    "#     # x1, y1 = np.meshgrid(np.r_[west:east:ewspace],np.r_[north:south:nsspace]) # offset by 1 meter to preserve shape\n",
    "#     ewdnsamp = int(spacing[0]/30)\n",
    "#     nsdnsamp = int(spacing[1]/30)\n",
    "    \n",
    "#     # Set up coarser sampling and check to make sure is in the same orientation as the original Landsat grid\n",
    "#     xresamp = ls_scene.x.isel(x=slice(None, None, ewdnsamp)).values\n",
    "#     if xresamp[0]!=ls_scene.x.values[0]:\n",
    "#         xresamp = ls_scene.x.isel(x=slice(None, None, -ewdnsamp)).values\n",
    "#         print('x resample reversed')\n",
    "#     yresamp = ls_scene.y.isel(y=slice(None, None, nsdnsamp)).values\n",
    "#     if yresamp[0]!=ls_scene.y.values[0]:\n",
    "#         yresamp = ls_scene.y.isel(y=slice(None, None, -nsdnsamp)).values\n",
    "#         print('y resample reversed')\n",
    "#     x1, y1 = np.meshgrid(xresamp,yresamp)\n",
    "#     LScoords = np.vstack([x1.ravel(),y1.ravel()]).T\n",
    "#     if (LScoords[0,0]!=ls_scene.x.values[0]) |  (LScoords[0,1]!=ls_scene.y.values[0]):\n",
    "#         raise Exception('Landsat coordinates do not match expected during MODIS lookup')\n",
    "\n",
    "#     # Ravel so ND can lookup easily\n",
    "#     # Convert from LS map coords to lat lon --> x = lon, y = lat (usually?)\n",
    "\n",
    "#     ###Make into test\n",
    "#     # Test that reprojection is working correctly on first and last grid point using round-trip transformation\n",
    "#     xs1, ys1 =  transform(inProj,outProj,LScoords[0,0], LScoords[0,1], radians=True, always_xy=True)\n",
    "#     xsl1, ysl1 =  transform(outProj,inProj,xs1, ys1, radians=True, always_xy=True)\n",
    "#     if np.linalg.norm(np.array([xsl1, ysl1]) - LScoords[0,:]) > test_threshold:\n",
    "#         print(f\"Round-trip transformation error for point {LScoords[0,:]}, {np.linalg.norm(np.array([xsl1, ysl1]) - LScoords[0,:])}\")\n",
    "#     else:\n",
    "#         # If passes, run on entire grid\n",
    "#         xs, ys =  transform(inProj,outProj,LScoords[:,0], LScoords[:,1], radians=True, always_xy=True)\n",
    "#     ###\n",
    "    \n",
    "#     # Produce landsat reprojected to lat/lon and ensure lat is in 0 column\n",
    "#     # Test: landsat data is in correct orientation as long as lat is in col 0 and lon in col 1\n",
    "#     grid_coords = test_gridcoords(xs,ys,scene)\n",
    "\n",
    "#     # Test that lines and samples match grid_coords\n",
    "#     if len(grid_coords) != lines*samples:\n",
    "#         raise Exception(f'Size of grid coordinates do not match low resolution Landsat dims: {len(grid_coords)} vs. {lines*samples}. Check that spacing is negative for y')\n",
    "#     MODIS_coords = np.vstack([lat.ravel(),lon.ravel()]).T\n",
    "#     MODIS_coords *= np.pi / 180. # to radians\n",
    "\n",
    "#     # Build lookup, haversine = calc dist between lat,lon pairs so can do nearest neighbor on sphere - if did utm it would be planar\n",
    "#     MOD_Ball = BallTree(MODIS_coords,metric='haversine') #sklearn library\n",
    "#     distanceMOD, indiciesMOD= MOD_Ball.query(grid_coords, dualtree=True, breadth_first=True)\n",
    "        \n",
    "#     return indiciesMOD,lines,samples,lat,lon\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# def test_gridcoords(xs,ys,scene):\n",
    "#     '''\n",
    "#     Test to ensure grid lat and lon are not swapped during reprojection and output grid coordinates\n",
    "#     that have been raveled and stacked for input into BallTree\n",
    "    \n",
    "#     Variables:\n",
    "#     xs = 1D radians representing longitude \n",
    "#     ys = 1D radians representing latitude\n",
    "#     scene = catalog item for landsat image\n",
    "    \n",
    "#     Output:\n",
    "#     grid_coords = two columns of x/y radian pairs representing lon/lat\n",
    "#     '''\n",
    "    \n",
    "#     # Convert radians to lat/lon\n",
    "#     x_check = xs * 180. / np.pi\n",
    "#     y_check = ys * 180. / np.pi\n",
    "    \n",
    "#     # We know lat is ys and lon is xs if this is true so goes in 0 column position to match MODIS\n",
    "#     if ((-90 <= y_check) & (y_check <= -60)).all() & ~((-90 <= x_check) & (x_check <= -60)).all():\n",
    "#         grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T # note y / x switch (i.e., lat long convention)\n",
    "#         print('Latitude in proper position')\n",
    "\n",
    "#     # A small subset of data have lat and lon that falls between -60 and -90 so test if the landsat metadata confirms that\n",
    "#     elif ((-90 <= y_check) & (y_check <= -60)).all():\n",
    "#         llons = np.array((float(scene.metadata['bbox'][0]), float(scene.metadata['bbox'][2])))\n",
    "#         # ys is latitude if true here\n",
    "#         if ((-90 <= llons) & (llons <= -60)).all():\n",
    "#             grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T # note y / x switch (i.e., lat long convention)\n",
    "#             print('Latitude in proper position')\n",
    "#         # xs is latitude if not and goes in 0 column position\n",
    "#         else:\n",
    "#             grid_coords = np.vstack([xs.ravel(),ys.ravel()]).T \n",
    "#             print('Latitude in wrong position')\n",
    "\n",
    "#     # Otherwise xs is latitude and goes in 0 column position\n",
    "#     else:\n",
    "#         grid_coords = np.vstack([xs.ravel(),ys.ravel()]).T\n",
    "#         print('Latitude in wrong position')\n",
    "    \n",
    "#     return grid_coords\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# def alignMODIS(data,lat,lon,param,indiciesMOD,lines,samples,mod07,ls_scene,spacing):\n",
    "#     test_threshold = 5\n",
    "    \n",
    "#     # Check to ensure lat/lon and data have compatible shapes\n",
    "#     if (np.shape(lat)== np.shape(lon)== np.shape(data))==False:\n",
    "#         raise Exception(\"Error in creating indicies, lat/lon and data shapes do not match\")\n",
    "        \n",
    "#     # Extract MODIS data into Landsat grid and gather unique data values\n",
    "#     dataOut,uniqWV = uniqueMODIS(data,param,indiciesMOD,lines,samples)\n",
    "    \n",
    "#     # Check grid directionality and create matching x/y for new grid\n",
    "#     # Define the source and target coordinate reference systems (CRS)\n",
    "#     src_crs = mod07.rio.crs #'epsg:4326'  MODIS\n",
    "#     target_crs = ls_scene.rio.crs #crs[6:] # 'epsg:3031' Landsat\n",
    "\n",
    "#     # Create a PyProj transformer\n",
    "#     transformer = pyproj.Transformer.from_crs(src_crs, target_crs, always_xy=True)\n",
    "#     transformer_test = pyproj.Transformer.from_crs(target_crs, src_crs, always_xy=True)\n",
    "\n",
    "#     # Test that reprojection is working correctly on first and last modis grid point\n",
    "#     xm1,xm2 = lon[0,0],lon[-1,-1]\n",
    "#     ym1,ym2 = lat[0,0],lat[-1,-1]\n",
    "#     xx,yy = [xm1,xm2], [ym1,ym2]\n",
    "#     xs1, ys1 =  transformer.transform(xx,yy)\n",
    "#     xsl1, ysl1 = transformer_test.transform(xs1, ys1)\n",
    "#     for i,n in enumerate(xsl1):\n",
    "#         if np.linalg.norm(np.array([xsl1[i], ysl1[i]]) - [xx[i],yy[i]]) > test_threshold:\n",
    "#             print(f\"Round-trip transformation error for {sceneid}, {np.linalg.norm(np.array([xsl1[i], ysl1[i]]) - xx[i],yy[i])}\")\n",
    "    \n",
    "#     # Spacing to create x and y parameters at the correct spacing\n",
    "#     redy = int(abs(spacing[0]/30))\n",
    "#     redx = int(abs(spacing[1]/30))\n",
    "\n",
    "#     # Set up coarser sampling and check to make sure is in the same orientation as the original Landsat grid\n",
    "#     xgrid = ls_scene.x.isel(x=slice(None, None, redx)).values\n",
    "#     if xgrid[0]!=ls_scene.x.values[0]:\n",
    "#         xgrid = ls_scene.x.isel(x=slice(None, None, -redx)).values\n",
    "#     ygrid = ls_scene.y.isel(y=slice(None, None, redy)).values\n",
    "#     if ygrid[0]!=ls_scene.y.values[0]:\n",
    "#         ygrid = ls_scene.y.isel(y=slice(None, None, -redy)).values\n",
    "#     if (xgrid[0]!=ls_scene.x.values[0]) |  (ygrid[0]!=ls_scene.y.values[0]):\n",
    "#         raise Exception('Landsat coordinates do not match expected during MODIS lookup')\n",
    "    \n",
    "#     # Create xarray from numpy array\n",
    "#     dataOut_xr = xr.DataArray(dataOut,name='SST',dims=[\"y\",\"x\"], coords={\"latitude\": ([\"y\"],ygrid), \"longitude\": ([\"x\"],xgrid)})\n",
    "    \n",
    "#     return dataOut_xr\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# def uniqueMODIS(data,param,indiciesMOD,lines,samples):\n",
    "#     '''\n",
    "#     Extracts data values and unique values from desired MODIS dataset that corresponds to Landsat file\n",
    "#     # Modified from http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "    \n",
    "#     Variables: \n",
    "#     data = array with MOD07 data in crs 4326 assigned \n",
    "#     param =  string for desired dataset from MODIS file\n",
    "#     indiciesMOD = indicies output for neighest neighbor query from MODIS to Landsat coordinates\n",
    "#     lines = number of lines in Landsat file/MODIS output shape\n",
    "#     samples = number of samples in Landsat file/MODIS output shape\n",
    "    \n",
    "#     Output:\n",
    "#     dataOut = MODIS atm image subset and aligned to Landsat image pixels\n",
    "#     uniq = uniq MODIS atm values within area of Landsat image\n",
    "#     #counts = count for each unique value in subset\n",
    "#     '''\n",
    "#     # Convert from K to C\n",
    "#     KtoC = -273.15\n",
    "    \n",
    "#     # Scaling coefficients for MODIS data\n",
    "#     wv_scale = 0.0010000000474974513\n",
    "#     ozone_scale = 0.10000000149011612\n",
    "\n",
    "#     # Reproject data from MODIS into corresponding postions for Landsat pixels for water vapor and ozone\n",
    "#     if param == 'sst':\n",
    "#         dataOut = np.reshape(np.array(data.ravel())[indiciesMOD],(lines,samples))#* # to scale?\n",
    "#         dataOut[dataOut < -3] = np.nan\n",
    "#         MODimg = np.array(data)#* # to scale?\n",
    "#         MODimg[MODimg < 0] = np.nan\n",
    "#     elif param == 'Water_Vapor':\n",
    "#         dataOut = np.reshape(np.array(data.ravel())[indiciesMOD] * wv_scale,(lines,samples))\n",
    "#         dataOut[dataOut < 0] = np.nan\n",
    "#         MODimg = np.array(data*wv_scale)\n",
    "#         MODimg[MODimg < 0] = np.nan\n",
    "#     elif param == 'Total_Ozone':\n",
    "#         dataOut = np.reshape(np.array(data.ravel())[indiciesMOD] * ozone_scale,(lines,samples))\n",
    "#         dataOut[dataOut < 225] = np.nan\n",
    "#         dataOut[dataOut > 430] = np.nan\n",
    "#         MODimg = np.array(data*ozone_scale)\n",
    "#         MODimg[MODimg < 0] = np.nan\n",
    "\n",
    "#     # Get unique values for datasets within Landsat extent\n",
    "#     #uniq, inverse, counts= np.unique(dataOut, return_inverse=True, return_counts=True)\n",
    "#     uniq = set(dataOut[np.isfinite(dataOut)])\n",
    "    \n",
    "#     return dataOut,uniq # Can also output MODimg and inverse and counts if desired\n",
    "\n",
    "\n",
    "# Atmospheric correction and production of SST\n",
    "'''\n",
    "Functions to find the matching MODIS water vapor image for atmospheric correction and production of SST.\n",
    "Open_MODIS finds and downloads the closest MODIS water vapor image to a specific landsat image. Get_wv\n",
    "aligns and subsets the modis image grid to landsat using MODISlookup and subsamples and extracts the data \n",
    "onto the Landsat grid using uniqueMODIS\n",
    "'''\n",
    "\n",
    "def open_MODIS(ls_scene,scene,modout_path):\n",
    "    '''\n",
    "    Search MOD/MDY07 atmospheric data and open water vapor for data collected closest in time to \n",
    "    Landsat scene.\n",
    "    \n",
    "    Input:\n",
    "    ls_scene = xarray dataset with Landsat scene\n",
    "    modout_path = directory path for MODIS data\n",
    "    scene = STAC catalog item\n",
    "    \n",
    "    Output:\n",
    "    mod07 = xarray dataset with MODIS (MOD/MDY07) water vapor \n",
    "    modfilenm = MODIS filename for image used in atm correction\n",
    "    '''\n",
    "\n",
    "    # Get spatial extent of Landsat scene in lat/lon\n",
    "    mbbox = (scene.metadata['bbox'][0], scene.metadata['bbox'][1], scene.metadata['bbox'][2], scene.metadata['bbox'][3]) #(west, south, east, north) \n",
    "    lsatpoly = Polygon([(mbbox[0],mbbox[1]),(mbbox[0],mbbox[3]),(mbbox[2],mbbox[3]),(mbbox[2],mbbox[1]),(mbbox[0],mbbox[1])]) # ensure full lineup between landsat and modis\n",
    "\n",
    "    ls_time = pd.to_datetime(ls_scene.time.values)\n",
    "    calc_dt = datetime.strptime(ls_time.strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S')\n",
    "    start_dt = (calc_dt + timedelta(days=-0.5)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_dt = (calc_dt + timedelta(days=0.5)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Gather all files from search location from Terra and Aqua for the same day as the Landsat image\n",
    "    results = earthaccess.search_data(\n",
    "        short_name='MOD07_L2',\n",
    "        bounding_box=mbbox,\n",
    "        # Day of a landsat scene to day after - searches day of only\n",
    "        temporal=(start_dt,end_dt)\n",
    "    )\n",
    "    results2 = earthaccess.search_data(\n",
    "        short_name='MYD07_L2',\n",
    "        bounding_box=mbbox,\n",
    "        # Day of a landsat scene to day after - searches day of only\n",
    "        temporal=(start_dt,end_dt)\n",
    "    )\n",
    "    results = results + results2\n",
    "    print (f'{len(results)} TOTAL granules')\n",
    "\n",
    "    # Accept only granules that overlap at least 100% with Landsat (percent_dif<0.1 is the other option)\n",
    "    best_grans = []\n",
    "    for granule in results:\n",
    "        try:\n",
    "            granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons']\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            continue\n",
    "        for num in range(len(granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons'])):\n",
    "            try:\n",
    "                map_points = [(xi['Longitude'],xi['Latitude']) for xi in granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons'][num]['Boundary']['Points']]\n",
    "                pgon = Polygon(map_points)\n",
    "                percent_dif = lsatpoly.difference(pgon).area/lsatpoly.area\n",
    "                if percent_dif == 0.0:\n",
    "                    if crosses_idl(map_points):\n",
    "                        print (f'A granule has a problematic polygon that likely crosses the International DateLine')\n",
    "                    else:\n",
    "                        best_grans.append(granule)\n",
    "                        continue\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                # Would love to raise an exception for a valueerror except for GEOSError but not sure how \n",
    "    print(f'{len(best_grans)} TOTAL granules w overlap')\n",
    "\n",
    "    # Find MODIS image closest in time to the Landsat image\n",
    "    Mdates = [pd.to_datetime(granule['umm']['TemporalExtent']['RangeDateTime']['BeginningDateTime']) for granule in best_grans]\n",
    "    ind = Mdates.index(min( Mdates, key=lambda x: abs(x - pytz.utc.localize(pd.to_datetime(ls_time)))))\n",
    "    print(f'Time difference between MODIS and Landsat: {abs(Mdates[ind] - pytz.utc.localize(pd.to_datetime(ls_time)))}')\n",
    "\n",
    "    # Download MODIS data if needed\n",
    "\n",
    "    # # This doesn't work because xarray can't open legacy HDF EOS data formats\n",
    "    # mod07 = xr.open_mfdataset(earthaccess.open(results))\n",
    "\n",
    "    # Use these access pathways while S3 streaming is not working\n",
    "    data_links = [granule.data_links(access=\"external\") for granule in best_grans[ind:ind+1]]\n",
    "    netcdf_list = [g._filter_related_links(\"USE SERVICE API\")[0].replace(\".html\", \".nc4\") for g in best_grans[ind:ind+1]]\n",
    "    # This is going to be slow as we are asking Opendap to format HDF into NetCDF4 so we only processing 3 granules\n",
    "    # and Opendap is very prone to failures due concurrent connections, not ideal.\n",
    "    file_handlers = earthaccess.download(netcdf_list,modout_path,provider='NSIDC')\n",
    "\n",
    "    # Open MODIS data\n",
    "    mod_list = os.listdir(modout_path)\n",
    "    mod_list = [file for file in mod_list if file[-3:]=='nc4']\n",
    "    # print(mod_list)\n",
    "    modfilenm = mod_list[0]\n",
    "    \n",
    "    os.rename(f'{modout_path}/{modfilenm}', f'{modout_path}/{modfilenm}.gz')\n",
    "    with gzip.open(f'{modout_path}/{modfilenm}.gz', 'rb') as f_in:\n",
    "        with open(f'{modout_path}/{modfilenm}', 'wb') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "\n",
    "    mod07 = xr.open_dataset(f'{modout_path}/{modfilenm}')\n",
    "    mod07 = mod07.rio.write_crs('epsg:4326')\n",
    "\n",
    "    # Delete MODIS file\n",
    "    os.remove(f'{modout_path}/{modfilenm}')\n",
    "    os.remove(f'{modout_path}/{modfilenm}.gz')\n",
    "    \n",
    "    return mod07,modfilenm\n",
    "\n",
    "##########################\n",
    "    \n",
    "def find_MODIS(lonboundsC,latboundsC,ls_scene):\n",
    "    '''\n",
    "    Finds the MODIS SST scene most closely coincident to a Landsat scene\n",
    "    Uses full Landsat scene extent, not cropped\n",
    "    \n",
    "    Variables: \n",
    "    ls_scene = xarray for one Landsat scene\n",
    "    \n",
    "    Outputs:\n",
    "    mod_scene = xarray of MODIS SST image coincident in time with the Landsat scene\n",
    "    granules[ind]['umm']['GranuleUR'] = modis file name\n",
    "    min_time = the time difference between the Landsat image acquisition and chosen MODIS image\n",
    "    \n",
    "    **not done, Differences from NLSST: 0.0 used as percent_dif requiring 100% overlap between MODIS and Landsat here since the subset area is so small\n",
    "    '''\n",
    "    \n",
    "    mbox = (lonboundsC[0],latboundsC[0],lonboundsC[1],latboundsC[1]) #east, south,west,north\n",
    "\n",
    "    # Construct a polygon to select a best fit MODIS image based on overlap\n",
    "    # Using the entire Landsat image\n",
    "    ls_scene_reproj = ls_scene.rio.reproject(\"EPSG:4326\")\n",
    "    xmin,xmax,ymin,ymax = ls_scene_reproj.x.values[0],ls_scene_reproj.x.values[-1],ls_scene_reproj.y.values[0],ls_scene_reproj.y.values[-1]\n",
    "    lsatpoly = Polygon([(xmin,ymin),(xmin,ymax),(xmax,ymax),(xmax,ymin),(xmin,ymin)])\n",
    "    \n",
    "    # Get date/time for Landsat image and search for corresponding MODIS imagery  \n",
    "    ls_time = pd.to_datetime(ls_scene.time.values)\n",
    "    calc_dt = datetime.strptime(ls_time.strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S')\n",
    "    start_dt = (calc_dt + timedelta(days=-0.5)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_dt = (calc_dt + timedelta(days=0.5)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Gather all files from search location from Terra and Aqua for the same day as the Landsat image\n",
    "    granules = earthaccess.search_data(\n",
    "        short_name='MODIS_T-JPL-L2P-v2019.0',\n",
    "        bounding_box=mbox,\n",
    "        # Day of a landsat scene to day after - searches day of only\n",
    "        temporal=(start_dt,end_dt)\n",
    "    )\n",
    "    granules2 = earthaccess.search_data(\n",
    "        short_name='MODIS_A-JPL-L2P-v2019.0', #MODIS_AQUA_L3_SST_THERMAL_DAILY_4KM_NIGHTTIME_V2019.0\n",
    "        bounding_box=mbox,\n",
    "        # Day of a landsat scene to day after - searches day of only\n",
    "        temporal=(start_dt,end_dt)\n",
    "    )\n",
    "    granules = granules + granules2\n",
    "    print (f'{len(granules)} TOTAL MODIS granules')\n",
    "\n",
    "    # Accept only MODIS granules that overlap at least a perscribed amount with Landsat, in this case 100% => percent_dif=0.0\n",
    "    best_grans = []\n",
    "    for granule in granules:\n",
    "        try:\n",
    "            granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons']\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            continue\n",
    "            # Would love to raise an exception for a valueerror except for GEOSError\n",
    "        for num in range(len(granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons'])):\n",
    "            try:\n",
    "                # Extract points, make into a polygon\n",
    "                map_points = [(xi['Longitude'],xi['Latitude']) for xi in granule['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']['GPolygons'][num]['Boundary']['Points']]\n",
    "                pgon = Polygon(map_points)\n",
    "                percent_dif = lsatpoly.difference(pgon).area/lsatpoly.area\n",
    "                # If the polygon covers the landsat area, check to make sure it doesn't cross the international date line with a messed up polygon (these are searched wrong in earthaccess so probably need adjustment there)\n",
    "                if percent_dif == 0.0:\n",
    "                    if crosses_idl(map_points):\n",
    "                        print (f'A granule has messed up polygon that likely crosses the International DateLine')\n",
    "                    else:\n",
    "                        best_grans.append(granule)\n",
    "                        continue\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                # Would love to raise an exception for a valueerror except for GEOSError\n",
    "    print(f'{len(best_grans)} remaining MODIS granules')\n",
    "\n",
    "    # Find MODIS image closest in time to each Landsat image\n",
    "    # Make Landsat datetime timezone aware (UTC)\n",
    "    Mdates = [pd.to_datetime(granule['umm']['TemporalExtent']['RangeDateTime']['BeginningDateTime']) for granule in best_grans]\n",
    "    ind = Mdates.index(min( Mdates, key=lambda x: abs(x - pytz.utc.localize(ls_time))))\n",
    "    time_dif = abs(Mdates[ind] - pytz.utc.localize(pd.to_datetime(ls_time)))\n",
    "    print(f'Time difference between MODIS and Landsat: {time_dif}')\n",
    "\n",
    "    mod_scene = xr.open_dataset(earthaccess.open(best_grans[ind:ind+1])[0])\n",
    "    mod_scene = mod_scene.rio.write_crs(\"epsg:4326\", inplace=True) \n",
    "    \n",
    "    return mod_scene, granules[ind]['umm']['GranuleUR'],time_dif\n",
    "\n",
    "##########################  \n",
    "\n",
    "# Notes for changes - MODISlookup2 doesn't need to output lat/lon, but if want to do the check, \n",
    "# can take the lat/lon check out of aligne and do it in \n",
    "def get_wv(ls_scene,mod07,spacing,param,scene,interp=0):\n",
    "    '''\n",
    "    Aligns and resamples MODIS water vapor data to match the spatial resolution and \n",
    "    alignment of a given Landsat scene. The function optionally applies interpolation \n",
    "    to improve the data quality.\n",
    "\n",
    "    Parameters:\n",
    "    ls_scene (xarray.Dataset): The Landsat scene dataset containing spatial coordinates.\n",
    "    mod07 (xarray.Dataset): The MODIS dataset containing water vapor data and coordinates (MOD/MDY07).\n",
    "    spacing (list): Desired spatial resolution (y, x) for alignment with MODIS data in meters.\n",
    "    param (str): Parameter name for the desired dataset within the MODIS file.\n",
    "    scene: \n",
    "    interp (int): Controls interpolation mode - 0 for none, 1 for bicubic kriging interpolation.\n",
    "\n",
    "    Returns:\n",
    "    WV_xr (xarray.DataArray): The processed xarray data array containing the Landsat-aligned \n",
    "                              and resampled water vapor data from MODIS.\n",
    "\n",
    "    Note:\n",
    "    This function is also very similar to get_sst used in LandsatCalibration; any changes here should consider potential \n",
    "    impacts there - may need to be copied/generalized.\n",
    "\n",
    "    The function performs several key operations:\n",
    "    1. Defines the bounding box for the Landsat scene based on its spatial coordinates.\n",
    "    2. Extracts the relevant water vapor data from the MODIS dataset using the specified parameter key.\n",
    "    3. Validates the geographic coordinate ranges (latitude and longitude) of the MODIS data.\n",
    "    4. Applies PyGMT interpolation if requested to generate a smoother water vapor data surface.\n",
    "    5. Utilizes a lookup function to align MODIS data indices with the Landsat grid based on the specified spatial resolution.\n",
    "    6. Aligns and resamples the MODIS data to match the Landsat scene's grid and spatial resolution.\n",
    "    7. Adjusts the coordinate system of the output to ensure compatibility with further processing or analysis.\n",
    "\n",
    "    Difference: no bicubic spline interpolation in LsatCalib during the upsampling, don't set new indexes at the end\n",
    "    '''\n",
    "    # Read in desired variables\n",
    "    ULX = ls_scene.x[0] \n",
    "    ULY = ls_scene.y[0]  \n",
    "    LRX = ls_scene.x[-1] \n",
    "    LRY = ls_scene.y[-1] \n",
    "    box = [ULX,LRX,ULY,LRY]\n",
    "    \n",
    "    #Extract desired datasets from MODIS file from lookup key (automatically scaled by xarray so no need to do it here)\n",
    "    data = mod07[param].values\n",
    "    lat, lon = mod07.Latitude, mod07.Longitude\n",
    "    #data.attributes()\n",
    "\n",
    "    # Test lat is in correct range\n",
    "    if ~((lat <= 90) & (lat >= -90)).all():\n",
    "        print('MODIS latitude not between -90 and 90')\n",
    "    # Test lon is in correct range\n",
    "    if ~((lon <= 180) & (lon >= -180)).all():\n",
    "        print('MODIS longitude not between -180 and 180')\n",
    "\n",
    "    # ***Need to use climatology to retrieve quantile data from this area\n",
    "    \n",
    "    # # Get rid of low outliers from over ice, cutoff for 98.5%\n",
    "    # outlier = np.quantile(data[np.isfinite(data)],0.015) #0.015\n",
    "    # mask2 = np.ones(data.shape)\n",
    "    # mask2[data<outlier] = np.nan\n",
    "    # data = np.around(mask2*data,decimals=5)\n",
    "\n",
    "    # Interpolate using PyGMT\n",
    "    if interp==1:  \n",
    "        grid = interpMOD(data,lat,lon)\n",
    "        \n",
    "        # Produce indicies for aligning MODIS pixel subset to match Landsat image at 4000m (or 300)resolution\n",
    "        indiciesMOD,lines,samples,lat,lon = MODISlookup(mod07,ls_scene,box,spacing,scene,interpgrid=grid)\n",
    "        data = grid.values\n",
    "        \n",
    "    else:\n",
    "        # Produce indicies for aligning MODIS pixel subset to match Landsat image at 4000m (or 300)resolution\n",
    "        indiciesMOD,lines,samples,lat,lon = MODISlookup(mod07,ls_scene,box,spacing,scene)\n",
    "\n",
    "    # Align and resample MODIS WV to Landsat at indicated spacing with correct axes\n",
    "    dataOutWV_xr = alignMODIS(data,lat,lon,param,indiciesMOD,lines,samples,mod07,ls_scene,spacing)\n",
    "    \n",
    "    # # Resample WV to Landsat resolution and interpolate with B-spline\n",
    "    # # Need to use 0.1k (this samples at .1 of the grid)\n",
    "    # # Output of shape fits and need to adjust x and y coords cuz are wrong\n",
    "    ups_factor = 30/spacing[0]\n",
    "    WV_upsample = pygmt.grdsample(grid=dataOutWV_xr, spacing=f'{ups_factor}k', interpolation='c')\n",
    "\n",
    "    # Put into Xarray\n",
    "    # Sometimes spacing works properly with -1 and sometimes not\n",
    "    latnew = np.arange(dataOutWV_xr.latitude[0],dataOutWV_xr.latitude[-1]+1,(dataOutWV_xr.latitude[-1]-dataOutWV_xr.latitude[0])/(WV_upsample.shape[0]-1))\n",
    "    if (WV_upsample.shape[0]!=latnew.shape[0]):\n",
    "        latnew = np.arange(dataOutWV_xr.latitude[0],dataOutWV_xr.latitude[-1]+1,(dataOutWV_xr.latitude[-1]-dataOutWV_xr.latitude[0])/(WV_upsample.shape[0]))\n",
    "\n",
    "    # Put into Xarray\n",
    "    latnew = ls_scene.y[:WV_upsample.shape[0]].values\n",
    "    lonnew = ls_scene.x[:WV_upsample.shape[1]].values\n",
    "    if dataOutWV_xr.latitude[0]!=latnew[0]:\n",
    "        print('Aligned y dim needs to start with the same coordinate as ls_scene')\n",
    "    if dataOutWV_xr.longitude[0]!=lonnew[0]:\n",
    "        print('Aligned x dim needs to start with the same coordinate as ls_scene')\n",
    "    \n",
    "    WV_xr = xr.DataArray(WV_upsample,name='SST',dims=[\"y\",\"x\"], coords={\"latitude\": ([\"y\"],latnew), \"longitude\": ([\"x\"],lonnew)})\n",
    "\n",
    "    WV_xr = WV_xr.rio.write_crs(\"epsg:3031\", inplace=True)\n",
    "    WV_xr = WV_xr.rename({'longitude':'x','latitude':'y'})\n",
    "    \n",
    "    return WV_xr\n",
    "\n",
    "##########################  \n",
    "\n",
    "def get_sst(ls_scene,mod07,spacing,param):\n",
    "    '''\n",
    "    ***This is copied in LandsatCalibration, modifications have been made but some may tranfer\n",
    "    \n",
    "    Create MODIS files aligned and subsampled to Landsat\n",
    "    \n",
    "    Variables:\n",
    "    ls_scene = xarray dataset of a Landsat scene\n",
    "    mod07 = xarray datarray with MODIS L2 SST data\n",
    "    spacing = list of desired spatial resolution of output data from the alignment of MODIS to Landsat in y and x (e.g.,[300,-300])\n",
    "    param = string for desired dataset from MODIS file\n",
    "    \n",
    "    Output:\n",
    "    WV_xr = xarray dataarray of Landsat aligned and upsampled modis data from desired dataset\n",
    "    \n",
    "    Differences from NLSST: scene is not a parameter (used for test_gridcoords), SST gets extracted differently into data/lat/lon\n",
    "    \n",
    "    '''\n",
    "    # Read in desired variables and paths\n",
    "    \n",
    "    uniqWV = []\n",
    "\n",
    "    ULX = ls_scene.x[0] \n",
    "    ULY = ls_scene.y[0]\n",
    "    LRX = ls_scene.x[-1]\n",
    "    LRY = ls_scene.y[-1] \n",
    "    box = [ULX,LRX,ULY,LRY]\n",
    "    \n",
    "    #Extract desired datasets from MODIS file\n",
    "    if param == 'sea_surface_temperature': \n",
    "        data = mod07[0,:,:]\n",
    "        lat, lon = mod07.lat, mod07.lon\n",
    "    else: \n",
    "        data = mod07[param].values\n",
    "        lat, lon = mod07.Latitude, mod07.Longitude    \n",
    "\n",
    "    # Produce indicies for aligning MODIS pixel subset to match Landsat image at 4000m (or 300)resolution\n",
    "    indiciesMOD,lines,samples = MODISslookup(mod07,ls_scene,box,spacing)\n",
    "\n",
    "    # Align MODIS SST to Landsat on slightly upsampled grid # have the option to output `uniqImgWV` if want to know range of data\n",
    "    dataOutWV_xr = alignMODIS(data,lat,lon,param,indiciesMOD,lines,samples,mod07,ls_scene,spacing)\n",
    "\n",
    "    # Resample MODIS to Landsat resolution and interpolate with B-spline\n",
    "    # Output of shape fits and need to adjust x and y coords cuz are wrong\n",
    "    ups_factor = 30/spacing[0]\n",
    "    WV_upsample = pygmt.grdsample(grid=dataOutWV_xr, spacing=f'{ups_factor}k') # ,interpolation='b' if prefer to interpolate with bspline but don't think it is useful here\n",
    "\n",
    "    # Put into Xarray\n",
    "    latnew = ls_scene.y[:WV_upsample.shape[0]].values\n",
    "    lonnew = ls_scene.x[:WV_upsample.shape[1]].values\n",
    "    if dataOutWV_xr.latitude[0]!=latnew[0]:\n",
    "        print('Aligned y dim needs to start with the same coordinate as ls_scene')\n",
    "    if dataOutWV_xr.longitude[0]!=lonnew[0]:\n",
    "        print('Aligned x dim needs to start with the same coordinate as ls_scene')\n",
    "    \n",
    "    WV_xr = xr.DataArray(WV_upsample,name='SST',dims=[\"y\",\"x\"], coords={\"latitude\": ([\"y\"],latnew), \"longitude\": ([\"x\"],lonnew)})\n",
    "    WV_xr = WV_xr.rio.write_crs(\"epsg:3031\", inplace=True)\n",
    "    WV_xr = WV_xr.rename({'longitude':'x','latitude':'y'})\n",
    "    WV_xr = WV_xr.set_index(x='x')\n",
    "    WV_xr = WV_xr.set_index(y='y')\n",
    "    \n",
    "    return WV_xr\n",
    "           \n",
    "\n",
    "##########################\n",
    "            \n",
    "def interpMOD(data,lat,lon):\n",
    "    \"\"\"\n",
    "    Interpolate spatial water vapor data using PyGMT.\n",
    "\n",
    "    This function takes arrays of water vapor data along with corresponding latitude and longitude values,\n",
    "    performs interpolation to fill in gaps in the data, and produces a continuous surface representation of water vapor.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): 2D array of water vapor measurements.\n",
    "        lat (numpy.ndarray): 2D array of latitude values corresponding to `data`.\n",
    "        lon (numpy.ndarray): 2D array of longitude values corresponding to `data`.\n",
    "\n",
    "    Returns:\n",
    "        grid (xarray.DataArray): A PyGMT grid object representing the interpolated surface of water vapor data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Interpolate using PyGMT\n",
    "    # Extract necessary data into Pandas DataFrame (required for PyGMT)\n",
    "    df = pd.DataFrame({\n",
    "        'longitude': lon.values.flatten(), # Flatten to convert from 2D to 1D array\n",
    "        'latitude': lat.values.flatten(),\n",
    "        'water_vapor': data.flatten() # Actual data values to be interpolated\n",
    "    })\n",
    "\n",
    "    # Remove missing or NaN values from DataFrame, as `surface` cannot handle them\n",
    "    df = df.dropna(subset=['water_vapor'])\n",
    "\n",
    "    # Determine the geographical extent for the interpolation based on the provided data points.\n",
    "    # This is necessary to define the spatial domain over which PyGMT will perform interpolation.\n",
    "    # [xmin, xmax, ymin, ymax] - made this the full image\n",
    "    region = [df.longitude.min(), df.longitude.max(), df.latitude.min(), df.latitude.max()]\n",
    "    # Alternatively, if the region is predefined (e.g., from metadata), it can be set directly.\n",
    "\n",
    "    # Use PyGMT to interpolate the data. PyGMT requires a session context to manage memory and configuration\n",
    "    # settings efficiently during its operations.\n",
    "    with pygmt.clib.Session() as session:\n",
    "        # Perform grid-based surface interpolation.\n",
    "        # The `data` parameter takes longitude, latitude, and water vapor as a NumPy array.\n",
    "        # `region` specifies the geographical extent.\n",
    "        # `spacing` sets the resolution of the output grid, here 0.3 km for high resolution.\n",
    "        # `tension` controls the stiffness of the interpolating surface. A value of 0.25 gives a balance between\n",
    "        # fitting the data closely and producing a smooth surface.\n",
    "        grid = pygmt.surface(\n",
    "            data=df[['longitude', 'latitude', 'water_vapor']].to_numpy(),  # Input data as NumPy array\n",
    "            region=region,  \n",
    "            spacing=['0.15k','0.05k'],  # f'0.3k'\n",
    "            tension=0.95,  \n",
    "        )   \n",
    "    \n",
    "    return grid\n",
    "\n",
    "##########################\n",
    "\n",
    "def MODISlookup(mod07,ls_scene,box,spacing,scene,interpgrid=None):\n",
    "    '''\n",
    "    Look up indices for aligning MODIS product to the Landsat grid\n",
    "    # Modified from http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file \n",
    "    # and Shane Grigsby\n",
    "\n",
    "    Variables:    \n",
    "    mod07 = xarray with MODIS data with crs 4326 assigned\n",
    "    ls_scene =  Landsat xarray DataArray\n",
    "    box = list with [left easting,right easting,top northing,bottom northing]\n",
    "    spacing = desired pixel size for extraction, list of [east/west, north/south] \n",
    "          (recommend choosing a number that allows for fast calculations and even division by 30)\n",
    "    scene = \n",
    "    interpgrid = xarray of mod07 data that has been through interpolation in PyGMT (optional)\n",
    "\n",
    "    Output:\n",
    "    indiciesMOD = indicies used to project MODIS pixels to match Landsat pixels\n",
    "    lines = number of lines in Landsat file/MODIS output shape\n",
    "    samples = number of samples in Landsat file/MODIS output shape\n",
    "    lon,lat = 2D lon and lat coordinates for grid\n",
    "    '''\n",
    "    test_threshold = 5\n",
    "    \n",
    "    if interpgrid is None:\n",
    "        lat, lon = mod07.Latitude.values, mod07.Longitude.values\n",
    "    else:\n",
    "        lat, lon = interpgrid.lat, interpgrid.lon\n",
    "        lon, lat = np.meshgrid(lon,lat)\n",
    "\n",
    "    # Test lat is in correct range\n",
    "    if ~((lat <= 90) & (lat >= -90)).all():\n",
    "        print('MODIS latitude not between -90 and 90')\n",
    "    # Test lon is in correct range\n",
    "    if ~((lon <= 180) & (lon >= -180)).all():\n",
    "        print('MODIS longitude not between -180 and 180')\n",
    "\n",
    "    # Get the existing coordinate system\n",
    "    old_cs = ls_scene.rio.crs # 'epsg:3031'\n",
    "    new_cs = mod07.rio.crs # 'epsg:4326'\n",
    "\n",
    "    # Create a transform object to convert between coordinate systems\n",
    "    inProj = Proj(init=old_cs)\n",
    "    outProj = Proj(init=new_cs)\n",
    "\n",
    "    # Parse coordinates and spacing to different variables\n",
    "    west,east,north,south = box\n",
    "    ewspace,nsspace = spacing\n",
    "\n",
    "    # Setting up grid, x coord from here to here at this spacing, mesh grid makes 2D\n",
    "    samples = len(np.r_[west:east+1:ewspace])\n",
    "    lines = len(np.r_[north:south-1:nsspace])#ns space is -300, could also do 30 instead of 300, but would just have duplicate pixels\n",
    "    if lines==0:\n",
    "        lines = len(np.r_[south:north-1:nsspace])\n",
    "\n",
    "    # x1, y1 = np.meshgrid(np.r_[west:east:ewspace],np.r_[north:south:nsspace]) # offset by 1 meter to preserve shape\n",
    "    ewdnsamp = int(spacing[0]/30)\n",
    "    nsdnsamp = int(spacing[1]/30)\n",
    "    \n",
    "    # Set up coarser sampling and check to make sure is in the same orientation as the original Landsat grid\n",
    "    xresamp = ls_scene.x.isel(x=slice(None, None, ewdnsamp)).values\n",
    "    if xresamp[0]!=ls_scene.x.values[0]:\n",
    "        xresamp = ls_scene.x.isel(x=slice(None, None, -ewdnsamp)).values\n",
    "        # print('x resample reversed')\n",
    "    yresamp = ls_scene.y.isel(y=slice(None, None, nsdnsamp)).values\n",
    "    if yresamp[0]!=ls_scene.y.values[0]:\n",
    "        yresamp = ls_scene.y.isel(y=slice(None, None, -nsdnsamp)).values\n",
    "        # print('y resample reversed')\n",
    "    x1, y1 = np.meshgrid(xresamp,yresamp)\n",
    "    LScoords = np.vstack([x1.ravel(),y1.ravel()]).T\n",
    "    if (LScoords[0,0]!=ls_scene.x.values[0]) |  (LScoords[0,1]!=ls_scene.y.values[0]):\n",
    "        raise Exception('Landsat coordinates do not match expected during MODIS lookup')\n",
    "\n",
    "    # Ravel so ND can lookup easily\n",
    "    # Convert from LS map coords to lat lon --> x = lon, y = lat (usually?)\n",
    "\n",
    "    ###Make into test\n",
    "    # Test that reprojection is working correctly on first and last grid point using round-trip transformation\n",
    "    xs1, ys1 =  transform(inProj,outProj,LScoords[0,0], LScoords[0,1], radians=True, always_xy=True)\n",
    "    xsl1, ysl1 =  transform(outProj,inProj,xs1, ys1, radians=True, always_xy=True)\n",
    "    if np.linalg.norm(np.array([xsl1, ysl1]) - LScoords[0,:]) > test_threshold:\n",
    "        print(f\"Round-trip transformation error for point {LScoords[0,:]}, {np.linalg.norm(np.array([xsl1, ysl1]) - LScoords[0,:])}\")\n",
    "    else:\n",
    "        # If passes, run on entire grid\n",
    "        xs, ys =  transform(inProj,outProj,LScoords[:,0], LScoords[:,1], radians=True, always_xy=True)\n",
    "    ###\n",
    "    \n",
    "    # Produce landsat reprojected to lat/lon and ensure lat is in 0 column\n",
    "    # Test: landsat data is in correct orientation as long as lat is in col 0 and lon in col 1\n",
    "    grid_coords = test_gridcoords(xs,ys,scene)\n",
    "\n",
    "    # Test that lines and samples match grid_coords\n",
    "    if len(grid_coords) != lines*samples:\n",
    "        raise Exception(f'Size of grid coordinates do not match low resolution Landsat dims: {len(grid_coords)} vs. {lines*samples}. Check that spacing is negative for y')\n",
    "    MODIS_coords = np.vstack([lat.ravel(),lon.ravel()]).T\n",
    "    MODIS_coords *= np.pi / 180. # to radians\n",
    "\n",
    "    # Build lookup, haversine = calc dist between lat,lon pairs so can do nearest neighbor on sphere - if did utm it would be planar\n",
    "    MOD_Ball = BallTree(MODIS_coords,metric='haversine') #sklearn library\n",
    "    distanceMOD, indiciesMOD= MOD_Ball.query(grid_coords, dualtree=True, breadth_first=True)\n",
    "        \n",
    "    return indiciesMOD,lines,samples,lat,lon\n",
    "\n",
    "##########################           \n",
    "\n",
    "def MODISsstlookup (mod07,ls_scene,box,spacing):\n",
    "    '''\n",
    "    Look up atmospheric consituents from MODIS product for each Landsat pixel\n",
    "    # Modified from http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file \n",
    "    # and Shane Grigsby\n",
    "\n",
    "    Variables:    \n",
    "    mod07 = xarray with MODIS data with crs 4326 assigned\n",
    "    ls_scene =  Landsat xarray DataArray\n",
    "    box = list with [left easting,right easting,top northing,bottom northing]\n",
    "    spacing = desired pixel size for extraction, list of [east/west, north/south] \n",
    "          (recommend choosing a number that allows for fast calculations and even division by 30)\n",
    "\n",
    "    Output:\n",
    "    indiciesMOD = indicies used to project MODIS pixels to match Landsat pixels\n",
    "    lines = number of lines in Landsat file/MODIS output shape\n",
    "    samples = number of samples in Landsat file/MODIS output shape\n",
    "    x1,y1 = x and y coordinates for grid\n",
    "    \n",
    "    Differences from NLSST: lat/lon variables named differently in SST vs WV files, no interpolation,\n",
    "    test_gridcoords does not use `scene`, don't need to output lat/lon because do not interpolate and make \n",
    "    new ones\n",
    "    \n",
    "    '''\n",
    "    test_threshold = 5 \n",
    "    \n",
    "    lat, lon = mod07.lat, mod07.lon # Different for SST vs WV\n",
    "    \n",
    "    # Test lat is in correct range\n",
    "    if ~((lat <= 90) & (lat >= -90)).all():\n",
    "        print('MODIS latitude not between -90 and 90')\n",
    "    # Test lon is in correct range\n",
    "    if ~((lon <= 180) & (lon >= -180)).all():\n",
    "        print('MODIS longitude not between -180 and 180')\n",
    "\n",
    "    # Get the existing coordinate system\n",
    "    old_cs = ls_scene.rio.crs # 'epsg:3031'\n",
    "    new_cs = mod07.rio.crs # 'epsg:4326'\n",
    "\n",
    "    # Create a transform object to convert between coordinate systems\n",
    "    inProj = Proj(init=old_cs)\n",
    "    outProj = Proj(init=new_cs)\n",
    "\n",
    "    # Parse coordinates and spacing to different variables\n",
    "    west,east,north,south = box\n",
    "    ewspace,nsspace = spacing\n",
    "\n",
    "    # Setting up grid, x coord from here to here at this spacing, mesh grid makes 2D\n",
    "    samples = len(np.r_[west:east+1:ewspace])\n",
    "    lines = len(np.r_[north:south-1:nsspace])#ns space is -300, could also do 30 instead of 300, but would just have duplicate pixels\n",
    "    if lines==0:\n",
    "        lines = len(np.r_[south:north-1:nsspace])\n",
    "        \n",
    "    # x1, y1 = np.meshgrid(np.r_[west:east:ewspace],np.r_[north:south:nsspace]) # offset by 1 meter to preserve shape\n",
    "    ewdnsamp = int(spacing[0]/30)\n",
    "    nsdnsamp = int(spacing[1]/30)\n",
    "\n",
    "    # Set up coarser sampling and check to make sure is in the same orientation as the original Landsat grid\n",
    "    xresamp = ls_scene.x.isel(x=slice(None, None, ewdnsamp)).values\n",
    "    if xresamp[0]!=ls_scene.x.values[0]:\n",
    "        xresamp = ls_scene.x.isel(x=slice(None, None, -ewdnsamp)).values\n",
    "        \n",
    "    yresamp = ls_scene.y.isel(y=slice(None, None, nsdnsamp)).values\n",
    "    if yresamp[0]!=ls_scene.y.values[0]:\n",
    "        yresamp = ls_scene.y.isel(y=slice(None, None, -nsdnsamp)).values\n",
    "\n",
    "    x1, y1 = np.meshgrid(xresamp,yresamp)\n",
    "    LScoords = np.vstack([x1.ravel(),y1.ravel()]).T\n",
    "    if (LScoords[0,0]!=ls_scene.x.values[0]) |  (LScoords[0,1]!=ls_scene.y.values[0]):\n",
    "        raise Exception('Landsat coordinates do not match expected during MODIS lookup')\n",
    "\n",
    "    # Ravel so ND can lookup easily\n",
    "    # Convert from LS map coords to lat lon --> x = lon, y = lat (usually?)\n",
    "    # Test that reprojection is working correctly on first and last grid point using round-trip transformation\n",
    "    xs1, ys1 =  transform(inProj,outProj,LScoords[0,0], LScoords[0,1], radians=True, always_xy=True)\n",
    "    xsl1, ysl1 =  transform(outProj,inProj,xs1, ys1, radians=True, always_xy=True)\n",
    "    if np.linalg.norm(np.array([xsl1, ysl1]) - LScoords[0,:]) > test_threshold:\n",
    "        print(f\"Round-trip transformation error for point {LScoords[0,:]}, {np.linalg.norm(np.array([xsl1, ysl1]) - LScoords[0,:])}\")\n",
    "    else:\n",
    "        # If passes, run on entire grid\n",
    "        xs, ys =  transform(inProj,outProj,LScoords[:,0], LScoords[:,1], radians=True, always_xy=True)\n",
    "\n",
    "    # Produce landsat reprojected to lat/lon and ensure lat is in 0 column\n",
    "    grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T\n",
    "    # Test that lines and samples match grid_coords\n",
    "    if len(grid_coords) != lines*samples:\n",
    "        raise Exception(f'Size of grid coordinates do not match low resolution Landsat dims: {len(grid_coords)} vs. {lines*samples}. Check that spacing is negative for y')\n",
    "    MODIS_coords = np.vstack([lat.values.ravel(),lon.values.ravel()]).T\n",
    "    MODIS_coords *= np.pi / 180. # to radians\n",
    "    \n",
    "    # Build lookup, haversine = calc dist between lat,lon pairs so can do nearest neighbor on sphere - if did utm it would be planar\n",
    "    MOD_Ball = BallTree(MODIS_coords,metric='haversine') #sklearn library\n",
    "    distanceMOD, indiciesMOD= MOD_Ball.query(grid_coords, dualtree=True, breadth_first=True)\n",
    "        \n",
    "    return indiciesMOD,lines,samples\n",
    "\n",
    "##########################\n",
    "\n",
    "def test_gridcoords(xs,ys,scene):\n",
    "    '''\n",
    "    Test to ensure grid lat and lon are not swapped during reprojection and output grid coordinates\n",
    "    that have been raveled and stacked for input into BallTree\n",
    "    \n",
    "    Variables:\n",
    "    xs = 1D radians representing longitude \n",
    "    ys = 1D radians representing latitude\n",
    "    scene = catalog item for landsat image\n",
    "    \n",
    "    Output:\n",
    "    grid_coords = two columns of x/y radian pairs representing lon/lat\n",
    "    '''\n",
    "    \n",
    "    # Convert radians to lat/lon\n",
    "    x_check = xs * 180. / np.pi\n",
    "    y_check = ys * 180. / np.pi\n",
    "    \n",
    "    # We know lat is ys and lon is xs if this is true so goes in 0 column position to match MODIS\n",
    "    if ((-90 <= y_check) & (y_check <= -60)).all() & ~((-90 <= x_check) & (x_check <= -60)).all():\n",
    "        grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T # note y / x switch (i.e., lat long convention)\n",
    "        # print('Latitude in proper position')\n",
    "\n",
    "    # A small subset of data have lat and lon that falls between -60 and -90 so test if the landsat metadata confirms that\n",
    "    elif ((-90 <= y_check) & (y_check <= -60)).all():\n",
    "        llons = np.array((float(scene.metadata['bbox'][0]), float(scene.metadata['bbox'][2])))\n",
    "        # ys is latitude if true here\n",
    "        if ((-90 <= llons) & (llons <= -60)).all():\n",
    "            grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T # note y / x switch (i.e., lat long convention)\n",
    "            # print('Latitude in proper position')\n",
    "        # xs is latitude if not and goes in 0 column position\n",
    "        else:\n",
    "            grid_coords = np.vstack([xs.ravel(),ys.ravel()]).T \n",
    "            print('Latitude in wrong position')\n",
    "\n",
    "    # Otherwise xs is latitude and goes in 0 column position\n",
    "    else:\n",
    "        grid_coords = np.vstack([xs.ravel(),ys.ravel()]).T\n",
    "        print('Latitude in wrong position')\n",
    "    \n",
    "    return grid_coords\n",
    "\n",
    "##########################\n",
    "\n",
    "def test_gridcoords_calib(xs,ys):\n",
    "    '''\n",
    "    Test to ensure grid lat and lon are not swapped during reprojection and output grid coordinates\n",
    "    that have been raveled and stacked for input into BallTree. There is some uncertainty only when the image is\n",
    "    taken between -60 and -90 longitude because lat and lon can have the same values.\n",
    "    \n",
    "    Variables:\n",
    "    xs = 1D radians representing longitude \n",
    "    ys = 1D radians representing latitude\n",
    "    \n",
    "    Output:\n",
    "    grid_coords = two columns of x/y radian pairs representing lon/lat\n",
    "    \n",
    "    Differences from NLSST: elif is different than NLSST pipeline\n",
    "    '''\n",
    "    \n",
    "    # Convert radians to lat/lon\n",
    "    x_check = xs * 180. / np.pi\n",
    "    y_check = ys * 180. / np.pi\n",
    "    \n",
    "    # We know lat is ys and lon is xs if this is true so goes in 0 column position to match MODIS\n",
    "    if ((-90 <= y_check) & (y_check <= -60)).all() & ~((-90 <= x_check) & (x_check <= -60)).all():\n",
    "        grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T # note y / x switch (i.e., lat long convention)\n",
    "        print('Latitude in proper position')\n",
    "\n",
    "    # A small subset of data have lat and lon that falls between -60 and -90 so test if the landsat metadata confirms that\n",
    "    elif ((-90 <= y_check) & (y_check <= -60)).all():\n",
    "        # xs is latitude if not and goes in 0 column position\n",
    "        grid_coords = np.vstack([ys.ravel(),xs.ravel()]).T \n",
    "        print('Latitude in uncertain position, may be incorrect')\n",
    "\n",
    "    # Otherwise xs is latitude and goes in 0 column position\n",
    "    else:\n",
    "        grid_coords = np.vstack([xs.ravel(),ys.ravel()]).T\n",
    "        print('Latitude in wrong position')\n",
    "    \n",
    "    return grid_coords\n",
    "\n",
    "##########################\n",
    "\n",
    "def alignMODIS(data,lat,lon,param,indiciesMOD,lines,samples,mod07,ls_scene,spacing):\n",
    "    '''\n",
    "    Align MODIS image to Landsat and resample at indicated spacing\n",
    "    \n",
    "    Variables:\n",
    "    data =\n",
    "    lat = \n",
    "    lon = \n",
    "    param =\n",
    "    indiciesMOD =\n",
    "    lines = \n",
    "    samples =\n",
    "    mod07 = \n",
    "    ls_scene =\n",
    "    spacing =\n",
    "    \n",
    "    Output:\n",
    "    dataOut_xr = \n",
    "    \n",
    "    Not currently set, but can also output: \n",
    "    uniqImg = uniq MODIS atm values within area of Landsat image\n",
    "    '''\n",
    "    test_threshold = 5\n",
    "    \n",
    "    # Check to ensure lat/lon and data have compatible shapes\n",
    "    if (np.shape(lat)== np.shape(lon)== np.shape(data))==False:\n",
    "        raise Exception(\"Error in creating indicies, lat/lon and data shapes do not match\")\n",
    "        \n",
    "    # Extract MODIS data into Landsat grid and gather unique data values\n",
    "    dataOut,uniqWV = uniqueMODIS(data,param,indiciesMOD,lines,samples)\n",
    "    \n",
    "    # Check grid directionality and create matching x/y for new grid\n",
    "    # Define the source and target coordinate reference systems (CRS)\n",
    "    src_crs = mod07.rio.crs #'epsg:4326'  MODIS\n",
    "    target_crs = ls_scene.rio.crs #crs[6:] # 'epsg:3031' Landsat\n",
    "\n",
    "    # Create a PyProj transformer\n",
    "    transformer = pyproj.Transformer.from_crs(src_crs, target_crs, always_xy=True)\n",
    "    transformer_test = pyproj.Transformer.from_crs(target_crs, src_crs, always_xy=True)\n",
    "\n",
    "    # Test that reprojection is working correctly on first and last modis grid point\n",
    "    xm1,xm2 = lon[0,0],lon[-1,-1]\n",
    "    ym1,ym2 = lat[0,0],lat[-1,-1]\n",
    "    xx,yy = [xm1,xm2], [ym1,ym2]\n",
    "    xs1, ys1 =  transformer.transform(xx,yy)\n",
    "    xsl1, ysl1 = transformer_test.transform(xs1, ys1)\n",
    "    for i,n in enumerate(xsl1):\n",
    "        if np.linalg.norm(np.array([xsl1[i], ysl1[i]]) - [xx[i],yy[i]]) > test_threshold:\n",
    "            print(f\"Round-trip transformation error for {sceneid}, {np.linalg.norm(np.array([xsl1[i], ysl1[i]]) - xx[i],yy[i])}\")\n",
    "    \n",
    "    # Spacing to create x and y parameters at the correct spacing\n",
    "    redy = int(abs(spacing[0]/30))\n",
    "    redx = int(abs(spacing[1]/30))\n",
    "\n",
    "    # From SST# Set up coarser sampling and check to make sure is in the same orientation as the original Landsat grid\n",
    "    # xgrid = ls_scene.x.isel(x=slice(None, None, redx)).values\n",
    "    # if xgrid[0]!=ls_scene.x.values[0]:\n",
    "    #     xgrid = ls_scene.x.isel(x=slice(None, None, -redx)).values\n",
    "    # ygrid = ls_scene.y.isel(y=slice(None, None, redy)).values\n",
    "    # if ygrid[0]!=ls_scene.y.values[0]:\n",
    "    #     ygrid = ls_scene.y.isel(y=slice(None, None, -redy)).values\n",
    "    # if (xgrid[0]!=ls_scene.x.values[0]) |  (ygrid[0]!=ls_scene.y.values[0]):\n",
    "    #     raise Exception('Landsat coordinates do not match expected during MODIS lookup')\n",
    "\n",
    "    #From LandsatCalib\n",
    "    # Set up coarser sampling grid to match spacing and check to make sure is in the same orientation as the original Landsat grid\n",
    "    xgrid = ls_scene.x.values[0::red_x]\n",
    "    if len(xgrid)==1:\n",
    "        xgrid = ls_scene.x.values[0::-red_x]\n",
    "    if xgrid[0]!=ls_scene.x.values[0]:\n",
    "        xgrid = np.flip(xgrid)\n",
    "        print ('Align x flip')\n",
    "    ygrid = ls_scene.y.values[0::red_y]\n",
    "    if len(ygrid)==1:\n",
    "        ygrid = ls_scene.y.values[0::-red_y]\n",
    "    if ygrid[0]!=ls_scene.y.values[0]:\n",
    "        ygrid = np.flip(ygrid)\n",
    "        print ('Align y flip')\n",
    "    if (xgrid[0]!=ls_scene.x.values[0]) |  (ygrid[0]!=ls_scene.y.values[0]):\n",
    "        raise Exception(f'Landsat coordinates do not match expected during MODIS align')\n",
    "    \n",
    "    # Create xarray from numpy array\n",
    "    dataOut_xr = xr.DataArray(dataOut,name='SST',dims=[\"y\",\"x\"], coords={\"latitude\": ([\"y\"],ygrid), \"longitude\": ([\"x\"],xgrid)})\n",
    "    \n",
    "    return dataOut_xr\n",
    "\n",
    "##########################\n",
    "\n",
    "def uniqueMODIS(data,param,indiciesMOD,lines,samples):\n",
    "    '''\n",
    "    Extracts data values and unique values from desired MODIS dataset that corresponds to Landsat file\n",
    "    No scaling needed - xarray automatically scales for you\n",
    "    # Modified from http://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "    \n",
    "    Variables: \n",
    "    data = array with MOD07 data in crs 4326 assigned \n",
    "    param =  string for desired dataset from MODIS file\n",
    "    indiciesMOD = indicies output for neighest neighbor query from MODIS to Landsat coordinates\n",
    "    lines = number of lines in Landsat file/MODIS output shape\n",
    "    samples = number of samples in Landsat file/MODIS output shape\n",
    "    \n",
    "    Output:\n",
    "    dataOut = MODIS atm image subset and aligned to Landsat image pixels\n",
    "    uniq = uniq MODIS atm values within area of Landsat image\n",
    "    #counts = count for each unique value in subset\n",
    "    '''\n",
    "    # Convert from K to C\n",
    "    KtoC = -273.15\n",
    "    \n",
    "    # Reproject data from MODIS into corresponding postions for Landsat pixels for the desired dataset\n",
    "    # Remove unrealistic data/outliers\n",
    "    # Scaling has already been automatically done by xarray\n",
    "    if param == 'sea_surface_temperature':  \n",
    "        #Extract desired datasets from MODIS file from lookup key\n",
    "        # Move to adjusted grid and rescale data\n",
    "        dataOut = np.reshape(np.array(data.values.ravel())[indiciesMOD],(lines,samples)) + KtoC #* # to scale?\n",
    "        dataOut[dataOut < -3.5] = np.nan\n",
    "    elif param == 'Water_Vapor':\n",
    "        dataOut = np.reshape(np.array(data.ravel())[indiciesMOD],(lines,samples))\n",
    "        dataOut[dataOut < 0] = np.nan\n",
    "        MODimg = np.array(data)\n",
    "        MODimg[MODimg < 0] = np.nan\n",
    "    elif param == 'Total_Ozone':\n",
    "        dataOut = np.reshape(np.array(data.ravel())[indiciesMOD],(lines,samples))\n",
    "        dataOut[dataOut < 225] = np.nan\n",
    "        dataOut[dataOut > 430] = np.nan\n",
    "        MODimg = np.array(data)\n",
    "        MODimg[MODimg < 0] = np.nan\n",
    "\n",
    "    # Get unique values for datasets within Landsat extent\n",
    "    #uniq, inverse, counts= np.unique(dataOut, return_inverse=True, return_counts=True)\n",
    "    uniq = set(dataOut[np.isfinite(dataOut)])\n",
    "    \n",
    "    return dataOut,uniq # Can also output MODimg and inverse and counts if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea76c3f2-9f19-4af2-848d-f6c1685252f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for deriving SST retrieval coefficients\n",
    "'''\n",
    "These functions help to derive the SST monthly correction coefficients\n",
    "prep_retrieval prepares the inputs for running the multiple regression that determines the coefficients, including\n",
    "converting ERA-5 specific humidity data to total column water vapor in spec_hu_to_tcwv. Derive retrieval then takes\n",
    "the inputs and runs an OLS multiple regression to derive the coefficients.\n",
    "\n",
    "Functions to search, open, and analyze Landsat scenes.\n",
    "Search_stac finds the Landsat scene based on user parameters, \n",
    "plot_search plots the locations of the landsat scenes from the search,\n",
    "landsat_to_xarray takes one of those scenes and puts all bands into an xarray,\n",
    "and create_masks produces cloud/ice/water masks for the scene. Subset_img \n",
    "subsets a landsat scene with coordinates that have been reprojected from lat/lon\n",
    "and may be flipped in which is larger in the pair. Lsat_reproj can be used to reproject\n",
    "while ensuring x and y pairs don't get flipped (common converting between espg 3031 and wgs84.\n",
    "'''\n",
    "def prep_retrieval(atmpath,prefix,spec_hu_file):\n",
    "    '''\n",
    "    Create the inputs for the SST algorithm using the atmospheric column inputs and outputs from \n",
    "    the MODTRAN model runs for Landsat. Uses specific humidity to calculate total column water vapor \n",
    "    for the retrieval multiple regression.\n",
    "\n",
    "    Units for ERA5 specific humidity listed here under main variables: https://cds.climate.copernicus.eu/datasets/reanalysis-era5-pressure-levels?tab=overview\n",
    "    \n",
    "    Variable:\n",
    "    atmpath = directory path where MODTRAN outputs are stored (str)\n",
    "    prefix = beginning of file path name for MODTRAN outputs - files created by Andy Harris (str) \n",
    "    spec_hu_file = file path for era5 input file for MODTRAN that includes specific humidity (str)\n",
    "    \n",
    "    Intermediates:\n",
    "    modtran_lut = pandas dataframe of MODTRAN outputs\n",
    "    modtran_atm = pandas dataframe of era5 atmopheric columns for input into MODTRAN\n",
    "    \n",
    "    Outputs:\n",
    "    modtran_lut = pandas dataframe of MODTRAN outputs with total column water vapor [cm] added as \n",
    "                  a column\n",
    "    '''\n",
    "    \n",
    "    # Open and concatenate MODTRAN outputs for SST algorithm\n",
    "    # Get file paths\n",
    "    modtr_list = os.listdir(atmpath)\n",
    "    modtr_list = [file for file in modtr_list if file.startswith(prefix)]\n",
    "    modtr_list.sort()\n",
    "\n",
    "    # Open into pandas and concatenate\n",
    "    df_list = []\n",
    "    lut_cols = ['wind spd [m/s]','Surface T[K]','TOA T[K]','transmittance','jakobian']\n",
    "    \n",
    "    if len(modtr_list)>1:\n",
    "        for mfile in modtr_list:\n",
    "            df_list.append(pd.read_csv(f'{atmpath}/{mfile}', sep=' ',header=None,names=lut_cols))\n",
    "\n",
    "        modtran_lut = pd.concat(df_list, ignore_index=True)\n",
    "    else:\n",
    "        mfile = modtr_list[0]\n",
    "        modtran_lut = pd.read_csv(f'{atmpath}/{mfile}', sep=' ',header=None,names=lut_cols)\n",
    "    \n",
    "    modtran_lut['TCWV [cm]'] = np.nan\n",
    "    \n",
    "    # Open atm profiles for input of water vapor specific humidity\n",
    "    atm_cols = ['Altitude [km]', 'pressure [hPa]', 'temp [K]', 'spec humidity [kg/kg]']\n",
    "    modtran_atm = pd.read_csv(f'{atmpath}/{spec_hu_file}', sep='\\t',header=None,names=atm_cols)\n",
    "    \n",
    "    # Run integral to get tcwv\n",
    "    modtran_lut = spec_hu_to_tcwv(modtran_lut,modtran_atm)\n",
    "\n",
    "    tcwvmin = modtran_lut['TCWV [cm]'].min()\n",
    "    tcwvmax = modtran_lut['TCWV [cm]'].max()\n",
    "    print (f'TCWV min: {tcwvmin}, max: {tcwvmax}')\n",
    "    \n",
    "    return modtran_lut\n",
    "\n",
    "##########################\n",
    "\n",
    "def concat_modtran_months(months,atmpath):\n",
    "    # Create a list to store the DataFrame for each month in the window.\n",
    "    modtran_list = []\n",
    "\n",
    "    n = 0\n",
    "    \n",
    "    for mo in months:\n",
    "        TCWV_input_file = atmpath / f\"TCWV_{mo}.csv\"\n",
    "        if os.path.isfile(TCWV_input_file):\n",
    "            # print(f\"  Month {mo}: retrieval input exists\")\n",
    "            modtran = pd.read_csv(TCWV_input_file)\n",
    "        else:\n",
    "            spec_hu_file = f\"modtran_atmprofiles_{mo}.txt\"\n",
    "            modtran_output_file = f\"modtran_atmprofiles_{mo}.bts+tau+dbtdsst.txt\"\n",
    "            modtran = prep_retrieval(atmpath, modtran_output_file, spec_hu_file)\n",
    "            modtran.to_csv(TCWV_input_file, index=False)\n",
    "        \n",
    "        # Remove rows with Surface T values of 271.46 and 271.461.\n",
    "        modtran = modtran[~modtran['Surface T[K]'].isin([271.46, 271.461])]\n",
    "        print(f'{mo}: {modtran.shape[0]}')\n",
    "        \n",
    "        modtran_list.append(modtran)\n",
    "\n",
    "        n = n + modtran.shape[0]\n",
    "    \n",
    "    # Concatenate the DataFrames for the three months in the window.\n",
    "    modtran_lut = pd.concat(modtran_list, ignore_index=True)\n",
    "\n",
    "    return modtran_lut,n\n",
    "\n",
    "##########################\n",
    "\n",
    "def derive_coeffs(atmpath,simTOA_transformer,simWV_transformer,simT_transformer):\n",
    "    # Derive retrieval coefficiencts from MODTRAN files - 3 month rolling window\n",
    "    months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    atmcor = {}  # To store the regression results for each middle month.\n",
    "    \n",
    "    # Loop over months by index so we can get the previous and next month via modulo arithmetic.\n",
    "    for i, middle_month in enumerate(months):\n",
    "        # Determine the rolling window months: previous, current, and next (with wrap-around)\n",
    "        prev_month = months[(i - 1) % 12]\n",
    "        next_month = months[(i + 1) % 12]\n",
    "        window_months = [prev_month, middle_month, next_month]\n",
    "        \n",
    "        print(f\"Processing rolling window for middle month {middle_month}\")\n",
    "        \n",
    "        modtran_lut,_ = concat_modtran_months(window_months,atmpath)\n",
    "    \n",
    "        modtran_lut_norm = modtran_lut\n",
    "    \n",
    "        modtran_lut_norm['Surface T[K]'] = simT_transformer.transform(modtran_lut[['Surface T[K]']])\n",
    "        modtran_lut_norm['TOA T[K]'] = simTOA_transformer.transform(modtran_lut[['TOA T[K]']])\n",
    "        modtran_lut_norm['TCWV [cm]'] = simWV_transformer.transform(modtran_lut[['TCWV [cm]']])\n",
    "        \n",
    "        # Run the regression using your derive_retrieval function on the concatenated DataFrame.\n",
    "        retrieval_results = derive_retrieval(modtran_lut_norm)\n",
    "        a1 = np.around(retrieval_results.params.toa, 2)\n",
    "        a2 = np.around(retrieval_results.params.tcwv_toa, 2)\n",
    "        a3 = np.around(retrieval_results.params.Intercept, 2)\n",
    "        r2 = np.around(retrieval_results.rsquared, 2)\n",
    "        \n",
    "        pa1 = np.around(retrieval_results.pvalues[1], 3)\n",
    "        pa2 = np.around(retrieval_results.pvalues[2], 3)\n",
    "        pa3 = np.around(retrieval_results.pvalues[0], 3)\n",
    "        \n",
    "        # Store the regression coefficients and R2 for the middle month.\n",
    "        atmcor[middle_month] = {\"a1\": a1, \"a2\": a2, \"a3\": a3}\n",
    "        print(f\"Rolling for month {middle_month}: toa = {a1}, tcwv_toa = {a2}, Intercept = {a3}, R2 = {r2}\")\n",
    "        print(f\"p-values for month {middle_month}: toa = {pa1}, tcwv_toa = {pa2}, Intercept = {pa3}\")\n",
    "    \n",
    "    print(retrieval_results.summary())\n",
    "    \n",
    "    return atmcor,retrieval_results,modtran_lut_norm\n",
    "\n",
    "##########################\n",
    "\n",
    "def derive_retrieval(modtran_lut):\n",
    "    '''\n",
    "    Derive the retrieval coefficients from the atmospheric column inputs and outputs to the MODTRAN\n",
    "    model runs for Landsat using multiple regression. \n",
    "    \n",
    "    Variables:\n",
    "    modtran_lut = pandas dataframe that includes columns for surface temperature [K], top of \n",
    "                  atmosphere brightness temperature [K], total column water vapor [cm]\n",
    "    \n",
    "    Outputs:\n",
    "    results = multiple regression summary and derived coefficients (ak) for retrieval atmospheric correction\n",
    "    '''\n",
    "    # Run OLS multiple regression to derive atmospheric correction coefficients\n",
    "    df_newnames = modtran_lut.rename(columns={'Surface T[K]': 'surface', 'TOA T[K]': 'toa', 'TCWV [cm]': 'tcwv'})\n",
    "    df_newnames['tcwv_toa'] = df_newnames['tcwv']*df_newnames['toa']\n",
    "    results = smf.ols('surface ~ toa + tcwv_toa', data=df_newnames).fit()\n",
    " \n",
    "    return results\n",
    "\n",
    "##########################\n",
    "\n",
    "def derive_retrieval_ransac(modtran_lut, residual_threshold=1.0, max_trials=100, random_state=42):\n",
    "    \"\"\"\n",
    "    Derive the retrieval coefficients from the atmospheric column inputs and outputs to the MODTRAN\n",
    "    model runs for Landsat using RANSAC regression.\n",
    "    \n",
    "    Variables:\n",
    "    -----------\n",
    "    modtran_lut : pandas DataFrame\n",
    "        A dataframe that includes columns for surface temperature [K], top of atmosphere \n",
    "        brightness temperature [K], and total column water vapor [cm]. Expected column names are:\n",
    "            'Surface T[K]', 'TOA T[K]', and 'TCWV [cm]'\n",
    "    \n",
    "    residual_threshold : float, default 1.0\n",
    "        Maximum residual for a data point to be classified as an inlier.\n",
    "        \n",
    "    max_trials : int, default 100\n",
    "        Maximum number of iterations for the RANSAC algorithm.\n",
    "        \n",
    "    random_state : int, default 42\n",
    "        Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing the estimated coefficients with keys:\n",
    "            'Intercept', 'toa', 'tcwv_toa'\n",
    "    \"\"\"\n",
    "    # Rename columns to standard names\n",
    "    df_newnames = modtran_lut.rename(columns={\n",
    "        'Surface T[K]': 'surface',\n",
    "        'TOA T[K]': 'toa',\n",
    "        'TCWV [cm]': 'tcwv'\n",
    "    })\n",
    "\n",
    "    # Remove rows with any NaN values\n",
    "    df_newnames = df_newnames.dropna()\n",
    "    \n",
    "    # Create the interaction term\n",
    "    df_newnames['tcwv_toa'] = df_newnames['tcwv'] * df_newnames['toa']\n",
    "    \n",
    "    # Prepare the predictor matrix and response vector\n",
    "    X = df_newnames[['toa', 'tcwv_toa']]\n",
    "    y = df_newnames['surface']\n",
    "    \n",
    "    # Set up the RANSAC regression with a base LinearRegression estimator\n",
    "    base_estimator = LinearRegression()\n",
    "    ransac = RANSACRegressor(estimator=base_estimator,\n",
    "                             max_trials=max_trials,\n",
    "                             residual_threshold=residual_threshold,\n",
    "                             random_state=random_state)\n",
    "    \n",
    "    # Fit the model\n",
    "    ransac.fit(X, y)\n",
    "    \n",
    "    # Extract the fitted parameters\n",
    "    # The intercept and coefficients are stored in the underlying estimator.\n",
    "    params = {\n",
    "        'Intercept': ransac.estimator_.intercept_,\n",
    "        'toa': ransac.estimator_.coef_[0],\n",
    "        'tcwv_toa': ransac.estimator_.coef_[1]\n",
    "    }\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "def derive_retrieval_odr(modtran_lut):\n",
    "    \"\"\"\n",
    "    Derive the retrieval coefficients from the atmospheric column inputs and outputs \n",
    "    to the MODTRAN model runs for Landsat using Orthogonal Distance Regression.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    modtran_lut : pandas DataFrame\n",
    "        A dataframe that includes columns for surface temperature [K],\n",
    "        top-of-atmosphere brightness temperature [K], and total column water vapor [cm].\n",
    "        Expected column names:\n",
    "            'Surface T[K]', 'TOA T[K]', and 'TCWV [cm]'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing the estimated coefficients:\n",
    "            'Intercept', 'toa', and 'tcwv_toa'\n",
    "    \"\"\"\n",
    "    # Rename columns to standard names\n",
    "    df_newnames = modtran_lut.rename(columns={\n",
    "        'Surface T[K]': 'surface',\n",
    "        'TOA T[K]': 'toa',\n",
    "        'TCWV [cm]': 'tcwv'\n",
    "    })\n",
    "    \n",
    "    # Remove any rows that contain NaNs\n",
    "    df_newnames = df_newnames.dropna()\n",
    "    \n",
    "    # Create the interaction term\n",
    "    df_newnames['tcwv_toa'] = df_newnames['tcwv'] * df_newnames['toa']\n",
    "    \n",
    "    # Prepare the independent variables and the dependent variable.\n",
    "    # For ODR, X must be an array of shape (n_predictors, n_points)\n",
    "    X = df_newnames[['toa', 'tcwv_toa']].values.T  # shape: (2, n)\n",
    "    y = df_newnames['surface'].values              # shape: (n,)\n",
    "    \n",
    "    # Define the linear model function for ODR.\n",
    "    # beta[0] is the intercept, beta[1] is the coefficient for 'toa', and beta[2] for 'tcwv_toa'\n",
    "    def linear_model(beta, x):\n",
    "        return beta[0] + beta[1] * x[0] + beta[2] * x[1]\n",
    "    \n",
    "    # Create an ODR Model object\n",
    "    model = odr.Model(linear_model)\n",
    "    \n",
    "    # Prepare the data for ODR. (If you have measurement errors, you can pass them via sx and sy)\n",
    "    data = odr.RealData(X, y)\n",
    "    \n",
    "    # Create an ODR instance with an initial guess for the parameters.\n",
    "    # Here we use an initial guess: [0.0, 1.0, 1.0]\n",
    "    odr_instance = odr.ODR(data, model, beta0=[0.0, 1.0, 1.0])\n",
    "    \n",
    "    # Run the ODR regression.\n",
    "    out = odr_instance.run()\n",
    "    \n",
    "    # Return the parameters in a dictionary similar to the statsmodels output.\n",
    "    results = {\n",
    "        'Intercept': out.beta[0],\n",
    "        'toa': out.beta[1],\n",
    "        'tcwv_toa': out.beta[2],\n",
    "        # Optionally, you can also return diagnostics:\n",
    "        'sum_square': out.sum_square,\n",
    "        'res_var': out.res_var\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "##########################\n",
    "\n",
    "def spec_hu_to_tcwv(modtran_lut, modtran_atm, atm_levels=37):\n",
    "    '''\n",
    "    Calculate total column water vapor by integrating across all atmospheric pressure levels\n",
    "    using hydrostatic approximation.\n",
    "\n",
    "    Output:\n",
    "    modtran_lut = original dataframe with added TCWV column in [cm]\n",
    "    '''\n",
    "    g = 9.80665  # gravity [m/s^2]\n",
    "\n",
    "    m = 0\n",
    "    for y in tqdm(range(modtran_lut.shape[0]-1)):\n",
    "        r = m + atm_levels\n",
    "        df = modtran_atm.iloc[m:r]\n",
    "\n",
    "        tcwv_pa = 0\n",
    "        for i in range(1, len(df)):\n",
    "            p0 = df['pressure [hPa]'].iloc[i-1] * 100  # convert to Pa\n",
    "            p1 = df['pressure [hPa]'].iloc[i] * 100\n",
    "            q0 = df['spec humidity [kg/kg]'].iloc[i-1]\n",
    "            q1 = df['spec humidity [kg/kg]'].iloc[i]\n",
    "            dq = (q0 + q1) / 2  # trapezoidal average\n",
    "            dp = p1 - p0        # pressure difference\n",
    "            tcwv_pa += dq * dp  # integral sum: q * dp\n",
    "\n",
    "        # Final TCWV in kg/m^2 → mm (same numerically) → cm\n",
    "        tcwv_kg_m2 = tcwv_pa / g\n",
    "        tcwv_cm = tcwv_kg_m2 / 10\n",
    "\n",
    "        modtran_lut.loc[y, 'TCWV [cm]'] = tcwv_cm\n",
    "        m = r\n",
    "\n",
    "    return modtran_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "009430d6-8fc1-40a0-93b6-e9e1d246c46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to produce SST with atmospheric correction\n",
    "'''\n",
    "Functions to produce SST with atmospheric correction\n",
    "apply_retrieval preps the masks and thermal data then runs the entire retrieval correction and calibration pipeline in lsatAtmCorr,\n",
    "lsatAtmCorr calculates top of atmosphere brightness temperatures from thermal digital numbers data in TOA_BT and applies \n",
    "the atmospheric correction to get absolute temperatures [C] using retrieval.\n",
    "'''\n",
    "\n",
    "##########################\n",
    "\n",
    "def TOA_BT(ls_thermal,scene):\n",
    "    '''\n",
    "    Calculate TOA radiance and brightness temperature using MTL json\n",
    "    \n",
    "    ls_thermal = xarray dataset of Landsat thermal data computed\n",
    "    scene = catalog item for landsat scene\n",
    "    \n",
    "    Using equations from https://www.usgs.gov/landsat-missions/using-usgs-landsat-level-1-data-product\n",
    "    '''\n",
    "    \n",
    "    # Calculate radiances using MTL data\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    # Extract bucket and key for json MTL file\n",
    "    # Example: bucket = \"usgs-landsat\" ; key = \"collection02/level-1/standard/oli-tirs/2019/002/113/LC08_L1GT_002113_20190206_20201016_02_T2/LC08_L1GT_002113_20190206_20201016_02_T2_MTL.json\"\n",
    "    s3_url = scene['MTL.json'].metadata['alternate']['s3']['href']\n",
    "    bucket = s3_url.split('/')[2].strip()\n",
    "    key = s3_url.split(bucket)[1].strip()[1:]\n",
    "\n",
    "    # Get MLT data\n",
    "    res = s3.get_object(Bucket=bucket, Key=key, RequestPayer=\"requester\")\n",
    "    MTL = res[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    # Get important constants from MTL\n",
    "    ind = MTL.find('K1_CONSTANT_BAND_10')\n",
    "    K1_10 = float(MTL[ind+23:ind+31])\n",
    "    ind = MTL.find('K2_CONSTANT_BAND_10')\n",
    "    K2_10 = float(MTL[ind+23:ind+32])\n",
    "    ind = MTL.find('RADIANCE_MULT_BAND_10')\n",
    "    ML10 = float(MTL[ind+25:ind+35])\n",
    "    ind = MTL.find('RADIANCE_ADD_BAND_10')\n",
    "    AL10 = float(MTL[ind+24:ind+31])\n",
    "\n",
    "    # Mask no data \n",
    "    DN_masked = ls_thermal.where(ls_thermal != 0)\n",
    "\n",
    "    # Top of Atmosphere radiance for Band 10\n",
    "    Llambda = ML10 * DN_masked + AL10\n",
    "\n",
    "    # Top of Atmosphere brightness temperature for Band 10\n",
    "    T10 = K2_10 / np.log((K1_10 / Llambda) + 1)\n",
    "    return T10\n",
    "\n",
    "##########################\n",
    "\n",
    "def retrieval(toa, wv, a1, a2, a3, simT_transformer, simTOA_transformer, simWV_transformer):\n",
    "    '''\n",
    "    Calculates the surface temperature.\n",
    "\n",
    "    Variables:\n",
    "    toa = calculated TOA [K] (xarray.DataArray)\n",
    "    wv = total column water vapor (xarray.DataArray)\n",
    "    ak = derived retrieval coefficients\n",
    "\n",
    "    Output:\n",
    "    SST = sea surface temperature [C] (xarray.DataArray)\n",
    "    '''\n",
    "    # Convert toa DataArray to numpy, preserving shape.\n",
    "    toa_arr = toa.values\n",
    "    original_toa_shape = toa_arr.shape\n",
    "    # Reshape to a column vector for the transformer\n",
    "    toa_norm = simTOA_transformer.transform(toa_arr.reshape(-1, 1))\n",
    "    toa_norm = toa_norm.reshape(original_toa_shape)\n",
    "    \n",
    "    # Convert wv DataArray to numpy array and transform similarly.\n",
    "    original_wv_shape = wv.shape\n",
    "    wv_norm = simWV_transformer.transform(wv.reshape(-1, 1))\n",
    "    wv_norm = wv_norm.reshape(original_wv_shape)\n",
    "    \n",
    "    # Calculate normalized SST using the retrieval coefficients and water vapor\n",
    "    SST_norm = a3 + a1 * toa_norm + a2 * wv_norm * toa_norm\n",
    "    \n",
    "    # Inverse transform SST: again reshape as needed.\n",
    "    original_sst_shape = SST_norm.shape\n",
    "    SST_norm_flat = SST_norm.reshape(-1, 1)\n",
    "    SST_flat = simT_transformer.inverse_transform(SST_norm_flat)\n",
    "    SST = SST_flat.reshape(original_sst_shape) - 273.15\n",
    "    \n",
    "    # Optionally, convert the result back into an xarray.DataArray,\n",
    "    # preserving the original toa coordinates and dimensions:\n",
    "    SST = xr.DataArray(SST, coords=toa.coords, dims=toa.dims)\n",
    "    \n",
    "    return SST\n",
    "\n",
    "##########################\n",
    "\n",
    "def lsatAtmCorr(ls_thermal,scene,mask,modwv,a1,a2,a3,simT_transformer,simTOA_transformer,simWV_transformer):\n",
    "    '''\n",
    "    Applies atmospheric correction to top of atmosphere (TOA) brightness temperatures and converts to \n",
    "    absolute temperature for Landsat thermal images. Uses a derived coefficients for a non-linear\n",
    "    sea surface temperature algorithm (retrieval) and water vapor from MODIS to produce the atmospheric \n",
    "    correction.\n",
    "\n",
    "    Variables:\n",
    "    ls_thermal = xarray dataset of Landsat thermal band computed \n",
    "    scene = STAC catalog item for the Landsat scene\n",
    "    modwv = Water Vapor array (or other varrying parameter) from MODIS that has been \n",
    "            processed to the same dimensionality and pixel size as the Landsat image\n",
    "    ak = derived retrieval coefficients \n",
    "\n",
    "    Previously defined:\n",
    "    ak = derived retrieval coefficients\n",
    "\n",
    "    Output: SST 2D array and GTiff of atmospheric corrected absolute temperatures [C]\n",
    "\n",
    "    '''\n",
    "    T10 = TOA_BT(ls_thermal,scene)\n",
    "    T10 = mask * T10\n",
    "    SST = retrieval(T10,modwv,a1,a2,a3,simT_transformer,simTOA_transformer,simWV_transformer)\n",
    "    SST = SST.compute()\n",
    "        \n",
    "    return SST\n",
    "\n",
    "##########################\n",
    "\n",
    "def apply_retrieval(ls_thermal,scene,mask,WV_xr,atmcor,simT_transformer,simTOA_transformer,simWV_transformer):\n",
    "    '''\n",
    "    Use MODIS water vapor and landsat DN in retrieval algorithm to derive sea surface temperature.\n",
    "    \n",
    "    Variables:\n",
    "    ls_scene = xarray dataset of Landsat scene  \n",
    "    scene = STAC catalog item for the Landsat scene\n",
    "    WV_xr = xarray dataarray of MODIS water vapor values matching timing of the landsat scene  \n",
    "    atmcor = dictionary of derived retrieval coefficients for all months\n",
    "    \n",
    "    Outputs:\n",
    "    SST = multiple regression summary and derived coefficients (ak) for retrieval atmospheric correction\n",
    "    Also saves a cloud-optimized geotiff of SST\n",
    "    '''\n",
    "    try:\n",
    "        wv2 = mask*WV_xr.values\n",
    "        wv3 = mask*np.around(wv2,decimals=5) # usually w2 but skippping outliers for now\n",
    "\n",
    "        means = np.nanmean(wv3)\n",
    "        print (f'Mean water vapor value is: {means}, min: {np.nanmin(wv3)}, max: {np.nanmax(wv3)}')\n",
    "        \n",
    "        # Select appropriate atmospheric correction coefficients\n",
    "        month = scene.metadata['datetime'].month\n",
    "        a_mo = f'{month}'.zfill(2)\n",
    "        a1 = atmcor[a_mo]['a1']\n",
    "        a2 = atmcor[a_mo]['a2']\n",
    "        a3 = atmcor[a_mo]['a3']\n",
    "        \n",
    "        # Apply atmospheric correction to get absolute temps in C\n",
    "        SST = lsatAtmCorr(ls_thermal,scene,mask,wv3,a1,a2,a3,simT_transformer,simTOA_transformer,simWV_transformer)\n",
    "\n",
    "        return SST\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print (f'atm correction of {ls_scene.id.values} failed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
