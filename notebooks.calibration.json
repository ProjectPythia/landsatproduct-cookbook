{"version":2,"kind":"Notebook","sha256":"dd4f736e8f5ee00e7b881597cf5550dfd456bd142bcd4de66844189ad9c2a272","slug":"notebooks.calibration","location":"/notebooks/calibration.ipynb","dependencies":[],"frontmatter":{"title":"Calibration","authors":[{"nameParsed":{"literal":"Jianwen Du","given":"Jianwen","family":"Du"},"name":"Jianwen Du","affiliations":["UoA"],"id":"contributors-calibration-generated-uid-0"}],"affiliations":[{"id":"UoA","name":"University of Arizona","department":"Hydrology and Atmospheric Sciences"}],"date":"2025-08-08","license":{"content":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"open_access":true,"github":"https://github.com/projectpythia/landsatproduct-cookbook","copyright":"2025","edit_url":"https://github.com/projectpythia/landsatproduct-cookbook/blob/main/notebooks/calibration.ipynb","exports":[{"format":"ipynb","filename":"calibration.ipynb","url":"/landsatproduct-cookbook/build/calibration-ece106fb4dfd6325ed2512e41ff88cc8.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"ü§î Why Calibrate?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J7Uart4Rka"}],"identifier":"id-why-calibrate","label":"ü§î Why Calibrate?","html_id":"id-why-calibrate","implicit":true,"key":"Ct2IZqzjE5"}],"key":"ZiD114v2sT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Calibration of a physical model is the process of tuning its parameters to ensure its outputs accurately match real-world measurements. It‚Äôs about bridging the gap between theoretical calculations and physical reality.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ad13UhJC4U"}],"key":"rSvRankQRy"},{"type":"div","style":{"backgroundColor":"#E3F2FD","borderLeft":"5px solid #2196F3","padding":"15px","fontFamily":"sans-serif"},"children":[{"type":"strong","children":[{"type":"text","value":"Key Goal:","key":"yV5WNxmT7H"}],"key":"uJrACYDkP4"},{"type":"text","value":" The primary goal is to improve predictive accuracy, transforming a model from a theoretical construct into a reliable tool for analysis and design.","key":"Rue5U1PvBT"}],"key":"ctHFATLON7"}],"key":"ygLkHiTefi"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"üìù What Do You Need?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JddCQjNoyF"}],"identifier":"id-what-do-you-need","label":"üìù What Do You Need?","html_id":"id-what-do-you-need","implicit":true,"key":"TydGwOLs7S"}],"key":"SlWOd3L2nA"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To calibrate a model, you need four key components:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bBZmf4m35G"}],"key":"XxZFhGtYEN"},{"type":"div","style":{"display":"flex","flexWrap":"wrap","gap":"10px","fontFamily":"sans-serif"},"children":[{"type":"div","style":{"flex":"1","minWidth":"200px","border":"1px solid #ccc","borderRadius":"5px","padding":"10px","background":"#fafafa"},"children":[{"type":"strong","children":[{"type":"text","value":"1. A Physical Model","key":"Qo997koFnf"}],"key":"m52dVl1wBs"},{"type":"break","key":"JXQyVFQaJH"},{"type":"text","value":"A set of mathematical equations or simulation software.","key":"cHDYY2WZt4"}],"key":"ibuaMOMdvG"},{"type":"div","style":{"flex":"1","minWidth":"200px","border":"1px solid #ccc","borderRadius":"5px","padding":"10px","background":"#fafafa"},"children":[{"type":"strong","children":[{"type":"text","value":"2. Tunable Parameters","key":"LqVDuuTfaI"}],"key":"VgUDMTdDvx"},{"type":"break","key":"I5GnlLswd2"},{"type":"text","value":"The specific \"knobs\" in your model that you can adjust.","key":"j2IJ2yttLK"}],"key":"nFmgptOjHm"},{"type":"div","style":{"flex":"1","minWidth":"200px","border":"1px solid #ccc","borderRadius":"5px","padding":"10px","background":"#fafafa"},"children":[{"type":"strong","children":[{"type":"text","value":"3. Experimental Data","key":"KCsxPvu1Qn"}],"key":"FjqN8fzjLz"},{"type":"break","key":"Katuxyx4V1"},{"type":"text","value":"High-quality measurements from the real-world system.","key":"REuiJsRntB"}],"key":"Atly7Wt61i"},{"type":"div","style":{"flex":"1","minWidth":"200px","border":"1px solid #ccc","borderRadius":"5px","padding":"10px","background":"#fafafa"},"children":[{"type":"strong","children":[{"type":"text","value":"4. An Objective Function","key":"QNr1T0BaEB"}],"key":"JGL1ePXFFS"},{"type":"break","key":"G0KbyWkBN7"},{"type":"text","value":"A metric that quantifies the error (e.g., RMSE).","key":"FoMZ36W6jm"}],"key":"KXnz7DpmDV"}],"key":"WVdqSICX1h"}],"key":"nOpWDmx6TZ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"‚öôÔ∏è How to Calibrate?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cN7Xf3TxRV"}],"identifier":"id-how-to-calibrate","label":"‚öôÔ∏è How to Calibrate?","html_id":"id-how-to-calibrate","implicit":true,"key":"beDNGXf5nq"}],"key":"lwSgueFaGg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"There are two main approaches to calibration: by hand (trial and error) or by using a smart computer search (optimization algorithms). Optimization is highly recommended for its efficiency and accuracy.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NxpX5OO2Le"}],"key":"NH8TGus6tu"},{"type":"details","children":[{"type":"summary","children":[{"type":"strong","children":[{"type":"text","value":"Click to see details on different optimization methods","key":"yDmiDTACMB"}],"key":"OXnN0QYw5h"}],"key":"YeszlsmziO"},{"type":"div","style":{"backgroundColor":"#E8F5E9","borderLeft":"5px solid #4CAF50","marginTop":"10px","padding":"15px","fontFamily":"sans-serif"},"children":[{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Gradient-Based Methods:","key":"Cg5nwy9mj8"}],"key":"x4IDQil2uU"},{"type":"text","value":" Use the error gradient for efficient searching (e.g., Levenberg-Marquardt).","key":"ZLHt3lxITK"}],"key":"OYwiET20jj"}],"key":"MkrWXMLzW2"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Gradient-Free Methods:","key":"Gw2qLJ1cDw"}],"key":"fPovJTidaY"},{"type":"text","value":" Do not require gradients, essential for ‚Äúblack-box‚Äù simulations (e.g., Nelder-Mead).","key":"v99eTqxOSr"}],"key":"SkaN3tjA4Y"}],"key":"uwShU6fjn8"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Bayesian Calibration:","key":"CLQkQT5zIb"}],"key":"Q1EvFsjdVr"},{"type":"text","value":" Treats parameters as probability distributions to quantify uncertainty.","key":"ck8OZXHdHV"}],"key":"hJfVPSMH3U"}],"key":"Zk5FsbSwS2"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Cross-Calibration:","key":"A3SiKlTakA"}],"key":"iq5xAQQdo2"},{"type":"text","value":" Calibrates one model against a trusted reference model to ensure consistency.","key":"USNgwRMPta"}],"key":"WHxd7hvy2N"}],"key":"x3J9ntrxu9"}],"key":"UY4SM40wvf"}],"key":"zcuI0kJ21V"}],"key":"syYWxqH2h2"}],"key":"qoEQLPSADu"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"‚úÖ How Do You Know It‚Äôs Calibrated?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YLV2r5aSTy"}],"identifier":"id-how-do-you-know-its-calibrated","label":"‚úÖ How Do You Know It‚Äôs Calibrated?","html_id":"id-how-do-you-know-its-calibrated","implicit":true,"key":"yQTqGsqYBE"}],"key":"rJ9OPmeSJv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"A successful calibration can be verified by analyzing the errors and by validating the model against new data. A common way to visualize the result is by plotting the model‚Äôs output against the experimental data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"utMFaAcw5r"}],"key":"q2IYmfLdJG"}],"key":"UxAbK49cOq"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Interactive Example: Adjusting Model Parameters","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K1uXzaiqDx"}],"identifier":"interactive-example-adjusting-model-parameters","label":"Interactive Example: Adjusting Model Parameters","html_id":"interactive-example-adjusting-model-parameters","implicit":true,"key":"boZb6BZKnq"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To make this concept interactive, you can run the code cell below. It will create the same plot but with sliders that let you manually adjust the model‚Äôs parameters (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Pa1XNFJ6Ly"},{"type":"inlineCode","value":"slope","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HyLhd2LzHl"},{"type":"text","value":" and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pEKVMkmsct"},{"type":"inlineCode","value":"intercept","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vd8iTdjG3F"},{"type":"text","value":"). Try to move the sliders to make the red line fit the blue dots. This gives you a hands-on feel for the ‚ÄúBy Hand‚Äù calibration process.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"iWkEIyUAnH"}],"key":"PNIWBTUFO5"}],"key":"ZNhI9a7wIE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# First, let's install ipywidgets for the interactive sliders\n#%pip install -q ipywidgets\n#%pip install -q scikit-image\n#%pip install seaborn\n# %pip install plotly\n%pip install xarray==2024.05.0\nimport earthaccess","key":"Pvdi8AWU23"},{"type":"output","id":"CiQaNLVvVw2B0-pXQpo1f","data":[{"output_type":"stream","name":"stdout","text":"Collecting xarray==2024.05.0\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading xarray-2024.5.0-py3-none-any.whl.metadata (11 kB)\r\nRequirement already satisfied: numpy>=1.23 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from xarray==2024.05.0) (2.2.6)\r\nRequirement already satisfied: packaging>=23.1 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from xarray==2024.05.0) (25.0)\r\nRequirement already satisfied: pandas>=2.0 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from xarray==2024.05.0) (2.3.1)\r\nRequirement already satisfied: python-dateutil>=2.8.2 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from pandas>=2.0->xarray==2024.05.0) (2.9.0.post0)\r\nRequirement already satisfied: pytz>=2020.1 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from pandas>=2.0->xarray==2024.05.0) (2025.2)\r\nRequirement already satisfied: tzdata>=2022.7 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from pandas>=2.0->xarray==2024.05.0) (2025.2)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/landsat-product-cookbook-dev/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->xarray==2024.05.0) (1.17.0)\r\nDownloading xarray-2024.5.0-py3-none-any.whl (1.2 MB)\r\n\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25h"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: xarray\r\n  Attempting uninstall: xarray\r\n    Found existing installation: xarray 2025.7.1\r\n    Uninstalling xarray-2025.7.1:\r\n      Successfully uninstalled xarray-2025.7.1\r\n"},{"output_type":"stream","name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nvirtualizarr 1.2.0 requires xarray>=2024.10.0, but you have xarray 2024.5.0 which is incompatible.\r\nrioxarray 0.19.0 requires xarray>=2024.7.0, but you have xarray 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\r\n\u001b[0mSuccessfully installed xarray-2024.5.0\r\n"},{"output_type":"stream","name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n"}],"key":"Uoz1p137uB"}],"key":"LymfMPv2uE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, fixed\n\n# 1. Create the sample \"Experimental Data\"\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 20)\ntrue_slope = 2.5\ntrue_intercept = 1.5\ny_data = true_slope * x_data + true_intercept + np.random.normal(0, 2, size=x_data.shape)\n\n# 2. Define a function to plot the data and our adjustable model\ndef plot_model(x, y, slope, intercept):\n    \"\"\"Plots the experimental data against the model line defined by slope and intercept.\"\"\"\n    y_model = slope * x + intercept\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(x, y, 'o', label='Experimental Data', markersize=8, color='royalblue')\n    plt.plot(x, y_model, '-', label='Adjustable Model', linewidth=3, color='red')\n    \n    # Calculate and display the RMSE as our objective function score\n    rmse = np.sqrt(np.mean((y - y_model)**2))\n    plt.title(f'Comparison of Model vs. Data (RMSE: {rmse:.2f})', fontsize=16)\n    \n    plt.xlabel('Independent Variable', fontsize=12)\n    plt.ylabel('Dependent Variable', fontsize=12)\n    plt.ylim(min(y_data)-2, max(y_data)+2)\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.6)\n    plt.show()\n\n# 3. Create the interactive plot!\n# The 'interact' function automatically creates sliders for the numerical arguments.\ninteract(plot_model, x=fixed(x_data), y=fixed(y_data), slope=(0.0, 5.0, 0.1), intercept=(-5.0, 5.0, 0.1));","key":"xbVE3xcwqk"},{"type":"output","id":"f_jsLKUR31ECnLNuUw6Qq","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 800x600 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"57418c7653ca5257893f031d6dab27b1","path":"/landsatproduct-cookbook/build/57418c7653ca5257893f031d6dab27b1.png"}}},{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"interactive(children=(FloatSlider(value=2.5, description='slope', max=5.0), FloatSlider(value=0.0, description‚Ä¶","content_type":"text/plain"},"application/vnd.jupyter.widget-view+json":{"content":"{\"version_major\":2,\"version_minor\":0,\"model_id\":\"57b383462e2e48bfb8f48f40d56e83cd\"}","content_type":"application/vnd.jupyter.widget-view+json"}}}],"key":"PTuyz4UWrx"}],"key":"JaBxo71P4l"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Example: Landsat calibration using MODIS SST","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IL9Qja3qfv"}],"identifier":"example-landsat-calibration-using-modis-sst","label":"Example: Landsat calibration using MODIS SST","html_id":"example-landsat-calibration-using-modis-sst","implicit":true,"key":"pwKfZAmqMH"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Create matchups between Landsat and MODIS SST data near Cosgrove, West Antarctica\nto produce a calibration for Landsat SSTs","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"U1GLtbeoMf"}],"key":"j4Ugi2MrGB"}],"key":"JPTjrZ7VPu"},{"type":"block","kind":"notebook-code","data":{"editable":true,"slideshow":{"slide_type":""},"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Import libraries and modules\n%config InlineBackend.figure_format = 'svg'\n%matplotlib widget\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport xarray as xr\nimport geopandas as gpd\nfrom datetime import date, timedelta, datetime\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom matplotlib import colors\nfrom matplotlib.pylab import rcParams\nfrom matplotlib.patches import Polygon as Pgon\nimport cartopy.crs as ccrs\nimport cartopy\n\nimport os\nfrom cycler import cycler\nimport pyproj\nfrom pyproj import Proj, transform\nfrom sklearn.neighbors import BallTree\nimport pytz\nimport pygmt\nimport gc\nimport copy\nimport random\nimport statsmodels.formula.api as sm\nimport scipy.stats as stats\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom shapely.geometry import Point, Polygon\nfrom pathlib import Path\nimport math\nfrom scipy.odr import Model, RealData, ODR\nfrom tqdm.notebook import trange, tqdm\nimport seaborn as sns\n\nimport earthaccess\n\n# For LST file masking\nimport pystac_client\nimport intake\nfrom rasterio.session import AWSSession\nimport boto3\n\nimport SSTutils as stu\n\nimport warnings\nwarnings.filterwarnings('ignore')","visibility":"show","key":"d9DGFP8N30"},{"type":"output","id":"KDSCR7bLrE8W6MZg38Cho","data":[{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrasterio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msession\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AWSSession\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboto3\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSSTutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstu\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     52\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'SSTutils'","ename":"ModuleNotFoundError","evalue":"No module named 'SSTutils'"}],"visibility":"show","key":"Ms0tmYXbn7"}],"visibility":"show","key":"IeS0hLf4sY"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"#For color cycling in plots that is color blind friendly...make new ones at \"I want hue\" tools.medialab.sciences-po.fr/iwanthue\ncolor_cycler = cycler(color=[\"#6777cf\",\"#adba49\",\"#c65ca0\",\"#5fa042\",\"#683287\",\"#72ce7b\",\"#c44a48\",\"#45c7a9\",\"#933c1d\",\"#d0803f\",\"#ac9239\",\"#317c39\"])\ncolorline_cycler = (cycler(color=[\"#75a141\",\"#6c61b9\",\"#bc4d45\",\"#c1913d\",\"#b85298\",\"#4aa8e8\"]) +\n                 cycler(linestyle=['-','--',':','-.','-','--']))\nrcParams['axes.prop_cycle'] = cycler('color', color_cycler)","visibility":"show","key":"xvWhBZ7b0B"},{"type":"output","id":"8Ojm0kydFkS_jVHjKmvCE","data":[],"visibility":"show","key":"VJOx6meMAg"}],"visibility":"show","key":"fKmqrzS1zO"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Build Landsat - MODIS SST matchups","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"V9kqLn18Ur"}],"identifier":"build-landsat-modis-sst-matchups","label":"Build Landsat - MODIS SST matchups","html_id":"build-landsat-modis-sst-matchups","implicit":true,"key":"VD8FDSI7hf"}],"visibility":"show","key":"DFvxXPBWPn"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Set paths and important variables and Calibration region bounding box\n\nbasepath = Path('/home/jovyan/landsatproduct-cookbook')\nspacing = [990,-990] # 990m sampling of MODIS data so that upsampling is easy and because 30m takes far too long\nparam = 'sea_surface_temperature'\nsize_threshold = 30\n\nlocation = 0             # 0 and 1 are the Cosgrove and Dotson Polynya calibration areas, respectively\nsurf_temp = 'SST'        # 'SST' and 'LST' are for the Landsat SST and LST algorithms respectively\n\n# Set location bounds\nif location==1:\n    pathdir = 'DotsonPolynya'\n    latboundsC = [ -73.9 , -73.5 ] # Dotson polynya\n    lonboundsC = [ -113 , -111.5 ]\n    dfloc = 'Dotson'\nelif location==0:\n    pathdir = 'Cosgrove'\n    latboundsC = [ -73.5 , -73.42 ] # near Cosgrove\n    lonboundsC = [ -103.0 , -102.0 ]\n    dfloc = 'Cosgrove'\nelif location==2:\n    pathdir = 'Burke'\n    latboundsC = [ -73.81 , -73.42 ] # south of Burke\n    lonboundsC = [ -104.2 , -103.8 ]\n    dfloc = 'Burke'\nif location==3:\n    pathdir = 'DotsonIntercomp'\n    latboundsC = [ -74.2 , -74.11 ] # Dotson plume for intercomparison\n    lonboundsC = [ -113.5 , -113.17 ]\n    dfloc = 'DotsonIntercomp'\n\n# Coefficients for calibration\n# SST\nsstcalib_m = 0.76 \nsstcalib_b = 0.55 \n\n# LST\nlstcalib_m = 0.80\nlstcalib_b = 1.00\n\nmodmin = -1.9\nLSTmin = np.around(modmin/lstcalib_m - lstcalib_b,2) \nSSTmin = np.around(modmin/sstcalib_m - sstcalib_b,2) # should be about -2.0\n\n# Uncertainties used in ODR propagation of error\nmodis_uncertainty = 0.44  # long wave sst ocean color atbd\nsst_uncertainty = 0.3 # USGS Landsat stray light notice\nlst_uncertainty = 1.0 # gerace 2020\npix_uncertainty = np.sqrt((1000*1000)/(100*100)) # MODIS 1km x 1km and Landsat 100m x 100m\n\n\n# For calibrated SST runs\nif surf_temp=='SST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/Validation/{pathdir}/'\n    else:\n        sstpath = basepath / f'Data/SST/MODcalib/{pathdir}/'\n    tif = 'tif'\n    thresh = SSTmin\n    calib_m = sstcalib_m\n    calib_b = sstcalib_b\n    \n# If running for LST comparisons\nelif surf_temp=='LST':\n    if location==3:\n        sstpath = basepath / f'Data/SST/LST/Calibration/DotsonPolynya/'\n    else:\n        sstpath = basepath / f'Data/SST/LST/Calibration/{pathdir}/'\n    tif = 'TIF'\n    thresh = LSTmin\n    calib_m = lstcalib_m\n    calib_b = lstcalib_b","visibility":"show","key":"rAh3vpL05S"},{"type":"output","id":"oUnF5FK10Z3cRhqTMBtei","data":[],"visibility":"show","key":"me0S1vtidZ"}],"visibility":"show","key":"n6EoTJK8g5"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate for accessing NASA data (MODIS)\nauth = earthaccess.login(strategy=\"interactive\")\n\n# If we are not authenticated\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)","visibility":"show","key":"pF5RB0hCaM"},{"type":"output","id":"0xN4wLjAKCG_17KCBECSm","data":[],"visibility":"show","key":"tb1DjRGKNr"}],"visibility":"show","key":"bnuPvIBUXH"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Convert bounding box to south polar stereo for checking if landsat has any data in bounding box\n# Speeds up process a lot\nsource_crs = 'epsg:4326' \ntarget_crs = 'epsg:3031' # Coordinate system of the file   \n\nbbox,checkbox = stu.lsat_reproj(source_crs,target_crs,(lonboundsC[0],latboundsC[0],lonboundsC[1],latboundsC[1]))\n\n# Create polygon for later cropping\npolygon = Polygon([(bbox[0][0],bbox[0][1]),(bbox[3][0],bbox[3][1]),(bbox[2][0],bbox[2][1]),(bbox[1][0],bbox[1][1])])\n\n# Create min/max boundaries for trimming image before crop_xarray to cut down on processing times\nminx, miny, maxx, maxy = polygon.bounds\npolarx = [minx, maxx]\npolary = [miny, maxy]","visibility":"show","key":"ApjSWQOTmK"},{"type":"output","id":"dmGLGH9HEP9QBa2ULqu6v","data":[],"visibility":"show","key":"fEm93z2KlJ"}],"visibility":"show","key":"e2nkIgPOWS"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Get Landsat file paths in directory\nlsatfiles = os.listdir(sstpath)\nlsatfiles = [x for x in lsatfiles if x[-3:] == tif]\nlsatfiles.sort()\nprint (len(lsatfiles))\nos.chdir(sstpath)","visibility":"show","key":"gKzYxbkuUn"},{"type":"output","id":"euma63Q3bhYo4jVzp5VUA","data":[],"visibility":"show","key":"h1xNn4E7xB"}],"visibility":"show","key":"ukmSlzLyYN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"SSTfails = [\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n 'LC08_L1GT_006112_20221024_20221107_02_T2_152257_Cel.tif',\n]\nLSTfails = [\n 'LC08_L1GT_007112_20211215_20211223_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20220201_20220211_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20221202_20221212_02_T2_SW_LST.TIF',\n 'LC08_L1GT_007112_20230204_20230209_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF',\n 'LC08_L1GT_008113_20221022_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010112_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220105_20220114_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20220121_20220128_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221020_20221101_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20221105_20221115_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230108_20230124_02_T2_SW_LST.TIF',\n 'LC08_L1GT_010113_20230313_20230321_02_T2_SW_LST.TIF',\n 'LC08_L1GT_012112_20221018_20221031_02_T2_SW_LST.TIF'\n]","key":"pP5ANrLdUq"},{"type":"output","id":"wFsC9Zn9u9kepq2JbiAS_","data":[],"key":"Gj26uBVV3h"}],"key":"wXSCmKCdDV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Search for desired Landsat scenes","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QR7IVUhCr2"}],"identifier":"search-for-desired-landsat-scenes","label":"Search for desired Landsat scenes","html_id":"search-for-desired-landsat-scenes","implicit":true,"key":"v5YlzQ7MVz"}],"key":"jU9sLWaYd3"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate for boto S3 access, etc.\nos.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\naws_session = AWSSession(boto3.Session(), requester_pays=True)","visibility":"show","key":"gz87M67LZ5"},{"type":"output","id":"VvjfrSLkPG4rCOTIinCFj","data":[],"visibility":"show","key":"LKDVEbgaa5"}],"visibility":"show","key":"ettvEFLDz8"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Setup and authenticate \nfrom dask.distributed import Client\nimport logging\nclient = Client(processes=True, n_workers=4, \n                threads_per_worker=1,\n                silence_logs=logging.ERROR)\nclient.run(lambda: os.environ[\"AWS_REQUEST_PAYER\"] == \"requester\" )\nclient","visibility":"show","key":"Ro9Kf7r0lP"},{"type":"output","id":"xXahxKIRzUYqNAnORDEpU","data":[],"visibility":"show","key":"pltAbOydyO"}],"visibility":"show","key":"xL8xnQw5h6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define the landsat STAC catalog location\nurl = 'https://landsatlook.usgs.gov/stac-server'\ncollection = 'landsat-c2l1' # Landsat Collection 2, Level 1 - includes L8 and L9","key":"EDJa1AUsCv"},{"type":"output","id":"TKD5DxXZ7OcXu_mqzr30R","data":[],"key":"yEv324X1YG"}],"key":"qTmsbPP4H9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"i=0\nls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\nls_scene","key":"s5FRbY4PTV"},{"type":"output","id":"sVQx-mUSQjsvsbhkTHJu0","data":[],"key":"TXi8Fd9KEI"}],"key":"nY1UK8DkeA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%time\n# ~1 min 32 sec per image\n# If number of MODIS images per satellite is much more than 25, its because there is a ULY,LRY issue\nos.chdir('/home/jovyan/landsatproduct-cookbook/Data/SST/MODcalib/Cosgrove/')\n\nlsat_mod = []\n#for i in tqdm(range(len(lsatfiles)), desc=\"Processing\"):\nfor i in tqdm(range(1), desc=\"Processing the first image\"):\n    # Check for known repeatedly bad files that will kill the code\n    if surf_temp == 'SST':    \n        if lsatfiles[i] in SSTfails:\n            continue\n    elif surf_temp == 'LST':\n        if lsatfiles[i] in LSTfails:\n            continue\n        \n    # Concatenate all landsat files into xarray with a time dimension\n    ls_scene = xr.open_dataset(lsatfiles[i],chunks=dict(x=512, y=512),engine='rasterio')['band_data'].sel(band=1)\n    ls_scene = ls_scene.rio.write_crs(\"epsg:3031\", inplace=True)\n    print(\"1\")\n    if surf_temp == 'SST':\n        times = pd.to_datetime(lsatfiles[i][17:25]+lsatfiles[i][41:47], format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-8])\n    elif surf_temp == 'LST':\n        # Need to mask LST because not done previously\n        mask = stu.get_lst_mask(lsatfiles[i])\n        ls_scene = ls_scene * mask\n        \n        times = pd.to_datetime(lsatfiles[i][17:25]+'120000', format='%Y%m%d%H%M%S')\n        ls_scene = ls_scene.assign_coords(time=times,ID=lsatfiles[i][:-4])\n        ls_scene = ls_scene - 273.15\n\n    # Subset scene and check that it has the correct dimensions because y order changes sometimes\n    ls_scene = stu.subset_img(ls_scene,polarx,polary) # subset so easier to work with\n    ls_scene = stu.crop_xarray_dataarray_with_polygon(ls_scene, polygon) # crop data to exact bounding box\n\n    # if location==3:\n    # # Calibrate\n    # ls_scene = ls_scene * calib_m + calib_b\n    \n    # # Remove SSTs that are unrealistically cool\n    # ls_scene = ls_scene.where(ls_scene >= thresh, np.nan)\n\n    lsID = lsatfiles[i]\n    print (lsID)\n    \n    # Take mean temp, will skip the modis stage if no Landsat data in the calibration region\n    try:\n        lsat = np.nanmean(ls_scene)\n        ls_num = ls_scene.notnull().values.sum()\n    except Exception as e:\n        print (lsID, e)\n        lsat = np.nan\n\n    print(lsat)\n    if ~np.isfinite(lsat):\n        continue\n\n    # Find coincident MODIS SST scene\n    mod_scene, mod_file,time_dif = stu.find_MODIS(lonboundsC,latboundsC,ls_scene)\n    print(mod_file)\n\n    try:\n        # Acquire and align MODIS data to Landsat\n\n        # To subset to only high quality MODIS temp measurements which doesn't seem to be useful\n        # print(mod_scene.quality_level.max().values)\n        # mod_temps = mod_scene.sea_surface_temperature.where(mod_scene.quality_level>=4)\n\n        MODsst_xr = stu.get_sst(ls_scene,mod_scene.sea_surface_temperature,spacing,param) #mod_scene.sea_surface_temperature\n\n        # Remove SSTs that are unrealistically cool\n        MODsst_xr = MODsst_xr.where(MODsst_xr >= -1.9, np.nan)\n\n        # Crop Landsat image to meet the slightly smaller MODIS image (smaller image results from upsample methods in get_wv2)\n        ls_scene = stu.subset_img(ls_scene,[MODsst_xr.x.min(),MODsst_xr.x.max()],[MODsst_xr.y.min(),MODsst_xr.y.max()])\n\n        # Only use MODIS data where cropped Landsat data is also available\n        MODsst_xr_sub = MODsst_xr.where(ls_scene.notnull(),np.nan)\n\n        # Take mean temp\n        modis = np.nanmean(MODsst_xr_sub)\n        MOD_num = MODsst_xr_sub.notnull().values.sum()\n    except Exception as e:\n        print (mod_file, e)\n        modis = np.nan\n        MOD_num = 0\n\n    # Take mean using Landsat data only where cropped MODIS data is also available (need to do both)\n    try:\n        ls_scene_sub = ls_scene.where(MODsst_xr_sub.notnull(),np.nan)\n        lsat = np.nanmean(ls_scene_sub)\n        ls_num = ls_scene_sub.notnull().values.sum()\n    except Exception as e:\n        print (lsID, e)\n        lsat = np.nan\n\n    # Append file names with SST means from the Cosgrove box\n    lsat_mod.append([times,mod_file,modis,MOD_num,lsID,lsat,ls_num,time_dif])\n    print (f'MODIS mean: {modis}, Landsat 8: {lsat}')\n\n    try:\n        del ls_scene, ls_sub, mod_scene, MODsst_xr, MODsst_xr_sub\n    except:\n        pass\n\n    gc.collect()","key":"qMAr9mQReE"},{"type":"output","id":"VFZBUGwOOftL3C5CHbApD","data":[],"key":"IVGWMlt2of"}],"key":"ieWeXigeKA"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# # Put data into DataFrame and save    \n# headers = ['DateTime','MODIS_filename','MODIS_SST','MODIS_pix','L8_filename',f'L8_{surf_temp}','L8_pix','time_dif']\n# lsat_mod_df = pd.DataFrame(lsat_mod,columns=headers)\n# out_df = basepath / f'Data/MODISvLandsat_{surf_temp}_{dfloc}_20250500.csv'\n# lsat_mod_df.to_csv(out_df, index=False)","visibility":"show","key":"PkN6RWdkd5"},{"type":"output","id":"_wHnVPccZI7aLdRZu1dnO","data":[],"visibility":"show","key":"oNEdMkEL2I"}],"visibility":"show","key":"BOMH1Mdp8Z"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Calculate calibration bias and trend","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jmiO0GdJEZ"}],"identifier":"calculate-calibration-bias-and-trend","label":"Calculate calibration bias and trend","html_id":"calculate-calibration-bias-and-trend","implicit":true,"key":"bE3b1e3HbR"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Uses a ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WrrMFEH5rA"},{"type":"link","url":"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"RANSAC regression","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"PuuqE8ji7j"}],"urlSource":"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html","key":"p6glFhumSI"},{"type":"text","value":", but provides comparisons to an Ordinary Least Squares regression calculation from statsmodel of the same parameters.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"xZCJjjhN8T"}],"key":"WJwM7L4aOj"}],"key":"PIcPmMball"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Read in paired MODIS/Landsat data created above\nsurf_temp = 'SST'\n\nif surf_temp=='LST':\n    thresh = -3.5 # -3.4 is ok too\n    pix_thresh = 1300\nelif surf_temp=='SST':\n    thresh = -3.1\n    pix_thresh = 1300\nmod_sst_thresh = -1.9\n\n# For Cosgrove region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Cosgrove.csv'\n    df1 = pd.read_csv(out_df)\n    lsat_mod_df_C = df1\nelse:   \n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Cosgrove_lin_scale.csv' \n    df1 = pd.read_csv(out_df)\n    lsat_mod_df_C = df1\n\nprint(f'Original # matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C['MODIS_pix']>=pix_thresh]\nlsat_mod_df_C = lsat_mod_df_C[lsat_mod_df_C[f'L8_{surf_temp}']>=thresh]\n\n# For Dotson polynya region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Dotson.csv'\n    df5 = pd.read_csv(out_df)\n    lsat_mod_df_D = df5\nelse:\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Dotson_lin_scale.csv'  \n    df5 = pd.read_csv(out_df)\n    lsat_mod_df_D = df5\n\nprint(f'Original # matchups at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D['MODIS_pix']>=pix_thresh]\nlsat_mod_df_D = lsat_mod_df_D[lsat_mod_df_D[f'L8_{surf_temp}']>=thresh]\n\n# For Burke region\nif surf_temp=='LST':\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_LST_Burke.csv'\n    df9 = pd.read_csv(out_df)\n    lsat_mod_df_B = df9\nelse:\n    out_df = '/home/jovyan/landsatproduct-cookbook/Data/MODISvLandsat_SST_Burke_lin_scale.csv'\n    df9 = pd.read_csv(out_df)\n    lsat_mod_df_B = df9\n\nprint(f'Original # matchups at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')\n\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_SST']>=mod_sst_thresh]\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B['MODIS_pix']>=pix_thresh]\nlsat_mod_df_B = lsat_mod_df_B[lsat_mod_df_B[f'L8_{surf_temp}']>=thresh]\n\n# Concatenate data from both regions\nlsat_mod_df_n = pd.concat([lsat_mod_df_B,lsat_mod_df_C,lsat_mod_df_D]) \nlsat_mod_df_bc = pd.concat([lsat_mod_df_B,lsat_mod_df_C]) \nlsat_mod_df_cd = pd.concat([lsat_mod_df_C,lsat_mod_df_D])\nlsat_mod_df_bd = pd.concat([lsat_mod_df_B,lsat_mod_df_D])\nprint(f'Num. good matchups at Cosgrove: {lsat_mod_df_C[lsat_mod_df_C.MODIS_SST.notna()].shape[0]}, at Dotson: {lsat_mod_df_D[lsat_mod_df_D.MODIS_SST.notna()].shape[0]}, at Burke: {lsat_mod_df_B[lsat_mod_df_B.MODIS_SST.notna()].shape[0]}')","visibility":"show","key":"zDumjFdC5U"},{"type":"output","id":"dmI_lzYJd0hCHotfZJX7f","data":[],"visibility":"show","key":"elZiyoTyFt"}],"visibility":"show","key":"qREKCje1yl"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# sum_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_n = lsat_mod_df_n[lsat_mod_df_n.DateTime.dt.month.isin([2])]\n# sum_c = lsat_mod_df_C[lsat_mod_df_C.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# sum_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bc = lsat_mod_df_bc[lsat_mod_df_bc.DateTime.dt.month.isin([2])]\n# sum_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_bd = lsat_mod_df_bd[lsat_mod_df_bd.DateTime.dt.month.isin([2])]\n# sum_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([9,10,11,12,1,3])]\n# shld_cd = lsat_mod_df_cd[lsat_mod_df_cd.DateTime.dt.month.isin([2])]","visibility":"show","key":"kGAY2xpj7U"},{"type":"output","id":"AVIRrLadfU_RFxZwFqZ5E","data":[],"visibility":"show","key":"r9p3CumO5l"}],"visibility":"show","key":"rXY7aCOiMp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # ***check all the february images to see if we need to add a threshold of 2.0C or cut images or if the issue is clouds???\n# # shld\n# look = lsat_mod_df_n.sort_values('L8_filename')\n# look.head(20)","key":"KJ08oPuCeE"},{"type":"output","id":"HDP_SgUwFrXzMV7ALWNOw","data":[],"key":"LOWfDxQ9aP"}],"key":"lkNfrBVNW1"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Orthoganal Regression \nif surf_temp=='LST':\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = lst_uncertainty\nelse:\n    data0 = lsat_mod_df_n\n    landsat_uncertainty = sst_uncertainty\n\n# Original data\nx_original = np.array(data0[f'L8_{surf_temp}'])\ny_original = np.array(data0['MODIS_SST'])\n\n# Assume these are your uncertainty estimates per observation\nsy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\nsx = np.full_like(x_original, landsat_uncertainty)\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model\nlinear = Model(linear_model)\n\n# Create a RealData object using your DataFrame\ndata = RealData(x_original, y_original,sx=sx, sy=sy)\n\n# Set up ODR with the model and data\nodr = ODR(data, linear, beta0=[1., 0.])\n\n# Run the regression\nout = odr.run()\n\n# Use the output\nbeta = out.beta\nbeta_err = out.sd_beta\n\n# Print the summary\nout.pprint()\n\n# Predicting values using the ODR model\ny_pred = linear_model(beta, x_original)\n\n# Get R2\n# Calculate Total Sum of Squares (SST)\ny_mean = np.mean(y_original)\nSST = np.sum((y_original - y_mean)**2)\n\n# Calculate Residual Sum of Squares (SSR)\nSSR = np.sum((y_original - y_pred)**2)\n\n# Compute RMSE\nrmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n\n# Calculate R^2\nR2 = 1 - (SSR / SST)\nprint(\"R^2:\", np.around(R2,2))\nprint(f\"RMSE: {np.around(rmse,2)}\")","visibility":"show","key":"CJfkE31sIB"},{"type":"output","id":"yAlNJcx9WT1yPvOOeKaDO","data":[],"visibility":"show","key":"Aw8NgjAPSX"}],"visibility":"show","key":"y8TdayAC73"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"if surf_temp=='LST':\n    # Plot regression\n    beta_mdn = [beta[0]-beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_mup = [beta[0]+beta_err[0]*1.96,beta[1]-beta_err[1]*1.96]\n    beta_bdn = [beta[0]-beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    beta_bup = [beta[0]+beta_err[0]*1.96,beta[1]+beta_err[1]*1.96]\n    print(f'At 95% confidence interval: {np.around(beta[0],2)}+/-{np.around(beta_err[0]*1.96,2)}, {np.around(beta[1],2)}+/-{np.around(beta_err[1]*1.96,2)}, n={y_pred.shape[0]}')\n    xfill = np.array([-4.5,1.5])\n    \n    fig, ax = plt.subplots(figsize=(8, 3.5))\n    ax.tick_params(labelsize=14)\n    \n    # LST data and regression\n    plt.scatter(x_original, y_original, s=12,color='mediumslateblue')\n    plt.plot(x_original, y_pred, color='mediumslateblue', label='LST ODR')\n    plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n    \n    # Comparison regressions\n    xi = np.arange(-7.0,5.0,1.0)\n    plt.plot(xi,xi * sstcalib_m + sstcalib_b,color='k',linewidth=2,label='SST ODR')\n    plt.plot(xi,xi,color='lightcoral',linewidth=2, label='MODIS 1:1')\n        \n    plt.legend(loc='lower right',fontsize=14)\n    plt.text(-2.7,-0.15,rf'$\\mathbf{{y={np.around(beta[0],2)}x+{np.around(beta[1],2)}\\quad r^2={np.around(R2,2)}}}$',color='mediumslateblue', fontweight='bold',fontsize=14)\n    plt.xlim([-3.5,-1.2])\n    plt.ylim([-3.05,0.8])\n    # else: \n    #     plt.plot(x_original, y_pred, color='k', label='NLSST Orthogonal Distance Regression')\n    #     plt.legend(loc='lower right',fontsize=12)\n    #     plt.text(-2.6,-0.2,f'y={np.around(beta[0],2)}x+{np.around(beta[1],2)}   $r^2$={np.around(R2,2)}',fontsize=14)\n    #     plt.xlim([-3.2,-0.15])\n    #     plt.ylim([-2.4,0.9]) \n    plt.xlabel('Landsat ST [¬∞C]',fontsize=16)\n    plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n    plt.tight_layout()","visibility":"show","key":"I8bh37uR1W"},{"type":"output","id":"H2gDVFycGNyzo68fnxwGV","data":[],"visibility":"show","key":"c957X4dMkY"}],"visibility":"show","key":"agF4aOQ91g"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Orthoganal Regression for SST only\ndataframes = [\n    ('Combined', lsat_mod_df_n),\n    ('Burke', lsat_mod_df_B),\n    ('Cosgrove', lsat_mod_df_C),\n    ('Dotson', lsat_mod_df_D),\n]\n\nif surf_temp=='LST':\n    landsat_uncertainty = lst_uncertainty\nelse:\n    landsat_uncertainty = sst_uncertainty\n\n# Dictionary to store the results from each DataFrame\nodr_results = {}\n\n# Define a linear function for the model\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\n# Create a Model object\nlinear = Model(linear_model)\n\n# Loop over each DataFrame\nfor df_name, data0 in dataframes:\n    print(f\"\\n=== Processing {df_name} ===\")\n    \n    # Original data\n    x_original = np.array(data0[f'L8_{surf_temp}'])\n    y_original = np.array(data0['MODIS_SST'])\n\n    # Assume these are your uncertainty estimates per observation\n    sy = np.full_like(y_original, modis_uncertainty * pix_uncertainty)  # Adjusted for resolution mismatch\n    sx = np.full_like(x_original, landsat_uncertainty)\n    \n    # Create a RealData object using your DataFrame\n    data = RealData(x_original, y_original,sx=sx, sy=sy)\n    \n    # Set up ODR with the model and data, providing an initial guess\n    odr = ODR(data, linear, beta0=[1., 0.])\n    \n    # Run the regression\n    out = odr.run()\n    \n    # Retrieve best-fit parameters and their std. dev.\n    beta = out.beta\n    beta_err = out.sd_beta\n    \n    # Print the summary\n    out.pprint()\n    \n    # Predicting values using the ODR model\n    y_pred = linear_model(beta, x_original)\n    \n    # Get R2\n    # Calculate Total Sum of Squares (SST)\n    y_mean = np.mean(y_original)\n    SST = np.sum((y_original - y_mean)**2)\n    \n    # Calculate Residual Sum of Squares (SSR)\n    SSR = np.sum((y_original - y_pred)**2)\n    \n    # Calculate R^2\n    R2 = 1 - (SSR / SST)\n\n    # Compute RMSE\n    rmse = np.sqrt(((y_original - y_pred) ** 2).mean())\n    \n    # Print R^2\n    print(f\"{df_name} R^2:\", np.around(R2, 2))\n    print(f\"RMSE: {np.around(rmse,2)}\")\n    \n    # Store results in a dictionary for later use (plotting, etc.)\n    odr_results[df_name] = {\n        'beta': beta,\n        'beta_err': beta_err,\n        'R2': R2,\n        'x_original': x_original,\n        'y_original': y_original,\n        'y_pred': y_pred\n    }","key":"w9VQBfA2XW"},{"type":"output","id":"Y2-TeHiiFtypkQQLiaBMV","data":[],"key":"fCsWPvvuRE"}],"key":"yVldWos96l"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Import the necessary ipywidgets components\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\n# The @interact decorator will automatically create widgets for the function arguments\n@interact(\n    show_burke=widgets.Checkbox(value=True, description=\"Burke Data\"),\n    show_cosgrove=widgets.Checkbox(value=True, description=\"Cosgrove Data\"),\n    show_dotson=widgets.Checkbox(value=True, description=\"Dotson Data\"),\n    show_combined_fit=widgets.Checkbox(value=True, description=\"Combined Fit\"),\n    show_confidence_interval=widgets.Checkbox(value=True, description=\"95% CI\")\n)\ndef interactive_sst_plot(show_burke, show_cosgrove, show_dotson, show_combined_fit, show_confidence_interval):\n    \n    # This is your original code, with plotting commands wrapped in if-statements\n    if surf_temp=='SST':\n        # Your original data calculation code (unchanged)\n        beta_mdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n        beta_mup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]-odr_results['Combined']['beta_err'][1]*1.96]\n        beta_bdn = [odr_results['Combined']['beta'][0]-odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n        beta_bup = [odr_results['Combined']['beta'][0]+odr_results['Combined']['beta_err'][0]*1.96,odr_results['Combined']['beta'][1]+odr_results['Combined']['beta_err'][1]*1.96]\n        a1 = np.around(odr_results['Combined']['beta'][0],2)\n        a2 = np.around(odr_results['Combined']['beta'][1],2)\n        ar = np.around(odr_results['Combined']['R2'],2)\n        b1 = np.around(odr_results['Burke']['beta'][0],2)\n        b2 = np.around(odr_results['Burke']['beta'][1],2)\n        br = np.around(odr_results['Burke']['R2'],2)\n        c1 = np.around(odr_results['Cosgrove']['beta'][0],2)\n        c2 = np.around(odr_results['Cosgrove']['beta'][1],2)\n        cr = np.around(odr_results['Cosgrove']['R2'],2)\n        d1 = np.around(odr_results['Dotson']['beta'][0],2)\n        d2 = np.around(odr_results['Dotson']['beta'][1],2)\n        dr = np.around(odr_results['Dotson']['R2'],2)\n        xfill = np.array([-4.3,0.9])\n\n        # --- Plotting Section ---\n        fig, ax = plt.subplots(figsize=(8, 4)) # Increased height slightly for better text placement\n        ax.tick_params(labelsize=14)\n\n        if show_burke:\n            plt.scatter(np.array(lsat_mod_df_B[f'L8_{surf_temp}']), np.array(lsat_mod_df_B['MODIS_SST']), s=12,color='#00bf7d', label='Burke')\n            plt.plot(odr_results['Burke']['x_original'], odr_results['Burke']['y_pred'], ls='-',linewidth=1,color='#00bf7d')\n            plt.text(-2.9,0.0,f'y={b1}x+{b2}   $r^2$={br}',color='#00bf7d',fontsize=12)\n\n        if show_cosgrove:\n            plt.scatter(np.array(lsat_mod_df_C[f'L8_{surf_temp}']), np.array(lsat_mod_df_C['MODIS_SST']), s=12,color=sns.color_palette(\"colorblind\")[3], label='Cosgrove')\n            plt.plot(odr_results['Cosgrove']['x_original'], odr_results['Cosgrove']['y_pred'], ls='-',linewidth=1,color=sns.color_palette(\"colorblind\")[3])\n            plt.text(-2.9,-0.3,f'y={c1}x+{c2}   $r^2$={cr}',color=sns.color_palette(\"colorblind\")[3],fontsize=12)\n            \n        if show_dotson:\n            plt.scatter(np.array(lsat_mod_df_D[f'L8_{surf_temp}']), np.array(lsat_mod_df_D['MODIS_SST']), s=12,color='#0073e6', label='Dotson')\n            plt.plot(odr_results['Dotson']['x_original'], odr_results['Dotson']['y_pred'], ls='-',linewidth=1,color='#0073e6')\n            plt.text(-2.9,-0.6,f'y={d1}x+{d2}   $r^2$={dr}',color='#0073e6',fontsize=12)\n\n        if show_combined_fit:\n            plt.plot(odr_results['Combined']['x_original'], odr_results['Combined']['y_pred'], color='k')\n            plt.text(-2.9,0.3,f'y={a1}x+{a2}   $r^2$={ar}',color='k',fontsize=14)\n            if show_confidence_interval:\n                plt.fill_between(xfill, linear_model(beta_bdn, xfill), linear_model(beta_mup, xfill),alpha=0.3, facecolor='0.3')\n\n        # General plot labels and limits (unchanged)\n        plt.xlim([-3.05,-0.15])\n        plt.ylim([-2.3,0.9])\n        plt.xlabel('Landsat SST [¬∞C]',fontsize=16)\n        plt.ylabel('MODIS SST [¬∞C]',fontsize=16)\n        plt.legend(loc='lower right',fontsize=10)\n        plt.tight_layout()\n        plt.show() # Make sure to show the plot","key":"yKIYyO5uiQ"},{"type":"output","id":"T8e3cXIMriByZ-BOu6H7l","data":[],"key":"ZG2XJ3bPRj"}],"key":"gtSVN2OekO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"odr_results['Combined']['beta_err']","key":"o0gWClqoCx"},{"type":"output","id":"RvIN5NjRsZN7Y-BXVgHX3","data":[],"key":"aeqwBec39F"}],"key":"QYP9CAE8wy"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"if surf_temp=='SST':\n    # Ordinary least squares regression between Landsat and MODIS SST matchups\n    resultC = sm.ols(formula=\"MODIS_SST ~ L8_SST\", data=data0).fit()\n    print (resultC.summary())","visibility":"show","key":"DukeiIZtZV"},{"type":"output","id":"AbtZJVKFCX-S06RdIOIBO","data":[],"visibility":"show","key":"zdI6HSxBr6"}],"visibility":"show","key":"bJ5pEl8nD2"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Interactive Analysis Dashboard using Matplotlib","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eVWuoCQXOd"}],"identifier":"interactive-analysis-dashboard-using-matplotlib","label":"Interactive Analysis Dashboard using Matplotlib","html_id":"interactive-analysis-dashboard-using-matplotlib","implicit":true,"key":"od440tStdk"}],"key":"FLGEiRgdxx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Imports for Interactive Dashboard\nimport ipywidgets as widgets\nfrom ipywidgets import interact, Layout","key":"osC7lmulew"},{"type":"output","id":"Zm76xtaHCLIBLyWbVlsou","data":[],"key":"B6C4TdBTdy"}],"key":"aNtsQljoVm"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Matplotlib-based Interactive Dashboard Function\n\ndef linear_model(p, x):\n    return p[0] * x + p[1]\n\ndef interactive_calibration_dashboard_matplotlib(region, chart_type, pix_thresh, modis_sst_thresh, lsat_sst_thresh):\n    # 1. & 2. Data filtering and selection (Same as your original code)\n    df_C_filt = lsat_mod_df_C[(lsat_mod_df_C['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_C['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_C[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_C_filt['Region'] = 'Cosgrove'\n\n    df_D_filt = lsat_mod_df_D[(lsat_mod_df_D['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_D['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_D[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_D_filt['Region'] = 'Dotson'\n\n    df_B_filt = lsat_mod_df_B[(lsat_mod_df_B['MODIS_pix'] >= pix_thresh) & (lsat_mod_df_B['MODIS_SST'] >= modis_sst_thresh) & (lsat_mod_df_B[f'L8_{surf_temp}'] >= lsat_sst_thresh)]\n    df_B_filt['Region'] = 'Burke'\n\n    if region == 'All Regions':\n        df_filtered = pd.concat([df_B_filt, df_C_filt, df_D_filt])\n    elif region == 'Cosgrove':\n        df_filtered = df_C_filt\n    elif region == 'Dotson':\n        df_filtered = df_D_filt\n    elif region == 'Burke':\n        df_filtered = df_B_filt\n    \n    # Create the figure and axis for the plot\n    fig, ax = plt.subplots(figsize=(8, 6))\n\n    if len(df_filtered) < 2:\n        ax.text(0.5, 0.5, \"Not enough data with the current filter settings.\", ha='center', va='center')\n        ax.set_axis_off()\n        plt.show()\n        return\n\n    # 3. ODR Calculation (Same as your original code)\n    x_data = df_filtered[f'L8_{surf_temp}'].values\n    y_data = df_filtered['MODIS_SST'].values\n    sx = np.full_like(x_data, sst_uncertainty)\n    sy = np.full_like(y_data, modis_uncertainty * pix_uncertainty)\n    model = Model(linear_model)\n    data = RealData(x_data, y_data, sx=sx, sy=sy)\n    odr = ODR(data, model, beta0=[1., 0.])\n    output = odr.run()\n    slope, intercept = output.beta\n    y_pred = linear_model(output.beta, x_data)\n\n    # 4. Statistics Calculation (Same as your original code, but formatted for Matplotlib title)\n    bias = np.mean(y_data - x_data)\n    trend = slope\n    ss_total = np.sum((y_data - np.mean(y_data))**2)\n    ss_resid = np.sum((y_data - y_pred)**2)\n    r2 = 1 - (ss_resid / ss_total) if ss_total > 0 else 0\n    rmse = np.sqrt(np.mean((y_data - y_pred)**2))\n    # Note: Matplotlib title doesn't support HTML bold tags, so they are removed.\n    stats_text = (f\"Trend (Slope): {trend:.2f} | Bias (MODIS - Landsat): {bias:.2f}¬∞C\\n\"\n                  f\"R¬≤: {r2:.2f} | RMSE: {rmse:.2f} | N: {len(df_filtered)}\")\n\n    # 5. Create Matplotlib figure based on chart_type\n    if chart_type == 'Scatter':\n        # Seaborn's scatterplot is a great way to handle coloring by category easily\n        sns.scatterplot(data=df_filtered, x=f'L8_{surf_temp}', y='MODIS_SST', hue='Region', ax=ax, s=50)\n    elif chart_type == 'Heatmap':\n        ax.hist2d(df_filtered[f'L8_{surf_temp}'], df_filtered['MODIS_SST'], bins=20, cmap='viridis')\n        fig.colorbar(ax.collections[0], ax=ax, label='Point Density')\n\n    # Add regression line\n    sorted_indices = np.argsort(x_data)\n    ax.plot(x_data[sorted_indices], y_pred[sorted_indices], color='black', linewidth=2, label='ODR Fit')\n\n    # Set titles, labels, and limits\n    ax.set_title(stats_text)\n    ax.set_xlabel(\"Landsat SST [¬∞C]\")\n    ax.set_ylabel(\"MODIS SST [¬∞C]\")\n    ax.set_xlim(-3.05, -0.15)\n    ax.set_ylim(-2.3, 0.9)\n    ax.legend()\n    ax.grid(True, linestyle='--', alpha=0.6)\n    \n    plt.show()\n\n# Define Widgets\nstyle = {'description_width': 'initial'}\nw_region = widgets.Dropdown(options=['All Regions', 'Cosgrove', 'Dotson', 'Burke'], value='All Regions', description='Select Region:', style=style)\nw_chart_type = widgets.ToggleButtons(options=['Scatter', 'Heatmap'], description='Chart Type:', button_style='info')\nw_pix_thresh = widgets.IntSlider(value=1300, min=0, max=5000, step=100, description='Min MODIS Pixels:', style=style, layout=Layout(width='500px'))\nw_modis_sst = widgets.FloatSlider(value=-1.9, min=-2.5, max=0, step=0.1, description='Min MODIS SST (¬∞C):', style=style, layout=Layout(width='500px'))\nw_lsat_sst = widgets.FloatSlider(value=-3.1, min=-4.0, max=0, step=0.1, description='Min Landsat SST (¬∞C):', style=style, layout=Layout(width='500px'))\n\n\n# Launch the new Matplotlib-based Dashboard\ninteract(interactive_calibration_dashboard_matplotlib, \n         region=w_region, \n         chart_type=w_chart_type,\n         pix_thresh=w_pix_thresh, \n         modis_sst_thresh=w_modis_sst, \n         lsat_sst_thresh=w_lsat_sst);","key":"bkNDPF1Nr9"},{"type":"output","id":"s2JrO8MdfJYf41GPhChbk","data":[],"key":"AClcobFUTu"}],"key":"U6TvIG2DNM"}],"key":"pyc4ghV5Mh"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Preprocessing data","url":"/notebooks/preprocessing","group":"Preamble"},"next":{"title":"Validating your data product","url":"/notebooks/validation-step1","group":"Preamble"}}},"domain":"http://localhost:3000"}